{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_validate,cross_val_predict\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix,make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from util.client import Nba_Season\n",
    "# NOTE: scikit-optimize no longer supported, look into using Optuna or Hyperopt\n",
    "# from skopt import BayesSearchCV\n",
    "# from skopt.space import Real, Integer, Categorical\n",
    "from collections import defaultdict\n",
    "import util.NeuralNet as nn\n",
    "import autobnn as ab\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "import torch\n",
    "import torch.nn as tnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_past_data(files):\n",
    "    '''\n",
    "    files: list of tuples in form of (features,samples,is_norm) file paths\n",
    "    returns: samples,features_norm\n",
    "    '''\n",
    "    samples = []\n",
    "    features_norm = []\n",
    "\n",
    "    for file in files:\n",
    "        features_yr = np.genfromtxt(file[0],delimiter=',')\n",
    "        if file[2]:\n",
    "            features_norm.extend(features_yr)\n",
    "        else:\n",
    "            features_yr_norm = [[float(i)/sum(j) for i in j ]for j in features_yr]\n",
    "            features_norm.extend(features_yr_norm)\n",
    "        \n",
    "        samples_yr = np.genfromtxt(file[1],delimiter=',')\n",
    "        samples.extend(samples_yr)\n",
    "\n",
    "    return samples,features_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This noteboook will explore the use of traditional neural networks to predict the outcome of NBA games. This notebook will outline the process of generating data using scrapers from ```client.py```, training MLPs on this data, and using these predictions to make bets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using client.py\n",
    "Below are some examples on how to use the utilities in ```client.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading from saved data\n",
    "The NBA folder contains a variety of datasets which can be loaded to train models. ```on_off_stats``` contains pickle data for each season mapping players to their on/off statistics as well as mapping teams to their statistical features. ```samps_feats``` contains samples and features for a given season. With this data, we can populate an Nba_Season object which can be used to add betting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../NBA/on_off_stats/2022-2023_on_off.pkl', 'rb') as f:\n",
    "    loaded_on_off = pickle.load(f)\n",
    "\n",
    "with open('../NBA/on_off_stats/2022-2023_team_stats.pkl', 'rb') as f:\n",
    "    loaded_stats = pickle.load(f)\n",
    "\n",
    "features = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "\n",
    "samples = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "nba_szn_2022_2023 = Nba_Season('2022','2023', team_stats=loaded_stats, team_on_off=loaded_on_off,\n",
    "                               features=features, samples=samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case we can just use the existing features and samples for training our models, making the construction of an Nba_Season object unnecessary for training models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generating features from CSV of games in form of [date, away team, away pts, home team, home pts]\n",
    "In order to generate new features, we can use the Nba_Season object with the paramaters of (start_year, end_year) to generate on/off statistics, features, and samples to our desired output path. To avoid getting flagged and blocked by basketball reference, it is best to run ```pop_const_new()``` and ```generate_features()```in seperate cells with ~1 minute break between.\n",
    "\n",
    "NOTE: This requires a CSV containing game information from basketball reference in the form of [date, away team, away pts, home team, home pts], for examples on expected format see ```NBA/games```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_szn_2023_2024 = Nba_Season('2023','2024')\n",
    "nba_szn_2023_2024.pop_const_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "Failed at line: 44 for file: ../NBA/games/2018-2019_season_inj.csv LINK: https://www.basketball-reference.com/boxscores/201810220DAL.html\n",
      "list index out of range\n",
      "Failed at line: 44 for file: ../NBA/games/2018-2019_season_inj.csv LINK: https://www.basketball-reference.com/boxscores/201810220UTA.html\n",
      "list index out of range\n",
      "Failed at line: 44 for file: ../NBA/games/2018-2019_season_inj.csv LINK: https://www.basketball-reference.com/boxscores/201810220POR.html\n",
      "list index out of range\n",
      "Failed at line: 44 for file: ../NBA/games/2018-2019_season_inj.csv LINK: https://www.basketball-reference.com/boxscores/201810220GSW.html\n",
      "list index out of range\n",
      "Failed at line: 44 for file: ../NBA/games/2018-2019_season_inj.csv LINK: https://www.basketball-reference.com/boxscores/201810220LAL.html\n",
      "list index out of range\n",
      "Failed at line: 44 for file: ../NBA/games/2018-2019_season_inj.csv LINK: https://www.basketball-reference.com/boxscores/201810230DET.html\n",
      "Too many failures, terminating feature generation\n"
     ]
    }
   ],
   "source": [
    "with open('../NBA/on_off_stats/2018-2019_on_off.pkl', 'rb') as f:\n",
    "    on_off_2018_2019 = pickle.load(f)\n",
    "with open('../NBA/on_off_stats/2018-2019_team_stats.pkl', 'rb') as f:\n",
    "    team_stats_2018_2019 = pickle.load(f)\n",
    "\n",
    "nba_szn_2018_2019 = Nba_Season('2018','2019',team_stats=team_stats_2018_2019,team_on_off=on_off_2018_2019)\n",
    "features, samples = nba_szn_2018_2019.generate_features('../NBA/games/2018-2019_season_inj.csv')\n",
    "# save generated data\n",
    "nba_szn_2018_2019.save_data(save_path='../NBA/samps_feats/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your IP is blocked the console will output error messages indicating at which entry requests stopped. If this happens, it is best to hide your IP using a VPN and continue generating features using saved pickle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../NBA/on_off_stats/2023-2024_on_off.pkl', 'rb') as f:\n",
    "    on_off_2023_2024 = pickle.load(f)\n",
    "with open('../NBA/on_off_stats/2023-2024_team_stats.pkl', 'rb') as f:\n",
    "    team_stats_2023_2024 = pickle.load(f)\n",
    "    \n",
    "nba_szn_2023_2024 = Nba_Season('2023','2024',team_stats=team_stats_2023_2024,team_on_off=on_off_2023_2024)\n",
    "features, samples = nba_szn_2023_2024.generate_features('../NBA/games/2023-2024_nba_season.csv')\n",
    "# save generated data\n",
    "nba_szn_2023_2024.save_data(save_path='../NBA/samps_feats/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Adding historic bet info from vegas insider\n",
    "Using our NBA season object can allow us to generate new CSVs containing betting statistics for making bets with trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.rotowire.com/betting/nba/archive.php - data for over under and spread\n",
    "games = nba_szn_2023_2024.add_bet_info('../NBA/games/2023-2024_nba_season.csv','../NBA/with_bets/2023-2024_season.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing against historic odds data for 2022-2023\n",
    "Once a model is trained, we can use the ```test_kelly()``` function defined below to make bets. This function is based on the [Kelly Criterion](https://en.wikipedia.org/wiki/Kelly_criterion) betting strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelly(home_pred,away_pred,home_line,away_line,max_bet=100):\n",
    "    '''\n",
    "    Applies kelly critereon based on features and moneyline data\n",
    "    home_pred: Prediction from MLP for home team\n",
    "    away_pred: Prediction from MLP for away team\n",
    "    home_line: Moneyline for home team\n",
    "    away_line: Moneyline for away team\n",
    "    '''\n",
    "    bet_amount = 0\n",
    "    to_win = 0\n",
    "\n",
    "    log_home = home_pred - home_pred * away_pred / (home_pred + away_pred - (2*home_pred*away_pred))\n",
    "    log_away = away_pred - home_pred * away_pred / (home_pred + away_pred - (2*home_pred*away_pred))\n",
    "\n",
    "    # calculate ratio and implied for home\n",
    "    home_line_adj = home_line\n",
    "    away_line_adj = away_line\n",
    "    if home_line < 0:\n",
    "        home_line_adj *= -1\n",
    "        home_line_adj /= 100\n",
    "        home_ratio = 1/(home_line_adj)\n",
    "        implied_home = home_line_adj/(1+home_line_adj)\n",
    "    else:\n",
    "        home_line_adj /= 100\n",
    "        home_ratio = home_line_adj\n",
    "        implied_home = 1/(home_line+1)\n",
    "\n",
    "    # calculate ratio and implied for away\n",
    "    if away_line < 0:\n",
    "        away_line_adj *= -1\n",
    "        away_line_adj /= 100\n",
    "        away_ratio = 1/(away_line_adj)\n",
    "        implied_away = away_line_adj/(1+away_line_adj)\n",
    "    else:\n",
    "        away_line_adj /= 100\n",
    "        away_ratio = away_line_adj\n",
    "        implied_away = 1/(away_line_adj+1)\n",
    "    \n",
    "    diff_home = log_home - implied_home\n",
    "    diff_away = log_away - implied_away\n",
    "\n",
    "    kelly_home = log_home - (log_away/home_ratio)\n",
    "    kelly_away = log_away - (log_home/away_ratio)\n",
    "\n",
    "    prob = 0\n",
    "\n",
    "    # make bets, negative if away team bet\n",
    "    if diff_home > diff_away and diff_home > 0.05:\n",
    "        bet_amount = (max_bet*kelly_home)\n",
    "        if home_line < 0:\n",
    "            to_win = bet_amount/((home_line*-1)/100)\n",
    "        else:\n",
    "            to_win = bet_amount/((home_line)/100)\n",
    "        prob = home_pred\n",
    "\n",
    "    \n",
    "    elif diff_away > diff_home and diff_away > 0.05:\n",
    "        bet_amount = (max_bet*kelly_away)\n",
    "        if away_line < 0:\n",
    "            to_win = -1*bet_amount/((away_line*-1)/100)\n",
    "        else:\n",
    "            to_win = -1*bet_amount/((away_line)/100)\n",
    "        prob = away_pred\n",
    "\n",
    "    return bet_amount,to_win,prob\n",
    "\n",
    "def test_kelly(model,samps,feats,money_lines):\n",
    "    money_made = 0\n",
    "    money_risked = 0\n",
    "    correct = 0\n",
    "    guessed = 0\n",
    "    team_bet = []\n",
    "    amount = []\n",
    "    gained = []\n",
    "    probs = []\n",
    "\n",
    "    for i in range(len(samps)):\n",
    "        preds = model.predict_proba(feats[i].reshape(1,-1))\n",
    "        away_pred = preds[0][0]\n",
    "        home_pred = preds[0][1]\n",
    "        home_ml = money_lines[i][7]\n",
    "        away_ml = money_lines[i][10]\n",
    "\n",
    "        to_bet,to_win,prob = kelly(home_pred,away_pred,home_ml,away_ml)\n",
    "        probs.append(prob)\n",
    "        money_risked += to_bet\n",
    "\n",
    "        curr_gained = 0\n",
    "\n",
    "        if to_win < 0:\n",
    "            team_bet.append('Away')\n",
    "            amount.append(to_bet)\n",
    "            guessed += 1\n",
    "            curr_gained = -1*to_bet\n",
    "            if samps[i] == 1:\n",
    "                correct += 1\n",
    "                curr_gained = (-1*to_win)\n",
    "                #money_made += curr_gained\n",
    "        elif to_win > 0:\n",
    "            team_bet.append('Home')\n",
    "            amount.append(to_bet)\n",
    "            guessed += 1\n",
    "            curr_gained = -1*to_bet\n",
    "            if samps[i] == 0:\n",
    "                correct += 1\n",
    "                curr_gained = to_win\n",
    "                #money_made += curr_gained\n",
    "        else:\n",
    "            team_bet.append(0)\n",
    "            amount.append(0)\n",
    "\n",
    "        gained.append(curr_gained)\n",
    "\n",
    "        if curr_gained > 0:\n",
    "            money_made += curr_gained\n",
    "\n",
    "    return correct,guessed,team_bet,probs,amount,gained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model\n",
    "Below, we train a neural network defined in ```util/NeuralNet.py``` on game data from 2015-2023. First we load the data, then test a variety of hyper parameters to optimize our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old samples and features\n",
    "features_norm = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features_norm,samples_1d, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try my own NN implementation\n",
    "nba_df = pd.read_csv('../NBA/samps_feats/2015-2023_nba_features_norm_inj.csv',header=None)\n",
    "#samp = pd.read_csv('samps_feats/2015-2023_nba_samples_inj.csv',header=None)\n",
    "nba_df['class'] = samples_1d\n",
    "nba_df.insert(0,'bias',1)\n",
    "\n",
    "k = 10\n",
    "nba_class_0 = nba_df.loc[nba_df['class'] == 0].sample(frac=1)\n",
    "nba_class_0['class'] = [[0,1]] * len(nba_class_0)\n",
    "nba0_split = np.array_split(nba_class_0,k)\n",
    "nba_class_1 = nba_df.loc[nba_df['class'] == 1].sample(frac=1)\n",
    "nba_class_1['class'] = [[1,0]] * len(nba_class_1)\n",
    "nba1_split = np.array_split(nba_class_1,k)\n",
    "nba_vals = [[0,1],[1,0]]\n",
    "\n",
    "nba_fold = []\n",
    "for i in range(k):\n",
    "    this_fold = [nba0_split[i],nba1_split[i]]\n",
    "    nba_fold.append(pd.concat(this_fold))\n",
    "\n",
    "dig_nn_arc = [[16,64,2],[16,32,2],[16,32,64,2]]\n",
    "\n",
    "def dig_test(fold,vals,nn_arc,lamb,eps,alpha,batch_size):\n",
    "    dig_res = nn.k_fold(fold,vals,nn_arc,lamb,eps,alpha,batch_size)\n",
    "    arc_dict = defaultdict(list)\n",
    "    print(f'lamb = {lamb} eps = {eps} alpha = {alpha} batch_size = {batch_size}')\n",
    "\n",
    "    for arc,perf in dig_res.items():\n",
    "        avg_acc,avg_f1 = [0,0]\n",
    "        for res in perf:\n",
    "            avg_acc += res[0]\n",
    "            avg_f1 += res[1]\n",
    "        arc_dict['Architecture'].append(arc)\n",
    "        arc_dict['Accuracy'].append(avg_acc/10)\n",
    "        arc_dict['F1'].append(avg_f1/10)\n",
    "\n",
    "    arc_table = pd.DataFrame(arc_dict)\n",
    "    print(arc_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb = 0.05 eps = 0.001 alpha = 1 batch_size = 200\n",
      "      Architecture  Accuracy        F1\n",
      "0      [16, 64, 2]  0.494139  0.440280\n",
      "1      [16, 32, 2]  0.497437  0.491444\n",
      "2  [16, 32, 64, 2]  0.488669  0.405804\n",
      "lamb = 0.05 eps = 0.001 alpha = 2 batch_size = 200\n",
      "      Architecture  Accuracy        F1\n",
      "0      [16, 64, 2]  0.489104  0.394730\n",
      "1      [16, 32, 2]  0.486670  0.426037\n",
      "2  [16, 32, 64, 2]  0.490318  0.360376\n",
      "lamb = 0.05 eps = 0.0001 alpha = 3 batch_size = 200\n",
      "      Architecture  Accuracy        F1\n",
      "0      [16, 64, 2]  0.489624  0.368952\n",
      "1      [16, 32, 2]  0.489539  0.388998\n",
      "2  [16, 32, 64, 2]  0.490406  0.340295\n"
     ]
    }
   ],
   "source": [
    "hyper_params = [[0.05,0.001,0.1,200],[0.05,0.001,0.5,200],[0.05,0.0001,1,200]]\n",
    "for params in hyper_params:\n",
    "    dig_test(nba_fold,nba_vals,dig_nn_arc,params[0],params[1],params[2],params[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb = 0.05 eps = 0.001 alpha = 0.1 batch_size = 200\n",
      "      Architecture  Accuracy        F1\n",
      "0      [16, 64, 2]  0.500391  0.497137\n",
      "1      [16, 32, 2]  0.495527  0.489780\n",
      "2  [16, 32, 16, 2]  0.506468  0.502972\n",
      "lamb = 0.05 eps = 0.001 alpha = 0.5 batch_size = 200\n",
      "      Architecture  Accuracy        F1\n",
      "0      [16, 64, 2]  0.492228  0.478710\n",
      "1      [16, 32, 2]  0.498562  0.495824\n",
      "2  [16, 32, 16, 2]  0.500999  0.497117\n",
      "lamb = 0.05 eps = 0.0001 alpha = 1 batch_size = 200\n",
      "      Architecture  Accuracy        F1\n",
      "0      [16, 64, 2]  0.491709  0.443859\n",
      "1      [16, 32, 2]  0.492232  0.456464\n",
      "2  [16, 32, 16, 2]  0.494660  0.484062\n"
     ]
    }
   ],
   "source": [
    "dig_nn_arc = [[16,64,2],[16,32,2],[16,32,16,2]]\n",
    "hyper_params = [[0.05,0.001,0.1,200],[0.05,0.001,0.5,200],[0.05,0.0001,1,200]]\n",
    "for params in hyper_params:\n",
    "    dig_test(nba_fold,nba_vals,dig_nn_arc,params[0],params[1],params[2],params[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb = 0.05 eps = 0.001 alpha = 0.1 batch_size = 100\n",
      "      Architecture  Accuracy        F1\n",
      "0      [16, 64, 2]  0.499003  0.496878\n",
      "1      [16, 32, 2]  0.503514  0.500165\n",
      "2  [16, 32, 16, 2]  0.510464  0.503028\n",
      "lamb = 0.1 eps = 0.001 alpha = 0.1 batch_size = 100\n",
      "      Architecture  Accuracy        F1\n",
      "0      [16, 64, 2]  0.493011  0.490122\n",
      "1      [16, 32, 2]  0.502561  0.497471\n",
      "2  [16, 32, 16, 2]  0.501261  0.493445\n",
      "lamb = 0.5 eps = 0.0001 alpha = 0.1 batch_size = 100\n",
      "      Architecture  Accuracy        F1\n",
      "0      [16, 64, 2]  0.494660  0.493091\n",
      "1      [16, 32, 2]  0.498302  0.489409\n",
      "2  [16, 32, 16, 2]  0.501520  0.493224\n"
     ]
    }
   ],
   "source": [
    "dig_nn_arc = [[16,64,2],[16,32,2],[16,32,16,2]]\n",
    "hyper_params = [[0.05,0.001,0.1,100],[0.1,0.001,0.1,100],[0.5,0.0001,0.1,100]]\n",
    "for params in hyper_params:\n",
    "    dig_test(nba_fold,nba_vals,dig_nn_arc,params[0],params[1],params[2],params[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[2678 1722 2519 1718]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.61      0.56      4400\n",
      "           1       0.50      0.41      0.45      4237\n",
      "\n",
      "    accuracy                           0.51      8637\n",
      "   macro avg       0.51      0.51      0.50      8637\n",
      "weighted avg       0.51      0.51      0.50      8637\n",
      "\n",
      "TEST SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[880 611 835 554]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.59      0.55      1491\n",
      "           1       0.48      0.40      0.43      1389\n",
      "\n",
      "    accuracy                           0.50      2880\n",
      "   macro avg       0.49      0.49      0.49      2880\n",
      "weighted avg       0.49      0.50      0.49      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(128,256,256,128), alpha=0.75, learning_rate_init=0.01, activation='identity', tol=0.01,early_stopping=True,epsilon=0.0001,solver='adam',max_iter=500)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TRAINING SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TEST SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are satisfied with our model's performance, we can make our bets using betting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602\n",
      "1285\n",
      "-36628.49345755003\n"
     ]
    }
   ],
   "source": [
    "# load features, for each feature predict outcome, use prediction for kelly bet on ML\n",
    "feats = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samps = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "samps_1d = [0 if j[0] == 0 else 1 for j in samps]\n",
    "correct,guessed,team_bet,probs,amount,gained = test_kelly(mlp,samps_1d,feats,bet_data[1:])\n",
    "\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[405 314 365 236]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.56      0.54       719\n",
      "           1       0.43      0.39      0.41       601\n",
      "\n",
      "    accuracy                           0.49      1320\n",
      "   macro avg       0.48      0.48      0.48      1320\n",
      "weighted avg       0.48      0.49      0.48      1320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = mlp.predict(feats)\n",
    "print(confusion_matrix(samps_1d,preds).ravel())\n",
    "print(classification_report(samps_1d,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our model is quite reckless in gambling, likely due to the fact that it is extremely overconfident in its predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate samples and features for current season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_szn = Nba_Season('2023','2024')\n",
    "curr_szn.pop_const_new()\n",
    "feats_curr, samps_curr = curr_szn.generate_features('../NBA/games/2023-2024_nba_season.csv')\n",
    "# save generated data\n",
    "curr_szn.save_data(save_path='../NBA/samps_feats/')\n",
    "curr_bet_data = curr_szn.add_bet_info('../NBA/2023-2024_nba_season.csv','../NBA/with_bets/2023-2024_season.csv')\n",
    "samps_1d_curr = [0 if j[0] == 0 else 1 for j in samps_curr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[248 161 208  99]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.61      0.57       409\n",
      "           1       0.38      0.32      0.35       307\n",
      "\n",
      "    accuracy                           0.48       716\n",
      "   macro avg       0.46      0.46      0.46       716\n",
      "weighted avg       0.47      0.48      0.48       716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = mlp.predict(feats_curr)\n",
    "print(confusion_matrix(samps_1d_curr,preds).ravel())\n",
    "print(classification_report(samps_1d_curr,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13786.679351604225\n"
     ]
    }
   ],
   "source": [
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "fix_bet_data = bet_data[1:]\n",
    "samps_1d_curr = [1 if j[2] > j[4] else 0 for j in fix_bet_data]\n",
    "correct,guessed,team_bet,probs,amount,gained = test_kelly(mlp,samps_1d_curr,feats_curr,fix_bet_data)\n",
    "\n",
    "df = pd.DataFrame(curr_bet_data)\n",
    "df['team_bet'] = team_bet\n",
    "df['confidence'] = probs\n",
    "df['amount'] = amount\n",
    "df['gained'] = gained\n",
    "\n",
    "print(df['gained'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2013 - 2023 NBA Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fix scraper for this season!\n",
    "nba_szn_2014 = Nba_Season('2013','2014')\n",
    "nba_szn_2014.pop_const_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2014, samples_2014 = nba_szn_2014.generate_features('../NBA/games/2013-2014_season_inj.csv')\n",
    "nba_szn_2014.save_data(save_path='../NBA/samps_feats/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old samples and features\n",
    "features_norm = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2014 - 2023 NBA Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features_norm,samples_1d, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for hyperparams\n",
    "In an attempt to find the optimal hyperparameters for our model, we can run BayesSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.5094361877801368\n",
      "test score: 0.5177083333333333\n"
     ]
    }
   ],
   "source": [
    "opt = BayesSearchCV(\n",
    "    MLPClassifier(hidden_layer_sizes=(128,256,256,128)),\n",
    "    {\n",
    "        'solver': ['adam'],\n",
    "        'learning_rate_init': (0.00001,0.1),\n",
    "        'learning_rate' :['invscaling','constant'],\n",
    "        'max_iter': (500,5000),\n",
    "        'activation': ['logistic', 'tanh', 'relu'],\n",
    "        'alpha': (1e-6,2),\n",
    "        'tol' : (1e-6,0.01)\n",
    "    },\n",
    "    n_iter=32,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "opt.fit(feat_train,samp_train)\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(feat_test, samp_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('activation', 'relu'), ('alpha', 5.830439210684934), ('learning_rate', 'invscaling'), ('learning_rate_init', 0.06113148894211121), ('max_iter', 4524), ('solver', 'adam'), ('tol', 0.006365456815293766)])\n"
     ]
    }
   ],
   "source": [
    "print(opt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[4393    7    8 4229]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4400\n",
      "           1       1.00      1.00      1.00      4237\n",
      "\n",
      "    accuracy                           1.00      8637\n",
      "   macro avg       1.00      1.00      1.00      8637\n",
      "weighted avg       1.00      1.00      1.00      8637\n",
      "\n",
      "TEST SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[768 723 694 695]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.52      0.52      1491\n",
      "           1       0.49      0.50      0.50      1389\n",
      "\n",
      "    accuracy                           0.51      2880\n",
      "   macro avg       0.51      0.51      0.51      2880\n",
      "weighted avg       0.51      0.51      0.51      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(128,256,256,128), alpha=0.00075, learning_rate_init=0.0006113148894211121, activation='tanh', tol=0.00006365456815293766, solver='lbfgs',max_iter=4524)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TRAINING SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TEST SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[4389   11   15 4222]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4400\n",
      "           1       1.00      1.00      1.00      4237\n",
      "\n",
      "    accuracy                           1.00      8637\n",
      "   macro avg       1.00      1.00      1.00      8637\n",
      "weighted avg       1.00      1.00      1.00      8637\n",
      "\n",
      "TEST SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[720 771 713 676]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.48      0.49      1491\n",
      "           1       0.47      0.49      0.48      1389\n",
      "\n",
      "    accuracy                           0.48      2880\n",
      "   macro avg       0.48      0.48      0.48      2880\n",
      "weighted avg       0.49      0.48      0.48      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(128,256,256,128), alpha=0.0075, learning_rate_init=0.0006113148894211121, activation='tanh', tol=0.00006365456815293766, solver='lbfgs',max_iter=4524,early_stopping=True)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TRAINING SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TEST SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[3272 1128 2230 2007]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66      4400\n",
      "           1       0.64      0.47      0.54      4237\n",
      "\n",
      "    accuracy                           0.61      8637\n",
      "   macro avg       0.62      0.61      0.60      8637\n",
      "weighted avg       0.62      0.61      0.60      8637\n",
      "\n",
      "TEST SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[942 549 907 482]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.63      0.56      1491\n",
      "           1       0.47      0.35      0.40      1389\n",
      "\n",
      "    accuracy                           0.49      2880\n",
      "   macro avg       0.49      0.49      0.48      2880\n",
      "weighted avg       0.49      0.49      0.48      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(128,256,256,128), alpha=5.830439210684934, learning_rate_init=0.0006113148894211121, activation='tanh', tol=0.00006365456815293766, solver='lbfgs',max_iter=4524)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TRAINING SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TEST SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.0001, learning_rate='invscaling', activation='tanh', solver='adam',max_iter=10000)\n",
    "cv_res = cross_validate(mlp,features_norm,samples_1d,cv=10,scoring=mlp.score)\n",
    "print(\"Fit scores: {}\".format(cv_res['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN, FP, FN, TP\n",
      "[3099 2792 3062 2564]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.53      0.51      5891\n",
      "           1       0.48      0.46      0.47      5626\n",
      "\n",
      "    accuracy                           0.49     11517\n",
      "   macro avg       0.49      0.49      0.49     11517\n",
      "weighted avg       0.49      0.49      0.49     11517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.0001, learning_rate='invscaling', activation='tanh', solver='adam',max_iter=10000)\n",
    "pred = cross_val_predict(mlp,features_norm,samples_1d,cv=10)\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samples_1d,pred).ravel())\n",
    "print(classification_report(samples_1d,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10368 candidates, totalling 51840 fits\n"
     ]
    }
   ],
   "source": [
    "GRID = [\n",
    "    {'scaler': [StandardScaler()],\n",
    "     'estimator': [MLPClassifier(random_state=1)],\n",
    "     'estimator__solver': ['adam','lbfgs'],\n",
    "     'estimator__learning_rate_init': [0.0001,0.001,0.01],\n",
    "     'estimator__learning_rate' :['invscaling','constant'],\n",
    "     'estimator__max_iter': [500,1500,2500],\n",
    "     'estimator__hidden_layer_sizes': [(128,128,128),(128,256,128),(64,128,128,64),(16,32,64,64,32,16)],\n",
    "     'estimator__activation': ['logistic', 'tanh', 'relu'],\n",
    "     'estimator__alpha': [0.0001, 0.001, 0.01,0.1],\n",
    "     'estimator__tol' : [0.01, 0.0001, 0.001],\n",
    "     'estimator__early_stopping': [True, False]\n",
    "     }\n",
    "]\n",
    "\n",
    "PIPELINE = Pipeline([('scaler', None), ('estimator', MLPClassifier())])\n",
    "\n",
    "grid_search = GridSearchCV(estimator=PIPELINE, param_grid=GRID, \n",
    "                            scoring=make_scorer(sklearn.metrics.accuracy_score),# average='macro'), \n",
    "                            n_jobs=-1, refit=True, verbose=1, \n",
    "                            return_train_score=False)\n",
    "\n",
    "grid_search.fit(feat_train,samp_train)\n",
    "print('Best parameters found:\\n', grid_search.best_params_)\n",
    "print('Best parameters score:\\n', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[3451  949 3242  995]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.78      0.62      4400\n",
      "           1       0.51      0.23      0.32      4237\n",
      "\n",
      "    accuracy                           0.51      8637\n",
      "   macro avg       0.51      0.51      0.47      8637\n",
      "weighted avg       0.51      0.51      0.47      8637\n",
      "\n",
      "TEST SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[1157  334 1097  292]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.78      0.62      1491\n",
      "           1       0.47      0.21      0.29      1389\n",
      "\n",
      "    accuracy                           0.50      2880\n",
      "   macro avg       0.49      0.49      0.45      2880\n",
      "weighted avg       0.49      0.50      0.46      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.0075, learning_rate='invscaling', activation='tanh', tol=0.001, solver='lbfgs',max_iter=1500)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TRAINING SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TEST SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[3768  632  672 3565]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      4400\n",
      "           1       0.85      0.84      0.85      4237\n",
      "\n",
      "    accuracy                           0.85      8637\n",
      "   macro avg       0.85      0.85      0.85      8637\n",
      "weighted avg       0.85      0.85      0.85      8637\n",
      "\n",
      "TEST SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[753 738 713 676]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.51      0.51      1491\n",
      "           1       0.48      0.49      0.48      1389\n",
      "\n",
      "    accuracy                           0.50      2880\n",
      "   macro avg       0.50      0.50      0.50      2880\n",
      "weighted avg       0.50      0.50      0.50      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.0001, learning_rate='invscaling', activation='tanh', solver='adam',max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TRAINING SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TEST SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[3609  496  504 3452]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      4105\n",
      "           1       0.87      0.87      0.87      3956\n",
      "\n",
      "    accuracy                           0.88      8061\n",
      "   macro avg       0.88      0.88      0.88      8061\n",
      "weighted avg       0.88      0.88      0.88      8061\n",
      "\n",
      "TEST SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[920 866 887 783]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.52      0.51      1786\n",
      "           1       0.47      0.47      0.47      1670\n",
      "\n",
      "    accuracy                           0.49      3456\n",
      "   macro avg       0.49      0.49      0.49      3456\n",
      "weighted avg       0.49      0.49      0.49      3456\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,64,128,64,32), alpha=0.5, learning_rate='invscaling', activation='relu', tol=0.001,solver='lbfgs',max_iter=2500)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TRAINING SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TEST SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2268 candidates, totalling 11340 fits\n",
      "Best parameters found:\n",
      " {'estimator': MLPClassifier(alpha=0.005, hidden_layer_sizes=(16, 32, 64, 32, 16),\n",
      "              learning_rate='invscaling', max_iter=10000, random_state=1), 'estimator__activation': 'relu', 'estimator__alpha': 0.005, 'estimator__early_stopping': False, 'estimator__hidden_layer_sizes': (16, 32, 64, 32, 16), 'estimator__learning_rate': 'invscaling', 'estimator__learning_rate_init': 0.001, 'estimator__max_iter': 10000, 'estimator__solver': 'adam', 'estimator__tol': 0.0001, 'scaler': StandardScaler()}\n",
      "Best parameters score:\n",
      " 0.5117242965422075\n"
     ]
    }
   ],
   "source": [
    "GRID = [\n",
    "    {'scaler': [StandardScaler()],\n",
    "     'estimator': [MLPClassifier(random_state=1)],\n",
    "     'estimator__solver': ['adam'],\n",
    "     'estimator__learning_rate_init': [0.0001,0.001,0.01],\n",
    "     'estimator__learning_rate' :['invscaling','constant'],\n",
    "     'estimator__max_iter': [10000],\n",
    "     'estimator__hidden_layer_sizes': [(32,64,32), (64,64,64), (64,128,64), (32,64,64,32), (16,32,64,32,16), (32,64,128,64,32), (16,32,64,64,32,16)],\n",
    "     'estimator__activation': ['logistic', 'tanh', 'relu'],\n",
    "     'estimator__alpha': [0.0001, 0.001, 0.005],\n",
    "     'estimator__tol' : [0.01, 0.0001, 0.001],\n",
    "     'estimator__early_stopping': [True, False]\n",
    "     }\n",
    "]\n",
    "\n",
    "PIPELINE = Pipeline([('scaler', None), ('estimator', MLPClassifier())])\n",
    "\n",
    "grid_search = GridSearchCV(estimator=PIPELINE, param_grid=GRID, \n",
    "                            scoring=make_scorer(sklearn.metrics.accuracy_score),# average='macro'), \n",
    "                            n_jobs=-1, refit=True, verbose=1, \n",
    "                            return_train_score=False)\n",
    "\n",
    "grid_search.fit(feat_train,samp_train)\n",
    "print('Best parameters found:\\n', grid_search.best_params_)\n",
    "print('Best parameters score:\\n', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[3902  498  431 3806]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      4400\n",
      "           1       0.88      0.90      0.89      4237\n",
      "\n",
      "    accuracy                           0.89      8637\n",
      "   macro avg       0.89      0.89      0.89      8637\n",
      "weighted avg       0.89      0.89      0.89      8637\n",
      "\n",
      "TEST SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[743 748 672 717]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.50      0.51      1491\n",
      "           1       0.49      0.52      0.50      1389\n",
      "\n",
      "    accuracy                           0.51      2880\n",
      "   macro avg       0.51      0.51      0.51      2880\n",
      "weighted avg       0.51      0.51      0.51      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(128,256,256,128), alpha=0.005, learning_rate='invscaling', learning_rate_init=0.001, activation='relu', tol=0.0001,solver='adam',max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TRAINING SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TEST SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[3370 1030 1456 2781]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73      4400\n",
      "           1       0.73      0.66      0.69      4237\n",
      "\n",
      "    accuracy                           0.71      8637\n",
      "   macro avg       0.71      0.71      0.71      8637\n",
      "weighted avg       0.71      0.71      0.71      8637\n",
      "\n",
      "TEST SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[824 667 763 626]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.55      0.54      1491\n",
      "           1       0.48      0.45      0.47      1389\n",
      "\n",
      "    accuracy                           0.50      2880\n",
      "   macro avg       0.50      0.50      0.50      2880\n",
      "weighted avg       0.50      0.50      0.50      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(128,256,512,256,128), alpha=0.005, learning_rate='invscaling', learning_rate_init=0.00001, activation='relu',solver='adam',max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TRAINING SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TEST SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022-2023 NBA Season with Injuries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_norm = []\n",
    "samples = []\n",
    "\n",
    "pop_team_stats('2023')\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "pop_team_on_off('2023')\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "# with open('2022-2023_on_off.pkl', 'wb') as f:\n",
    "#     pickle.dump(TEAM_ON_OFF, f)\n",
    "\n",
    "# with open('2022-2023_on_off.pkl', 'rb') as f:\n",
    "#     loaded_dict = pickle.load(f)\n",
    "\n",
    "features_2023,samples_2023 = generate_features('2023','../NBA/games/2022-2023_season_injury.csv')\n",
    "\n",
    "np.savetxt('../NBA/2022-2023_nba_features_inj.csv', features_2023, delimiter=',')\n",
    "np.savetxt('../NBA/2022-2023_nba_samples_inj.csv', samples_2023, delimiter=',')\n",
    "\n",
    "#features_2023_ext,samples_2023_ext = generate_features('2023','games/2022-2023_season_inj_ext.csv')\n",
    "\n",
    "#features_2023.extend(features_2023_ext)\n",
    "#samples_2023.extend(samples_2023_ext)\n",
    "features_2023_norm = [[float(i)/sum(j) for i in j ]for j in features_2023]\n",
    "\n",
    "features_norm.extend(features_2023_norm)\n",
    "samples.extend(samples_2023)\n",
    "\n",
    "#features_2023_norm = [[float(i)/sum(j) for i in j ]for j in features_2023]\n",
    "samples_2023_1d = [0 if j[0] == 0 else 1 for j in samples_2023]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features_2023_norm,samples_2023_1d, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN, FP, FN, TP\n",
      "[496   1   1 426]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       497\n",
      "           1       1.00      1.00      1.00       427\n",
      "\n",
      "    accuracy                           1.00       924\n",
      "   macro avg       1.00      1.00      1.00       924\n",
      "weighted avg       1.00      1.00      1.00       924\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[114 108  85  89]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.51      0.54       222\n",
      "           1       0.45      0.51      0.48       174\n",
      "\n",
      "    accuracy                           0.51       396\n",
      "   macro avg       0.51      0.51      0.51       396\n",
      "weighted avg       0.52      0.51      0.51       396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.075, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN, FP, FN, TP\n",
      "[451  46  14 413]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       497\n",
      "           1       0.90      0.97      0.93       427\n",
      "\n",
      "    accuracy                           0.94       924\n",
      "   macro avg       0.93      0.94      0.93       924\n",
      "weighted avg       0.94      0.94      0.94       924\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[111 111  95  79]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.50      0.52       222\n",
      "           1       0.42      0.45      0.43       174\n",
      "\n",
      "    accuracy                           0.48       396\n",
      "   macro avg       0.48      0.48      0.48       396\n",
      "weighted avg       0.48      0.48      0.48       396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.0001, learning_rate='invscaling', activation='tanh', solver='adam',max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 256, 128)\n",
      "TN, FP, FN, TP\n",
      "[487  10   8 419]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       497\n",
      "           1       0.98      0.98      0.98       427\n",
      "\n",
      "    accuracy                           0.98       924\n",
      "   macro avg       0.98      0.98      0.98       924\n",
      "weighted avg       0.98      0.98      0.98       924\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[118 104  94  80]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.53      0.54       222\n",
      "           1       0.43      0.46      0.45       174\n",
      "\n",
      "    accuracy                           0.50       396\n",
      "   macro avg       0.50      0.50      0.50       396\n",
      "weighted avg       0.50      0.50      0.50       396\n",
      "\n",
      "(64, 128, 128, 64)\n",
      "TN, FP, FN, TP\n",
      "[488   9  29 398]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       497\n",
      "           1       0.98      0.93      0.95       427\n",
      "\n",
      "    accuracy                           0.96       924\n",
      "   macro avg       0.96      0.96      0.96       924\n",
      "weighted avg       0.96      0.96      0.96       924\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[132  90 101  73]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.59      0.58       222\n",
      "           1       0.45      0.42      0.43       174\n",
      "\n",
      "    accuracy                           0.52       396\n",
      "   macro avg       0.51      0.51      0.51       396\n",
      "weighted avg       0.51      0.52      0.52       396\n",
      "\n",
      "(128, 256, 256, 128)\n",
      "TN, FP, FN, TP\n",
      "[486  11  15 412]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       497\n",
      "           1       0.97      0.96      0.97       427\n",
      "\n",
      "    accuracy                           0.97       924\n",
      "   macro avg       0.97      0.97      0.97       924\n",
      "weighted avg       0.97      0.97      0.97       924\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[136  86 103  71]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59       222\n",
      "           1       0.45      0.41      0.43       174\n",
      "\n",
      "    accuracy                           0.52       396\n",
      "   macro avg       0.51      0.51      0.51       396\n",
      "weighted avg       0.52      0.52      0.52       396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arcs = [(128,256,128),(64,128,128,64),(128,256,256,128)]\n",
    "for arc in arcs:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=arc, alpha=0.0075, learning_rate_init=0.001, activation='tanh', solver='adam', epsilon=0.0000001, max_iter=10000)\n",
    "    mlp.fit(feat_train,samp_train)\n",
    "    print(arc)\n",
    "    predict_train = mlp.predict(feat_train)\n",
    "    predict_test = mlp.predict(feat_test)\n",
    "\n",
    "    print('TN, FP, FN, TP')\n",
    "    print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "    print(classification_report(samp_train,predict_train))\n",
    "    print('TN, FP, FN, TP')\n",
    "    print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "    print(classification_report(samp_test,predict_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       497\n",
      "           1       1.00      1.00      1.00       427\n",
      "\n",
      "    accuracy                           1.00       924\n",
      "   macro avg       1.00      1.00      1.00       924\n",
      "weighted avg       1.00      1.00      1.00       924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.55      0.55       222\n",
      "           1       0.41      0.40      0.40       174\n",
      "\n",
      "    accuracy                           0.48       396\n",
      "   macro avg       0.48      0.48      0.48       396\n",
      "weighted avg       0.48      0.48      0.48       396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.05, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=5000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 - 2023 NBA Seasons with Injuries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate Samples and Features for each Season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test Model and Tune Hyper Paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_1d =  [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features_norm,samples_1d, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN, FP, FN, TP\n",
      "[2715   76   67 2448]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      2791\n",
      "           1       0.97      0.97      0.97      2515\n",
      "\n",
      "    accuracy                           0.97      5306\n",
      "   macro avg       0.97      0.97      0.97      5306\n",
      "weighted avg       0.97      0.97      0.97      5306\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[571 597 588 519]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.49      0.49      1168\n",
      "           1       0.47      0.47      0.47      1107\n",
      "\n",
      "    accuracy                           0.48      2275\n",
      "   macro avg       0.48      0.48      0.48      2275\n",
      "weighted avg       0.48      0.48      0.48      2275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.0001, learning_rate_init=0.025, learning_rate='adaptive', activation='tanh', solver='adam', epsilon=0.0001, max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN, FP, FN, TP\n",
      "[2441  350 1301 1214]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.87      0.75      2791\n",
      "           1       0.78      0.48      0.60      2515\n",
      "\n",
      "    accuracy                           0.69      5306\n",
      "   macro avg       0.71      0.68      0.67      5306\n",
      "weighted avg       0.71      0.69      0.68      5306\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[824 344 788 319]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.71      0.59      1168\n",
      "           1       0.48      0.29      0.36      1107\n",
      "\n",
      "    accuracy                           0.50      2275\n",
      "   macro avg       0.50      0.50      0.48      2275\n",
      "weighted avg       0.50      0.50      0.48      2275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.0001, learning_rate_init=0.0025, learning_rate='adaptive', activation='relu', solver='adam', epsilon=0.000001, max_iter=5000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (64, 128, 48), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=10000)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(16,32,16), (32,64,32), (64,64,64), (64,128,48), (16,32,64,32,16)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05, 0.001],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(mlp,parameter_space,n_jobs=-1)\n",
    "clf.fit(feat_train,samp_train)\n",
    "\n",
    "print('Best parameters found:\\n', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 810 candidates, totalling 4050 fits\n",
      "Best parameters found:\n",
      " {'estimator': MLPClassifier(hidden_layer_sizes=(32, 64, 32), learning_rate_init=0.0001,\n",
      "              max_iter=10000, random_state=1), 'estimator__activation': 'relu', 'estimator__alpha': 0.0001, 'estimator__early_stopping': False, 'estimator__epsilon': 1e-08, 'estimator__hidden_layer_sizes': (32, 64, 32), 'estimator__learning_rate_init': 0.0001, 'estimator__max_iter': 10000, 'estimator__solver': 'adam', 'estimator__tol': 0.0001, 'scaler': StandardScaler()}\n"
     ]
    }
   ],
   "source": [
    "GRID = [\n",
    "    {'scaler': [StandardScaler()],\n",
    "     'estimator': [MLPClassifier(random_state=1)],\n",
    "     'estimator__solver': ['adam'],\n",
    "     'estimator__learning_rate_init': [0.0001],\n",
    "     'estimator__max_iter': [10000],\n",
    "     'estimator__hidden_layer_sizes': [(16,32,16), (32,64,32), (64,64,64), (64,128,48), (16,32,64,32,16)],\n",
    "     'estimator__activation': ['logistic', 'tanh', 'relu'],\n",
    "     'estimator__alpha': [0.0001, 0.001, 0.005],\n",
    "     'estimator__epsilon' : [0.001,0.00001,0.00000001],\n",
    "     'estimator__tol' : [0.01, 0.0001, 0.000001],\n",
    "     'estimator__early_stopping': [True, False]\n",
    "     }\n",
    "]\n",
    "\n",
    "PIPELINE = Pipeline([('scaler', None), ('estimator', MLPClassifier())])\n",
    "\n",
    "grid_search = GridSearchCV(estimator=PIPELINE, param_grid=GRID, \n",
    "                            scoring=make_scorer(sklearn.metrics.accuracy_score),# average='macro'), \n",
    "                            n_jobs=-1, refit=True, verbose=1, \n",
    "                            return_train_score=False)\n",
    "\n",
    "grid_search.fit(feat_train,samp_train)\n",
    "print('Best parameters found:\\n', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN, FP, FN, TP\n",
      "[2787    4   11 2504]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2791\n",
      "           1       1.00      1.00      1.00      2515\n",
      "\n",
      "    accuracy                           1.00      5306\n",
      "   macro avg       1.00      1.00      1.00      5306\n",
      "weighted avg       1.00      1.00      1.00      5306\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[593 575 602 505]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.51      0.50      1168\n",
      "           1       0.47      0.46      0.46      1107\n",
      "\n",
      "    accuracy                           0.48      2275\n",
      "   macro avg       0.48      0.48      0.48      2275\n",
      "weighted avg       0.48      0.48      0.48      2275\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,64,128,64,32), alpha=0.075, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[2637  154  182 2333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      2791\n",
      "           1       0.94      0.93      0.93      2515\n",
      "\n",
      "    accuracy                           0.94      5306\n",
      "   macro avg       0.94      0.94      0.94      5306\n",
      "weighted avg       0.94      0.94      0.94      5306\n",
      "\n",
      "TEST SET \n",
      "\n",
      "TN, FP, FN, TP\n",
      "[609 559 558 549]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.52      0.52      1168\n",
      "           1       0.50      0.50      0.50      1107\n",
      "\n",
      "    accuracy                           0.51      2275\n",
      "   macro avg       0.51      0.51      0.51      2275\n",
      "weighted avg       0.51      0.51      0.51      2275\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,64,128,64,32), alpha=0.5, learning_rate='invscaling', activation='relu', tol=0.001,solver='lbfgs',max_iter=2500)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TRAINING SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TEST SET \\n')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
