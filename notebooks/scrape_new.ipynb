{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import time\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "from util.client import Nba_Season\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "TEAM_NAME_TO_ABR = {\n",
    "        \"ATLANTA HAWKS\": 'ATL',\n",
    "        \"BOSTON CELTICS\": 'BOS',\n",
    "        \"BROOKLYN NETS\": 'BRK',\n",
    "        \"CHARLOTTE HORNETS\": 'CHO',\n",
    "        \"CHICAGO BULLS\": 'CHI',\n",
    "        \"CLEVELAND CAVALIERS\": 'CLE',\n",
    "        \"DALLAS MAVERICKS\": 'DAL',\n",
    "        \"DENVER NUGGETS\": 'DEN',\n",
    "        \"DETROIT PISTONS\": 'DET',\n",
    "        \"GOLDEN STATE WARRIORS\": 'GSW',\n",
    "        \"HOUSTON ROCKETS\": 'HOU',\n",
    "        \"INDIANA PACERS\": 'IND',\n",
    "        \"LOS ANGELES CLIPPERS\": 'LAC',\n",
    "        \"LA CLIPPERS\": 'LAC',\n",
    "        \"LOS ANGELES LAKERS\": 'LAL',\n",
    "        \"LA LAKERS\": 'LAL',\n",
    "        \"MEMPHIS GRIZZLIES\": 'MEM',\n",
    "        \"MIAMI HEAT\": 'MIA',\n",
    "        \"MILWAUKEE BUCKS\": 'MIL',\n",
    "        \"MINNESOTA TIMBERWOLVES\": 'MIN',\n",
    "        \"NEW ORLEANS PELICANS\": 'NOP',\n",
    "        \"NEW YORK KNICKS\": 'NYK',\n",
    "        \"OKLAHOMA CITY THUNDER\": 'OKC',\n",
    "        \"ORLANDO MAGIC\": 'ORL',\n",
    "        \"PHILADELPHIA 76ERS\": 'PHI',\n",
    "        \"PHOENIX SUNS\": 'PHO',\n",
    "        \"PORTLAND TRAIL BLAZERS\": 'POR',\n",
    "        \"SACRAMENTO KINGS\": 'SAC',\n",
    "        \"SAN ANTONIO SPURS\": 'SAS',\n",
    "        \"TORONTO RAPTORS\": 'TOR',\n",
    "        \"UTAH JAZZ\": 'UTA',\n",
    "        \"WASHINGTON WIZARDS\": 'WAS',\n",
    "\n",
    "        # DEPRECATED TEAMS\n",
    "        # \"CHARLOTTE BOBCATS\": 'CHA',\n",
    "        # \"KANSAS CITY KINGS\": 'KCK',\n",
    "        # \"NEW JERSEY NETS\": 'NJN',\n",
    "        # \"NEW ORLEANS HORNETS\": 'NOH',\n",
    "        # \"NEW ORLEANS/OKLAHOMA CITY HORNETS\": 'NOK',\n",
    "        # \"SEATTLE SUPERSONICS\": 'SEA',\n",
    "        # \"ST. LOUIS HAWKS\": 'STL',\n",
    "        # \"VANCOUVER GRIZZLIES\": 'VAN',\n",
    "        # \"WASHINGTON BULLETS\": 'WSB',\n",
    "    }\n",
    "\n",
    "TEAM_ABR_TO_URL = {\n",
    "        \"ATL\": 'https://www.nba.com/stats/team/1610612737',\n",
    "        \"BOS\": 'https://www.nba.com/stats/team/1610612738',\n",
    "        \"BRK\": 'https://www.nba.com/stats/team/1610612751',\n",
    "        \"CHO\": 'https://www.nba.com/stats/team/1610612766',\n",
    "        \"CHI\": 'https://www.nba.com/stats/team/1610612741',\n",
    "        \"CLE\": 'https://www.nba.com/stats/team/1610612739',\n",
    "        \"DAL\": 'https://www.nba.com/stats/team/1610612742',\n",
    "        \"DEN\": 'https://www.nba.com/stats/team/1610612743',\n",
    "        \"DET\": 'https://www.nba.com/stats/team/1610612765',\n",
    "        \"GSW\": 'https://www.nba.com/stats/team/1610612744',\n",
    "        \"HOU\": 'https://www.nba.com/stats/team/1610612745',\n",
    "        \"IND\": 'https://www.nba.com/stats/team/1610612754',\n",
    "        \"LAC\": 'https://www.nba.com/stats/team/1610612746',\n",
    "        \"LAL\": 'https://www.nba.com/stats/team/1610612747',\n",
    "        \"MEM\": 'https://www.nba.com/stats/team/1610612763',\n",
    "        \"MIA\": 'https://www.nba.com/stats/team/1610612748',\n",
    "        \"MIL\": 'https://www.nba.com/stats/team/1610612749',\n",
    "        \"MIN\": 'https://www.nba.com/stats/team/1610612750',\n",
    "        \"NOP\": 'https://www.nba.com/stats/team/1610612740',\n",
    "        \"NYK\": 'https://www.nba.com/stats/team/1610612752',\n",
    "        \"OKC\": 'https://www.nba.com/stats/team/1610612760',\n",
    "        \"ORL\": 'https://www.nba.com/stats/team/1610612753',\n",
    "        \"PHI\": 'https://www.nba.com/stats/team/1610612755',\n",
    "        \"PHO\": 'https://www.nba.com/stats/team/1610612756',\n",
    "        \"POR\": 'https://www.nba.com/stats/team/1610612757',\n",
    "        \"SAC\": 'https://www.nba.com/stats/team/1610612758',\n",
    "        \"SAS\": 'https://www.nba.com/stats/team/1610612759',\n",
    "        \"TOR\": 'https://www.nba.com/stats/team/1610612761',\n",
    "        \"UTA\": 'https://www.nba.com/stats/team/1610612762',\n",
    "        \"WAS\": 'https://www.nba.com/stats/team/1610612764',\n",
    "    }\n",
    "\n",
    "MONTH_TO_NUM = {\n",
    "        \"Jan\" : \"01\",\n",
    "        \"Feb\" : \"02\",\n",
    "        \"Mar\" : \"03\",\n",
    "        \"Apr\" : \"04\",\n",
    "        \"May\" : \"05\",\n",
    "        \"Jun\" : \"06\",\n",
    "        \"Jul\" : \"07\",\n",
    "        \"Aug\" : \"08\",\n",
    "        \"Sep\" : \"09\",\n",
    "        \"Oct\" : \"10\",\n",
    "        \"Nov\" : \"11\",\n",
    "        \"Dec\" : \"12\",\n",
    "    }\n",
    "\n",
    "ALL_TEAMS_CONC = dict.fromkeys(TEAM_ABR_TO_URL.keys()) # ABR -> dict(date -> [cum_stats,last10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map teams to NBA stats page\n",
    "Use selenium to load JS on stats page for a day, getting the last 10 and stats to date for each team in a season\n",
    "### NOTE: I was being silly, you can scrape this page: https://www.nba.com/stats/teams/advanced?SeasonType=Regular+Season&DateTo=10%2F26%2F2023 its way better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add PIE at some point?\n",
    "PIE Formula=(PTS + FGM + FTM – FGA – FTA + Deff.REB + Off.REB/2 + AST + STL + BLK/2 – PF – TO) / (Game.PTS + Game.FGM + Game.FTM – Game.FGA – Game.FTA + Game.Deff.REB + Game.Off.REB/2 + Game.AST + Game.STL + Game.BLK/2 – Game.PF – Game.TO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one deprecated for now dont use (or do idk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_thread(info):\n",
    "    '''\n",
    "    Go through list of dates and populate ALL_TEAMS_CONC\n",
    "    dates: list of dates similar to `Tue Oct 29 2013`\n",
    "    base_url: base url of NBA stats page for this team\n",
    "    abr: team abbreviation\n",
    "    RETURNS: dict mapping date -> [cum_stats, last10]\n",
    "    '''\n",
    "    dates = info[0]\n",
    "    base_url = info[1]\n",
    "    options = Options()\n",
    "    chrome_ops = webdriver.ChromeOptions()\n",
    "    chrome_ops.add_argument(\"--headless=new\")\n",
    "    options.headless = True\n",
    "    driver = webdriver.Chrome(options=options) # requires appropriate webdriver in PATH variables, or pass path to file as arg `executable_path=`\n",
    "    # driver.implicitly_wait(2)\n",
    "    wait = WebDriverWait(driver,10,0.2)\n",
    "    out_dict = defaultdict(list)\n",
    "    missing = []\n",
    "    i = 0\n",
    "    try:\n",
    "        for date in dates:\n",
    "            date_list = date.split()\n",
    "            team_stats = base_url + f'&DateTo={MONTH_TO_NUM[date_list[1]]}%2F{date_list[2]}%2F{date_list[3]}'\n",
    "            if i < 82:\n",
    "                team_stats += '&SeasonType=Regular+Season&Split=lastn'\n",
    "            else:\n",
    "                team_stats += '&SeasonType=Playoffs&Split=lastn'\n",
    "            driver.get(team_stats)\n",
    "            # load JS\n",
    "            try:\n",
    "                wait.until(EC.visibility_of_all_elements_located((By.TAG_NAME, 'td')))\n",
    "                # wait.until(EC.visibility_of_any_elements_located((By.TAG_NAME, 'table')))\n",
    "            except Exception as e:\n",
    "                # print(f'URL: {team_stats} caused exception: {e}')\n",
    "                missing.append(date)\n",
    "                continue\n",
    "            \n",
    "            html = driver.page_source\n",
    "\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            results = soup.find_all('table')\n",
    "\n",
    "            # 24 stats total from i = 1 to 24, only care about 3 - 24\n",
    "            # GP\tMIN\tPTS\tW\tL\tWIN%\tFGM\tFGA\tFG%\t3PM\t3PA\t3P%\tFTM\tFTA\tFT%\tOREB\tDREB\tREB\tAST\tTOV\tSTL\tBLK\tPF\t+/-\n",
    "            cumalitive = results[2].find_all('td') # cum stats to this point\n",
    "            cum_stats = []\n",
    "            for e in cumalitive[3:]: # only care about last ten games?\n",
    "                cum_stats.append(float(e.text))\n",
    "\n",
    "            per_n = results[3].find_all('tr') # every 10 games ranges\n",
    "            last_10 = []\n",
    "\n",
    "            # if last 10 range includes at least 5 games, use those, else use previous 10 range\n",
    "            if float(per_n[-1].find_all('td')[1].text) >= 5 or i < 10 or len(per_n) < 2:\n",
    "                for e in per_n[-1].find_all('td')[3:]:\n",
    "                    last_10.append(float(e.text))\n",
    "                \n",
    "            else:\n",
    "                for e in per_n[-2].find_all('td')[3:]:\n",
    "                    last_10.append(float(e.text))\n",
    "\n",
    "            out_dict[date].append(cum_stats)\n",
    "            out_dict[date].append(last_10)\n",
    "            i += 1\n",
    "    except Exception as e:\n",
    "        driver.quit()\n",
    "        print(e)\n",
    "        return info[2],out_dict,missing\n",
    "    print(f'Data for: {info[2]} complete, Captured: {len(out_dict)}, Missing: {len(missing)}')\n",
    "    driver.quit()\n",
    "    return info[2],out_dict,missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to call from a ThreadPoolExecutor (if using in a notebook), can called from ProcessPoolExecutor as well (must called from __main__ in an actual Python file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add batch size parameter/fix pooling \n",
    "def get_stats_multi_win(info):\n",
    "    '''\n",
    "    Go through list of dates and populate ALL_TEAMS_CONC\n",
    "    dates: list of dates similar to `Tue Oct 29 2013`\n",
    "    base_url: base url of NBA stats page for this team\n",
    "    abr: team abbreviation\n",
    "    RETURNS: dict mapping date -> [cum_stats, last10]\n",
    "    '''\n",
    "    dates = info[0]\n",
    "    base_url = info[1]\n",
    "    options = Options()\n",
    "    chrome_ops = webdriver.ChromeOptions()\n",
    "    chrome_ops.add_argument(\"--headless=new\")\n",
    "    options.headless = True\n",
    "    driver = webdriver.Chrome(options=options) # requires appropriate webdriver in PATH variables, or pass path to file as arg `executable_path=`\n",
    "    out_dict = defaultdict(list)\n",
    "    missing = []\n",
    "\n",
    "    try:\n",
    "        for i in range(4,len(dates),5): # change range step to control how many tabs are opened in a batch, current set to 5\n",
    "            date_list = []\n",
    "            k = 0\n",
    "            for j in range(i-4,i+1):\n",
    "                curr_date = dates[j].split()\n",
    "                date_list.append(dates[j])\n",
    "                team_stats = base_url + f'&DateTo={MONTH_TO_NUM[curr_date[1]]}%2F{curr_date[2]}%2F{curr_date[3]}&Split=lastn'\n",
    "                if j < 82:\n",
    "                    team_stats += '&SeasonType=Regular+Season'\n",
    "                else:\n",
    "                    team_stats += '&SeasonType=Playoffs'\n",
    "                driver.get(team_stats)\n",
    "                k += 1\n",
    "                if k < 5: # change range step to control how many tabs are opened in a batch, current set to 5\n",
    "                    driver.execute_script(\"window.open()\")\n",
    "                    driver.switch_to.window(driver.window_handles[k])\n",
    "            \n",
    "            window_list = driver.window_handles\n",
    "            k = 0\n",
    "            # load JS\n",
    "            time.sleep(2)\n",
    "            for window in window_list:\n",
    "                date = date_list[k]\n",
    "                k += 1\n",
    "                driver.switch_to.window(window)\n",
    "                html = driver.page_source\n",
    "\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                results = soup.find_all('table')\n",
    "\n",
    "                try:\n",
    "                    # 24 stats total from i = 1 to 24, only care about 3 - 24\n",
    "                    # GP\tMIN\tPTS\tW\tL\tWIN%\tFGM\tFGA\tFG%\t3PM\t3PA\t3P%\tFTM\tFTA\tFT%\tOREB\tDREB\tREB\tAST\tTOV\tSTL\tBLK\tPF\t+/-\n",
    "                    cumalitive = results[2].find_all('td') # cum stats to this point\n",
    "                    cum_stats = []\n",
    "                    for e in cumalitive[3:]: # only care about last ten games?\n",
    "                        cum_stats.append(float(e.text))\n",
    "\n",
    "                    per_n = results[3].find_all('tr') # every 10 games ranges\n",
    "                    last_10 = []\n",
    "\n",
    "                    # if last 10 range includes at least 5 games, use those, else use previous 10 range\n",
    "                    if float(per_n[-1].find_all('td')[1].text) >= 5 or i < 10 or len(per_n) < 2:\n",
    "                        for e in per_n[-1].find_all('td')[3:]:\n",
    "                            last_10.append(float(e.text))\n",
    "                        \n",
    "                    else:\n",
    "                        for e in per_n[-2].find_all('td')[3:]:\n",
    "                            last_10.append(float(e.text))\n",
    "\n",
    "                    out_dict[date].append(cum_stats)\n",
    "                    out_dict[date].append(last_10)\n",
    "                except:\n",
    "                    missing.append(date)\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "        \n",
    "        date_list = []\n",
    "        k = 0\n",
    "        remaining = len(dates) % 5\n",
    "        if remaining > 0:\n",
    "            for i in range(len(dates) - remaining, len(dates)):\n",
    "                curr_date = dates[i].split()\n",
    "                date_list.append(dates[i])\n",
    "                team_stats = base_url + f'&DateTo={MONTH_TO_NUM[curr_date[1]]}%2F{curr_date[2]}%2F{curr_date[3]}&Split=lastn'\n",
    "                if i < 82:\n",
    "                    team_stats += '&SeasonType=Regular+Season'\n",
    "                else:\n",
    "                    team_stats += '&SeasonType=Playoffs'\n",
    "                driver.get(team_stats)\n",
    "                k += 1\n",
    "                if k < remaining:\n",
    "                    driver.execute_script(\"window.open()\")\n",
    "                    driver.switch_to.window(driver.window_handles[k])\n",
    "\n",
    "            \n",
    "            window_list = driver.window_handles\n",
    "            k = 0\n",
    "            # load JS\n",
    "            time.sleep(2)\n",
    "            for window in window_list:\n",
    "                date = date_list[k]\n",
    "                k += 1\n",
    "                driver.switch_to.window(window)\n",
    "                html = driver.page_source\n",
    "\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                results = soup.find_all('table')\n",
    "\n",
    "                try:\n",
    "                    # 24 stats total from i = 1 to 24, only care about 3 - 24\n",
    "                    # GP\tMIN\tPTS\tW\tL\tWIN%\tFGM\tFGA\tFG%\t3PM\t3PA\t3P%\tFTM\tFTA\tFT%\tOREB\tDREB\tREB\tAST\tTOV\tSTL\tBLK\tPF\t+/-\n",
    "                    cumalitive = results[2].find_all('td') # cum stats to this point\n",
    "                    cum_stats = []\n",
    "                    for e in cumalitive[3:]: # only care about last ten games?\n",
    "                        cum_stats.append(float(e.text))\n",
    "\n",
    "                    per_n = results[3].find_all('tr') # every 10 games ranges\n",
    "                    last_10 = []\n",
    "\n",
    "                    # if last 10 range includes at least 5 games, use those, else use previous 10 range\n",
    "                    if float(per_n[-1].find_all('td')[1].text) >= 5 or i < 10 or len(per_n) < 2:\n",
    "                        for e in per_n[-1].find_all('td')[3:]:\n",
    "                            last_10.append(float(e.text))\n",
    "                        \n",
    "                    else:\n",
    "                        for e in per_n[-2].find_all('td')[3:]:\n",
    "                            last_10.append(float(e.text))\n",
    "\n",
    "                    out_dict[date].append(cum_stats)\n",
    "                    out_dict[date].append(last_10)\n",
    "                except:\n",
    "                    missing.append(date)\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        driver.quit()\n",
    "        print(f'Data for: {info[2]} complete, Captured: {len(out_dict)}, Missing: {len(missing)}, Error: {e}')\n",
    "        return info[2],out_dict,missing\n",
    "    \n",
    "    print(f'Data for: {info[2]} complete, Captured: {len(out_dict)}, Missing: {len(missing)}')\n",
    "    driver.quit()\n",
    "    return info[2],out_dict,missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: using multiple threads/processes can put a strain on your system, its also hard to close when it starts running!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "import concurrent.futures\n",
    "\n",
    "def test_this(games_df,szn):\n",
    "    start_date = games_df['date'][0].split()\n",
    "    teams = []\n",
    "\n",
    "    # Generate list of URLS for each team\n",
    "    for team, abr in TEAM_NAME_TO_ABR.items():\n",
    "        team_games = games_df.loc[(games_df['away'].str.upper() == team) | (games_df['home'].str.upper() == team)]\n",
    "        dates = team_games['date'].to_list()\n",
    "        url = TEAM_ABR_TO_URL[abr] + f'/traditional?Season={szn}&DateFrom={MONTH_TO_NUM[start_date[1]]}%2F{start_date[2]}%2F{start_date[3]}'\n",
    "        teams.append([dates,url,abr])\n",
    "        \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        results = list(executor.map(get_stats_multi_win,teams))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for: CHO complete, Captured: 82, Missing: 1\n",
      "Data for: BOS complete, Captured: 106, Missing: 0\n",
      "Data for: ATL complete, Captured: 87, Missing: 2\n",
      "Data for: BRK complete, Captured: 86, Missing: 1\n",
      "Data for: CHI complete, Captured: 87, Missing: 0\n",
      "Data for: CLE complete, Captured: 82, Missing: 2\n",
      "Data for: DET complete, Captured: 82, Missing: 0\n",
      "Data for: DEN complete, Captured: 86, Missing: 1\n",
      "list index out of range\n",
      "Data for: GSW complete, Captured: 104, Missing: 0\n",
      "Data for: HOU complete, Captured: 82, Missing: 0\n",
      "Data for: IND complete, Captured: 82, Missing: 0\n",
      "Data for: LAC complete, Captured: 82, Missing: 2\n",
      "Data for: LAL complete, Captured: 82, Missing: 0\n",
      "Data for: MEM complete, Captured: 94, Missing: 0\n",
      "list index out of range\n",
      "Data for: MIL complete, Captured: 94, Missing: 0\n",
      "Data for: MIN complete, Captured: 87, Missing: 2\n",
      "list index out of range\n",
      "Data for: NYK complete, Captured: 82, Missing: 0\n",
      "Data for: OKC complete, Captured: 82, Missing: 0\n",
      "Data for: ORL complete, Captured: 81, Missing: 1\n",
      "Data for: POR complete, Captured: 81, Missing: 1\n",
      "Data for: PHI complete, Captured: 94, Missing: 0\n",
      "list index out of range\n",
      "Data for: SAC complete, Captured: 82, Missing: 0\n",
      "Data for: SAS complete, Captured: 82, Missing: 1\n",
      "Data for: TOR complete, Captured: 88, Missing: 0\n",
      "Data for: WAS complete, Captured: 82, Missing: 0\n",
      "Data for: UTA complete, Captured: 87, Missing: 1\n"
     ]
    }
   ],
   "source": [
    "games_df = pd.read_csv('../NBA/games/2021-2022_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "results = test_this(games_df,'2021-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TEAMS_CONC = dict.fromkeys(TEAM_ABR_TO_URL.keys()) # ABR -> dict(date -> [cum_stats,last10])\n",
    "\n",
    "for r in results:\n",
    "        ALL_TEAMS_CONC[r[0]] = r[1]\n",
    "        ALL_TEAMS_CONC[r[0]][\"MISSED\"] = r[2]\n",
    "    \n",
    "with open('../NBA/conc_stats/2021-2022_conc_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(ALL_TEAMS_CONC,f)\n",
    "\n",
    "# with open('../NBA/conc_stats/2023-2024_conc_stats.pkl', 'rb') as f:\n",
    "#     save_me = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all missing dates are included in \"MISSED\" key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "with open('../NBA/conc_stats/2023-2024_conc_stats.pkl', 'rb') as f:\n",
    "    conc_2024 = pickle.load(f)\n",
    "\n",
    "games_df = pd.read_csv('../NBA/games/2023-2024_nba_season.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "\n",
    "def check_missed(conc_stats,games_df):\n",
    "    unknown_misses = [] # store missed dates that are not in missed key\n",
    "    for team, abr in TEAM_NAME_TO_ABR.items():\n",
    "        team_games = games_df.loc[(games_df['away'].str.upper() == team) | (games_df['home'].str.upper() == team)]\n",
    "        dates = team_games['date'].to_list()\n",
    "        missing_counted = set(conc_stats[abr]['MISSED'])\n",
    "        for date in dates:\n",
    "            if date not in conc_stats[abr] and date not in missing_counted:\n",
    "                unknown_misses.append(date)\n",
    "    return unknown_misses\n",
    "\n",
    "uk_miss = check_missed(conc_2024,games_df)\n",
    "print(len(uk_miss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing(info):\n",
    "    '''\n",
    "    Function to retry missing dates\n",
    "    expects list with args:\n",
    "    [dates,base_url,abr,reg_szn_end,play_in_end]\n",
    "    reg_szn_end: date of final regular season game\n",
    "    play_in_end: date of final play in game (empty if no play in)\n",
    "    returns a dict mapping dates to stats\n",
    "    '''\n",
    "    dates = info[0]\n",
    "    base_url = info[1]\n",
    "    reg_szn_end = info[3]\n",
    "    play_in_end = info[4]\n",
    "    options = Options()\n",
    "    driver = webdriver.Chrome(options=options) # requires appropriate webdriver in PATH variables, or pass path to file as arg `executable_path=`\n",
    "    out_dict = defaultdict(list)\n",
    "    missing = []\n",
    "\n",
    "    try:\n",
    "        for i in range(len(dates)):\n",
    "            date_list = []\n",
    "            curr_date = dates[i].split()\n",
    "            date_list.append(dates[i])\n",
    "            team_stats = base_url + f'&DateTo={MONTH_TO_NUM[curr_date[1]]}%2F{curr_date[2]}%2F{curr_date[3]}&Split=lastn'\n",
    "\n",
    "            if curr_date[3] < reg_szn_end[3] or (MONTH_TO_NUM[curr_date[1]] <= reg_szn_end[1] and curr_date[2] <= reg_szn_end[2]): # reg szn tourny??\n",
    "                team_stats += '&SeasonType=Regular+Season'\n",
    "            elif len(play_in_end) > 0 and curr_date[1] <= play_in_end[1] and curr_date[2] <= play_in_end[2]:\n",
    "                team_stats += '&SeasonType=PlayIn'\n",
    "            else:\n",
    "                team_stats += '&SeasonType=Playoffs'\n",
    "\n",
    "            driver.get(team_stats)\n",
    "\n",
    "            if i < len(dates) - 1: # change range step to control how many tabs are opened in a batch, current set to 5\n",
    "                driver.execute_script(\"window.open()\")\n",
    "                driver.switch_to.window(driver.window_handles[k])\n",
    "            \n",
    "            window_list = driver.window_handles\n",
    "            k = 0\n",
    "            # load JS\n",
    "            time.sleep(5)\n",
    "            for window in window_list:\n",
    "                date = date_list[k]\n",
    "                k += 1\n",
    "                driver.switch_to.window(window)\n",
    "                html = driver.page_source\n",
    "\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                results = soup.find_all('table')\n",
    "\n",
    "                try:\n",
    "                    # 24 stats total from i = 1 to 24, only care about 3 - 24\n",
    "                    # GP\tMIN\tPTS\tW\tL\tWIN%\tFGM\tFGA\tFG%\t3PM\t3PA\t3P%\tFTM\tFTA\tFT%\tOREB\tDREB\tREB\tAST\tTOV\tSTL\tBLK\tPF\t+/-\n",
    "                    cumalitive = results[2].find_all('td') # cum stats to this point\n",
    "                    cum_stats = []\n",
    "                    for e in cumalitive[3:]: # only care about last ten games?\n",
    "                        cum_stats.append(float(e.text))\n",
    "\n",
    "                    per_n = results[3].find_all('tr') # every 10 games ranges\n",
    "                    last_10 = []\n",
    "\n",
    "                    # if last 10 range includes at least 5 games, use those, else use previous 10 range\n",
    "                    if float(per_n[-1].find_all('td')[1].text) >= 5 or i < 10 or len(per_n) < 2:\n",
    "                        for e in per_n[-1].find_all('td')[3:]:\n",
    "                            last_10.append(float(e.text))\n",
    "                        \n",
    "                    else:\n",
    "                        for e in per_n[-2].find_all('td')[3:]:\n",
    "                            last_10.append(float(e.text))\n",
    "\n",
    "                    out_dict[date].append(cum_stats)\n",
    "                    out_dict[date].append(last_10)\n",
    "                except:\n",
    "                    missing.append(date)\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        driver.quit()\n",
    "        print(f'Data for: {info[2]} complete, Captured: {len(out_dict)}, Missing: {len(missing)}, Error: {e}')\n",
    "        return info[2],out_dict,missing\n",
    "    \n",
    "    print(f'Data for: {info[2]} complete, Captured: {len(out_dict)}, Missing: {len(missing)}')\n",
    "    driver.quit()\n",
    "    return info[2],out_dict,missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "import concurrent.futures\n",
    "\n",
    "def retry_missing(games_df,conc_stats,szn,reg_szn_end,play_in_end):\n",
    "    start_date = games_df['date'][0].split()\n",
    "    teams = []\n",
    "\n",
    "    # Generate list of URLS for each team\n",
    "    for team, abr in TEAM_NAME_TO_ABR.items():\n",
    "        missing = conc_stats[abr]['MISSED']\n",
    "        if len(missing) == 0:\n",
    "            continue\n",
    "        url = TEAM_ABR_TO_URL[abr] + f'/traditional?Season={szn}&DateFrom={MONTH_TO_NUM[start_date[1]]}%2F{start_date[2]}%2F{start_date[3]}'\n",
    "        teams.append([missing,url,abr,reg_szn_end,play_in_end])\n",
    "        \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        results = list(executor.map(get_stats_multi_win,teams))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for: WAS complete, Captured: 1, Missing: 0\n",
      "Data for: CHI complete, Captured: 2, Missing: 0\n",
      "Data for: PHO complete, Captured: 2, Missing: 0\n",
      "Data for: UTA complete, Captured: 2, Missing: 0\n",
      "Data for: NYK complete, Captured: 2, Missing: 0\n",
      "Data for: GSW complete, Captured: 2, Missing: 0\n",
      "Data for: NYK complete, Captured: 2, Missing: 0\n",
      "Data for: POR complete, Captured: 3, Missing: 0\n",
      "Data for: WAS complete, Captured: 2, Missing: 0\n",
      "Data for: DAL complete, Captured: 1, Missing: 0\n",
      "Data for: DEN complete, Captured: 3, Missing: 0\n"
     ]
    }
   ],
   "source": [
    "with open('../NBA/conc_stats/2022-2023_conc_stats.pkl', 'rb') as f:\n",
    "    conc_2023 = pickle.load(f)\n",
    "\n",
    "games_df_2023 = pd.read_csv('../NBA/games/2022-2023_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "\n",
    "reg_szn_end_2023 = [\"\",\"04\",\"9\",\"2023\"]\n",
    "play_in_end_2023 = [\"\",\"04\",\"14\",\"2023\"]\n",
    "\n",
    "res_2023 = retry_missing(games_df_2023,conc_2023,'2022-23',reg_szn_end_2023,play_in_end_2023)\n",
    "\n",
    "with open('../NBA/conc_stats/2021-2022_conc_stats.pkl', 'rb') as f:\n",
    "    conc_2022 = pickle.load(f)\n",
    "\n",
    "games_df_2022 = pd.read_csv('../NBA/games/2021-2022_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "\n",
    "reg_szn_end_2022 = [\"\",\"04\",\"10\",\"2022\"]\n",
    "play_in_end_2022 = [\"\",\"04\",\"15\",\"2022\"]\n",
    "\n",
    "res_2022 = retry_missing(games_df_2022,conc_2022,'2021-22',reg_szn_end_2022,play_in_end_2022)\n",
    "\n",
    "with open('../NBA/conc_stats/2020-2021_conc_stats.pkl', 'rb') as f:\n",
    "    conc_2021 = pickle.load(f)\n",
    "\n",
    "games_df_2021 = pd.read_csv('../NBA/games/2020-2021_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "\n",
    "reg_szn_end_2021 = [\"\",\"05\",\"16\",\"2021\"]\n",
    "play_in_end_2021 = [\"\",\"05\",\"21\",\"2021\"]\n",
    "\n",
    "res_2021 = retry_missing(games_df_2021,conc_2021,'2020-21',reg_szn_end_2021,play_in_end_2021)\n",
    "\n",
    "with open('../NBA/conc_stats/2019-2020_conc_stats.pkl', 'rb') as f:\n",
    "    conc_2020 = pickle.load(f)\n",
    "\n",
    "games_df_2020 = pd.read_csv('../NBA/games/2019-2020_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "\n",
    "reg_szn_end_2020 = [\"\",\"08\",\"14\",\"2020\"]\n",
    "play_in_end_2020 = [\"\",\"08\",\"15\",\"2020\"]\n",
    "\n",
    "res_2020 = retry_missing(games_df_2020,conc_2020,'2019-20',reg_szn_end_2020,play_in_end_2020)\n",
    "\n",
    "with open('../NBA/conc_stats/2018-2019_conc_stats.pkl', 'rb') as f:\n",
    "    conc_2019 = pickle.load(f)\n",
    "\n",
    "games_df_2019 = pd.read_csv('../NBA/games/2018-2019_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "\n",
    "reg_szn_end_2019 = [\"\",\"04\",\"10\",\"2019\"]\n",
    "play_in_end_2019 = []\n",
    "\n",
    "res_2019 = retry_missing(games_df_2019,conc_2019,'2018-19',reg_szn_end_2019,play_in_end_2019)\n",
    "\n",
    "with open('../NBA/conc_stats/2017-2018_conc_stats.pkl', 'rb') as f:\n",
    "    conc_2018 = pickle.load(f)\n",
    "\n",
    "games_df_2018 = pd.read_csv('../NBA/games/2017-2018_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "\n",
    "reg_szn_end_2018 = [\"\",\"04\",\"11\",\"2018\"]\n",
    "play_in_end_2018 = []\n",
    "\n",
    "res_2018 = retry_missing(games_df_2018,conc_2018,'2017-18',reg_szn_end_2018,play_in_end_2018)\n",
    "\n",
    "with open('../NBA/conc_stats/2016-2017_conc_stats.pkl', 'rb') as f:\n",
    "    conc_2017 = pickle.load(f)\n",
    "\n",
    "games_df_2017 = pd.read_csv('../NBA/games/2016-2017_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "\n",
    "reg_szn_end_2017 = [\"\",\"04\",\"12\",\"2017\"]\n",
    "play_in_end_2017 = []\n",
    "\n",
    "res_2017 = retry_missing(games_df_2017,conc_2017,'2016-17',reg_szn_end_2017,play_in_end_2017)\n",
    "\n",
    "# MISSED\n",
    "# res_2022 = retry_missing(games_df,conc_2022,'2022-23',reg_szn_end_2023,play_in_end_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = [[res_2017,conc_2017],[res_2018,conc_2018],[res_2019,conc_2019],[res_2020,conc_2020],[res_2021,conc_2021],[res_2022,conc_2022],[res_2023,conc_2023]]\n",
    "for res,conc in res_list:\n",
    "    for r in res:\n",
    "        if len(r[1]) != len(conc[r[0]]['MISSED']): # make sure we got all missing\n",
    "            print(r[1])\n",
    "            continue\n",
    "        conc[r[0]]['MISSED'] = []\n",
    "        for d,f in r[1].items():\n",
    "            conc[r[0]][d] = f\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../NBA/conc_stats/2022-2023_conc_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(conc_2023,f)\n",
    "\n",
    "with open('../NBA/conc_stats/2021-2022_conc_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(conc_2022,f)\n",
    "\n",
    "with open('../NBA/conc_stats/2020-2021_conc_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(conc_2021,f)\n",
    "\n",
    "with open('../NBA/conc_stats/2019-2020_conc_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(conc_2020,f)\n",
    "    \n",
    "with open('../NBA/conc_stats/2018-2019_conc_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(conc_2019,f)\n",
    "\n",
    "with open('../NBA/conc_stats/2017-2018_conc_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(conc_2018,f)\n",
    "\n",
    "with open('../NBA/conc_stats/2016-2017_conc_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(conc_2017,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "check_list = [[games_df_2017,conc_2017],[games_df_2018,conc_2018],[games_df_2019,conc_2019],[games_df_2020,conc_2020],[games_df_2021,conc_2021],[games_df_2022,conc_2022],[games_df_2023,conc_2023]]\n",
    "for games,conc in check_list:\n",
    "    uk_miss = check_missed(conc,games)\n",
    "    print(len(uk_miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in res:\n",
    "    if len(r[1]) != len(conc_2024[r[0]]['MISSED']): # make sure we got all missing\n",
    "        print(r[1])\n",
    "        continue\n",
    "    conc_2024[r[0]]['MISSED'] = []\n",
    "    for d,f in r[1].items():\n",
    "        conc_2024[r[0]][d] = f\n",
    "    \n",
    "# with open('../NBA/conc_stats/2023-2024_conc_stats.pkl', 'wb') as f:\n",
    "#     pickle.dump(conc_2024,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../NBA/conc_stats/2022-2023_conc_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(conc_2024,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# TODO: add batch size parameter/fix pooling \n",
    "def get_adv_stats(info):\n",
    "    '''\n",
    "    Gets cumulative advanced stats for a given season, NOT INCLUDING LAST 10\n",
    "    input: [dates,url,abr,reg_szn_end,play_in_end]\n",
    "    RETURNS: dict mapping date -> [abr,adv_stats]\n",
    "    '''\n",
    "    dates = info[0]\n",
    "    base_url = info[1]\n",
    "    reg_szn_end = info[3]\n",
    "    play_in_end = info[4]\n",
    "    reg_szn_end_dt = datetime.datetime(int(reg_szn_end[3]),int(reg_szn_end[1]),int(reg_szn_end[2]))\n",
    "    if len(play_in_end) > 0:\n",
    "        play_in_end_dt = datetime.datetime(int(play_in_end[3]),int(play_in_end[1]),int(play_in_end[2]))\n",
    "\n",
    "    options = Options()\n",
    "    driver = webdriver.Chrome(options=options) # requires appropriate webdriver in PATH variables, or pass path to file as arg `executable_path=`\n",
    "    # teams_dict = info[2]\n",
    "    out_dict = defaultdict(list) # map date -> [abr,adv_stats]\n",
    "    missing = []\n",
    "\n",
    "    try:\n",
    "        for i in range(4,len(dates),5): # change range step to control how many tabs are opened in a batch, current set to 5\n",
    "            date_list = []\n",
    "            k = 0\n",
    "            for j in range(i-4,i+1):\n",
    "                curr_date = dates[j].split()\n",
    "                date_list.append(dates[j])\n",
    "                team_stats = base_url + f'&DateTo={MONTH_TO_NUM[curr_date[1]]}%2F{curr_date[2]}%2F{curr_date[3]}'\n",
    "\n",
    "                curr_date_dt = datetime.datetime(int(curr_date[3]),int(MONTH_TO_NUM[curr_date[1]]),int(curr_date[2]))\n",
    "\n",
    "                if curr_date_dt <= reg_szn_end_dt:\n",
    "                    team_stats += '&SeasonType=Regular+Season'\n",
    "                elif len(play_in_end) > 0 and curr_date_dt <= play_in_end_dt:\n",
    "                    team_stats += '&SeasonType=PlayIn'\n",
    "                else:\n",
    "                    team_stats += '&SeasonType=Playoffs'\n",
    "\n",
    "                driver.get(team_stats)\n",
    "                k += 1\n",
    "                if k < 5: # change range step to control how many tabs are opened in a batch, current set to 10\n",
    "                    driver.execute_script(\"window.open()\")\n",
    "                    driver.switch_to.window(driver.window_handles[k])\n",
    "            \n",
    "            window_list = driver.window_handles\n",
    "            k = 0\n",
    "            # load JS\n",
    "            time.sleep(2)\n",
    "            for window in window_list:\n",
    "                date = date_list[k]\n",
    "                k += 1\n",
    "                driver.switch_to.window(window)\n",
    "                html = driver.page_source\n",
    "\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                results = soup.find_all('table')\n",
    "\n",
    "                try:\n",
    "                    teams = results[2].find_all('tr')\n",
    "                    for team in teams[1:]:\n",
    "                        # rank \tTEAM\tGP\tW\tL\tMIN\tOFFRTG\tDEFRTG\tNETRTG\tAST%\tAST/TO\tASTRATIO\tOREB%\tDREB%\tREB%\tTOV%\tEFG%\tTS%\tPACE\tPIE\tPOS\n",
    "                        # [6:20]\n",
    "                        adv = []\n",
    "                        stats = team.find_all('td')\n",
    "                        abr = TEAM_NAME_TO_ABR[stats[1].text.upper()]\n",
    "                        for e in stats[6:20]:\n",
    "                            adv.append(float(e.text))\n",
    "\n",
    "                        out_dict[date].append([abr,adv])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'Exception: {e} for team: {abr} on link: {team_stats}')\n",
    "                    missing.append(date)\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "        \n",
    "        date_list = []\n",
    "        k = 0\n",
    "        remaining = len(dates) % 5\n",
    "        if remaining > 0:\n",
    "            for i in range(len(dates) - remaining, len(dates)):\n",
    "                curr_date = dates[i].split()\n",
    "                date_list.append(dates[i])\n",
    "                team_stats = base_url + f'&DateTo={MONTH_TO_NUM[curr_date[1]]}%2F{curr_date[2]}%2F{curr_date[3]}'\n",
    "\n",
    "                curr_date_dt = datetime.datetime(int(curr_date[3]),int(MONTH_TO_NUM[curr_date[1]]),int(curr_date[2]))\n",
    "\n",
    "                if curr_date_dt <= reg_szn_end_dt:\n",
    "                    team_stats += '&SeasonType=Regular+Season'\n",
    "                elif len(play_in_end) > 0 and curr_date_dt <= play_in_end_dt:\n",
    "                    team_stats += '&SeasonType=PlayIn'\n",
    "                else:\n",
    "                    team_stats += '&SeasonType=Playoffs'\n",
    "\n",
    "                driver.get(team_stats)\n",
    "                k += 1\n",
    "                if k < remaining:\n",
    "                    driver.execute_script(\"window.open()\")\n",
    "                    driver.switch_to.window(driver.window_handles[k])\n",
    "\n",
    "            \n",
    "            window_list = driver.window_handles\n",
    "            k = 0\n",
    "            # load JS\n",
    "            time.sleep(2)\n",
    "            for window in window_list:\n",
    "                date = date_list[k]\n",
    "                k += 1\n",
    "                driver.switch_to.window(window)\n",
    "                html = driver.page_source\n",
    "\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                results = soup.find_all('table')\n",
    "\n",
    "                try:\n",
    "                    teams = results[2].find_all('tr')\n",
    "                    for team in teams[1:]:\n",
    "                        # rank \tTEAM\tGP\tW\tL\tMIN\tOFFRTG\tDEFRTG\tNETRTG\tAST%\tAST/TO\tASTRATIO\tOREB%\tDREB%\tREB%\tTOV%\tEFG%\tTS%\tPACE\tPIE\tPOS\n",
    "                        # [6:20]\n",
    "                        adv = []\n",
    "                        stats = team.find_all('td')\n",
    "                        abr = TEAM_NAME_TO_ABR[stats[1].text.upper()]\n",
    "                        for e in stats[6:20]:\n",
    "                            adv.append(float(e.text))\n",
    "\n",
    "                        out_dict[date].append([abr,adv])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'Exception: {e} for team: {abr} on link: {team_stats}')\n",
    "                    missing.append(date)\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        driver.quit()\n",
    "        print(f'Captured: {len(out_dict)}, Missing: {len(missing)}, Error: {e}')\n",
    "        return out_dict,missing\n",
    "    \n",
    "    print(f'Captured: {len(out_dict)}, Missing: {len(missing)}')\n",
    "    driver.quit()\n",
    "    return out_dict,missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "import concurrent.futures\n",
    "\n",
    "def get_adv_pool(df_list,szn,reg_szn_end,play_in_end):\n",
    "    pack = []\n",
    "    for i in range(len(df_list)):\n",
    "        start_date = df_list[i]['date'][0].split()\n",
    "        dates = df_list[i]['date'].unique() # Get unique dates as list\n",
    "        pack.append([dates,f'https://www.nba.com/stats/teams/advanced?Season={szn[i]}&DateFrom={MONTH_TO_NUM[start_date[1]]}%2F{start_date[2]}%2F{start_date[3]}','',reg_szn_end[i],play_in_end[i]])\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        results = list(executor.map(get_adv_stats,pack))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "szn_list = []\n",
    "reg_szn_list = []\n",
    "play_in_list = []\n",
    "\n",
    "games_df_2024 = pd.read_csv('../NBA/games/2023-2024_nba_season.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "reg_szn_end_2024 = [\"\",\"04\",\"14\",\"2024\"]\n",
    "play_in_end_2024 = [\"\",\"04\",\"19\",\"2024\"]\n",
    "\n",
    "df_list.append(games_df_2024)\n",
    "reg_szn_list.append(reg_szn_end_2024)\n",
    "play_in_list.append(play_in_end_2024)\n",
    "szn_list.append('2023-24')\n",
    "\n",
    "games_df_2023 = pd.read_csv('../NBA/games/2022-2023_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "reg_szn_end_2023 = [\"\",\"04\",\"9\",\"2023\"]\n",
    "play_in_end_2023 = [\"\",\"04\",\"14\",\"2023\"]\n",
    "\n",
    "df_list.append(games_df_2023)\n",
    "reg_szn_list.append(reg_szn_end_2023)\n",
    "play_in_list.append(play_in_end_2023)\n",
    "szn_list.append('2022-23')\n",
    "\n",
    "games_df_2022 = pd.read_csv('../NBA/games/2021-2022_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "reg_szn_end_2022 = [\"\",\"04\",\"10\",\"2022\"]\n",
    "play_in_end_2022 = [\"\",\"04\",\"15\",\"2022\"]\n",
    "\n",
    "df_list.append(games_df_2022)\n",
    "reg_szn_list.append(reg_szn_end_2022)\n",
    "play_in_list.append(play_in_end_2022)\n",
    "szn_list.append('2021-22')\n",
    "\n",
    "games_df_2021 = pd.read_csv('../NBA/games/2020-2021_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "reg_szn_end_2021 = [\"\",\"05\",\"16\",\"2021\"]\n",
    "play_in_end_2021 = [\"\",\"05\",\"21\",\"2021\"]\n",
    "\n",
    "df_list.append(games_df_2021)\n",
    "reg_szn_list.append(reg_szn_end_2021)\n",
    "play_in_list.append(play_in_end_2021)\n",
    "szn_list.append('2020-21')\n",
    "\n",
    "games_df_2020 = pd.read_csv('../NBA/games/2019-2020_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "reg_szn_end_2020 = [\"\",\"08\",\"14\",\"2020\"]\n",
    "play_in_end_2020 = [\"\",\"08\",\"15\",\"2020\"]\n",
    "\n",
    "df_list.append(games_df_2020)\n",
    "reg_szn_list.append(reg_szn_end_2020)\n",
    "play_in_list.append(play_in_end_2020)\n",
    "szn_list.append('2019-20')\n",
    "\n",
    "games_df_2019 = pd.read_csv('../NBA/games/2018-2019_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "reg_szn_end_2019 = [\"\",\"04\",\"10\",\"2019\"]\n",
    "play_in_end_2019 = []\n",
    "\n",
    "df_list.append(games_df_2019)\n",
    "reg_szn_list.append(reg_szn_end_2019)\n",
    "play_in_list.append(play_in_end_2019)\n",
    "szn_list.append('2018-19')\n",
    "\n",
    "games_df_2018 = pd.read_csv('../NBA/games/2017-2018_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "reg_szn_end_2018 = [\"\",\"04\",\"11\",\"2018\"]\n",
    "play_in_end_2018 = []\n",
    "\n",
    "df_list.append(games_df_2018)\n",
    "reg_szn_list.append(reg_szn_end_2018)\n",
    "play_in_list.append(play_in_end_2018)\n",
    "szn_list.append('2017-18')\n",
    "\n",
    "games_df_2017 = pd.read_csv('../NBA/games/2016-2017_season_inj.csv',sep=',',names=['date','away','away_pt','home','home_pt'])\n",
    "reg_szn_end_2017 = [\"\",\"04\",\"12\",\"2017\"]\n",
    "play_in_end_2017 = []\n",
    "\n",
    "df_list.append(games_df_2017)\n",
    "reg_szn_list.append(reg_szn_end_2017)\n",
    "play_in_list.append(play_in_end_2017)\n",
    "szn_list.append('2016-17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured: 212, Missing: 0\n"
     ]
    }
   ],
   "source": [
    "res = get_adv_pool([games_df_2023],['2022-23'],[reg_szn_end_2023],[play_in_end_2023])\n",
    "res_2023 = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured: 212, Missing: 0\n",
      "Captured: 193, Missing: 0\n",
      "Captured: 204, Missing: 0\n",
      "Captured: 203, Missing: 0\n",
      "Captured: 213, Missing: 0\n",
      "Captured: 191, Missing: 0\n",
      "Captured: 212, Missing: 0\n",
      "Captured: 213, Missing: 0\n"
     ]
    }
   ],
   "source": [
    "res_tot = get_adv_pool(df_list,szn_list,reg_szn_list,play_in_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(res_tot)):\n",
    "    curr_dict = res_tot[i][0]\n",
    "    with open(f'../NBA/conc_stats_adv/{szn_list[i]}_conc_stats.pkl', 'wb') as f:\n",
    "        pickle.dump(curr_dict,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nba.com/stats/team/1610612738/onoffcourt-advanced\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.nba.com/stats/team/1610612738/onoffcourt-advanced\")\n",
    "time.sleep(5)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "results = soup.find_all('table') # 2-4, overall, on, off, find_all('tr')[1:], <- .find_all('td') where i = 0 has Last, First,\n",
    "overall = results[2].find_all('tr')[1].find_all('td')\n",
    "on_court = results[3].find_all('tr')[1:]\n",
    "off_court = results[4].find_all('tr')[1:]\n",
    "\n",
    "# \tGP\tMIN\tOFFRTG\tDEFRTG\tNETRTG\tAST%\tAST/TO\tAST RATIO\tOREB%\tDREB%\tREB%\tTOV%\tEFG%\tTS%\tPACE\tPIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# TODO: add batch size parameter/fix pooling \n",
    "def get_on_off(info):\n",
    "    '''\n",
    "    Gets cumulative advanced stats for a given season, NOT INCLUDING LAST 10\n",
    "    input: [dates,url,abr,reg_szn_end,play_in_end]\n",
    "    RETURNS: dict mapping date -> [abr,adv_stats]\n",
    "    '''\n",
    "    dates = info[0]\n",
    "    base_url = info[1]\n",
    "    abr = info[2]\n",
    "    reg_szn_end = info[3]\n",
    "    play_in_end = info[4]\n",
    "    reg_szn_end_dt = datetime.datetime(int(reg_szn_end[3]),int(reg_szn_end[1]),int(reg_szn_end[2]))\n",
    "    if len(play_in_end) > 0:\n",
    "        play_in_end_dt = datetime.datetime(int(play_in_end[3]),int(play_in_end[1]),int(play_in_end[2]))\n",
    "\n",
    "    options = Options()\n",
    "    driver = webdriver.Chrome(options=options) # requires appropriate webdriver in PATH variables, or pass path to file as arg `executable_path=`\n",
    "    # teams_dict = info[2]\n",
    "    out_dict = defaultdict(list) # map date -> [abr,adv_stats]\n",
    "    missing = []\n",
    "\n",
    "    try:\n",
    "        for i in range(9,len(dates),10): # change range step to control how many tabs are opened in a batch, current set to 5\n",
    "            date_list = []\n",
    "            k = 0\n",
    "            for j in range(i-9,i+1):\n",
    "                curr_date = dates[j].split()\n",
    "                date_list.append(dates[j])\n",
    "                team_stats = base_url + f'&DateTo={MONTH_TO_NUM[curr_date[1]]}%2F{curr_date[2]}%2F{curr_date[3]}'\n",
    "\n",
    "                curr_date_dt = datetime.datetime(int(curr_date[3]),int(MONTH_TO_NUM[curr_date[1]]),int(curr_date[2]))\n",
    "\n",
    "                if curr_date_dt <= reg_szn_end_dt:\n",
    "                    team_stats += '&SeasonType=Regular+Season'\n",
    "                elif len(play_in_end) > 0 and curr_date_dt <= play_in_end_dt:\n",
    "                    team_stats += '&SeasonType=PlayIn'\n",
    "                else:\n",
    "                    team_stats += '&SeasonType=Playoffs'\n",
    "\n",
    "                driver.get(team_stats)\n",
    "                k += 1\n",
    "                if k < 10: # change range step to control how many tabs are opened in a batch, current set to 10\n",
    "                    driver.execute_script(\"window.open()\")\n",
    "                    driver.switch_to.window(driver.window_handles[k])\n",
    "            \n",
    "            window_list = driver.window_handles\n",
    "            k = 0\n",
    "            # load JS\n",
    "            time.sleep(2)\n",
    "            for window in window_list:\n",
    "                date = date_list[k]\n",
    "                k += 1\n",
    "                driver.switch_to.window(window)\n",
    "                html = driver.page_source\n",
    "\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                results = soup.find_all('table')\n",
    "\n",
    "                try:\n",
    "                    overall = results[2].find_all('tr')[1].find_all('td')\n",
    "                    over_stats = []\n",
    "                    on_dict = defaultdict(list)\n",
    "                    off_dict = defaultdict(list)\n",
    "\n",
    "                    for over in overall[1:]:\n",
    "                        over_stats.append(float(over.text))\n",
    "\n",
    "                    out_dict[date].append(over_stats)\n",
    "\n",
    "                    # NAME\tGP\tMIN\tOFFRTG\tDEFRTG\tNETRTG\tAST%\tAST/TO\tAST RATIO\tOREB%\tDREB%\tREB%\tTOV%\tEFG%\tTS%\tPACE\tPIE\n",
    "                    on_court = results[3].find_all('tr')[1:]\n",
    "                    for player in on_court:\n",
    "                        on_stats = []\n",
    "                        player_stats = player.find_all('td')\n",
    "                        name_strip = player_stats[0].text\n",
    "                        d = ''.join(name_strip.split())\n",
    "                        full_name = ' '.join(d.split(',')[::-1]).upper()\n",
    "                        for e in player_stats[1:]:\n",
    "                            on_stats.append(float(e.text))\n",
    "                        on_dict[full_name] = on_stats\n",
    "\n",
    "                    out_dict[date].append(on_dict)\n",
    "\n",
    "                    off_court = results[4].find_all('tr')[1:]\n",
    "                    for player in off_court:\n",
    "                        off_stats = []\n",
    "                        player_stats = player.find_all('td')\n",
    "                        name_strip = player_stats[0].text\n",
    "                        d = ''.join(name_strip.split())\n",
    "                        full_name = ' '.join(d.split(',')[::-1]).upper()\n",
    "                        for e in player_stats[1:]:\n",
    "                            off_stats.append(float(e.text))\n",
    "                        off_dict[full_name] = off_stats\n",
    "\n",
    "                    out_dict[date].append(off_dict)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'Exception: {e} for team: {info[2]} on link: {team_stats}')\n",
    "                    missing.append(date)\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "        \n",
    "        date_list = []\n",
    "        k = 0\n",
    "        remaining = len(dates) % 10\n",
    "        if remaining > 0:\n",
    "            for i in range(len(dates) - remaining, len(dates)):\n",
    "                curr_date = dates[i].split()\n",
    "                date_list.append(dates[i])\n",
    "                team_stats = base_url + f'&DateTo={MONTH_TO_NUM[curr_date[1]]}%2F{curr_date[2]}%2F{curr_date[3]}'\n",
    "\n",
    "                curr_date_dt = datetime.datetime(int(curr_date[3]),int(MONTH_TO_NUM[curr_date[1]]),int(curr_date[2]))\n",
    "\n",
    "                if curr_date_dt <= reg_szn_end_dt:\n",
    "                    team_stats += '&SeasonType=Regular+Season'\n",
    "                elif len(play_in_end) > 0 and curr_date_dt <= play_in_end_dt:\n",
    "                    team_stats += '&SeasonType=PlayIn'\n",
    "                else:\n",
    "                    team_stats += '&SeasonType=Playoffs'\n",
    "\n",
    "                driver.get(team_stats)\n",
    "                k += 1\n",
    "                if k < remaining:\n",
    "                    driver.execute_script(\"window.open()\")\n",
    "                    driver.switch_to.window(driver.window_handles[k])\n",
    "\n",
    "            \n",
    "            window_list = driver.window_handles\n",
    "            k = 0\n",
    "            # load JS\n",
    "            time.sleep(2)\n",
    "            for window in window_list:\n",
    "                date = date_list[k]\n",
    "                k += 1\n",
    "                driver.switch_to.window(window)\n",
    "                html = driver.page_source\n",
    "\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                results = soup.find_all('table')\n",
    "\n",
    "                try:\n",
    "                    overall = results[2].find_all('tr')[1].find_all('td')\n",
    "                    over_stats = []\n",
    "                    on_dict = defaultdict(list)\n",
    "                    off_dict = defaultdict(list)\n",
    "\n",
    "                    for over in overall[1:]:\n",
    "                        over_stats.append(float(over.text))\n",
    "\n",
    "                    out_dict[date].append(over_stats)\n",
    "\n",
    "                    # NAME\tGP\tMIN\tOFFRTG\tDEFRTG\tNETRTG\tAST%\tAST/TO\tAST RATIO\tOREB%\tDREB%\tREB%\tTOV%\tEFG%\tTS%\tPACE\tPIE\n",
    "                    on_court = results[3].find_all('tr')[1:]\n",
    "                    for player in on_court:\n",
    "                        on_stats = []\n",
    "                        player_stats = player.find_all('td')\n",
    "                        name_strip = player_stats[0].text\n",
    "                        d = ''.join(name_strip.split())\n",
    "                        full_name = ' '.join(d.split(',')[::-1]).upper()\n",
    "                        for e in player_stats[1:]:\n",
    "                            on_stats.append(float(e.text))\n",
    "                        on_dict[full_name] = on_stats\n",
    "\n",
    "                    out_dict[date].append(on_dict)\n",
    "\n",
    "                    off_court = results[4].find_all('tr')[1:]\n",
    "                    for player in off_court:\n",
    "                        off_stats = []\n",
    "                        player_stats = player.find_all('td')\n",
    "                        name_strip = player_stats[0].text\n",
    "                        d = ''.join(name_strip.split())\n",
    "                        full_name = ' '.join(d.split(',')[::-1]).upper()\n",
    "                        for e in player_stats[1:]:\n",
    "                            off_stats.append(float(e.text))\n",
    "                        off_dict[full_name] = off_stats\n",
    "\n",
    "                    out_dict[date].append(off_dict)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'Exception: {e} for team: {abr} on link: {team_stats}')\n",
    "                    missing.append(date)\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        driver.quit()\n",
    "        print(f'Team: {info[2]}, Captured: {len(out_dict)}, Missing: {len(missing)}, Error: {e}')\n",
    "        return info[2],out_dict,missing\n",
    "    \n",
    "    print(f'Team: {info[2]}, Captured: {len(out_dict)}, Missing: {len(missing)}')\n",
    "    driver.quit()\n",
    "    return info[2],out_dict,missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "import concurrent.futures\n",
    "\n",
    "def pop_on_off(games_df,szn,reg_szn,play_in):\n",
    "    start_date = games_df['date'][0].split()\n",
    "    teams = []\n",
    "\n",
    "    # Generate list of URLS for each team\n",
    "    for team, abr in TEAM_NAME_TO_ABR.items():\n",
    "        team_games = games_df.loc[(games_df['away'].str.upper() == team) | (games_df['home'].str.upper() == team)]\n",
    "        dates = team_games['date'].to_list()\n",
    "        url = TEAM_ABR_TO_URL[abr] + f'/onoffcourt-advanced?Season={szn}&DateFrom={MONTH_TO_NUM[start_date[1]]}%2F{start_date[2]}%2F{start_date[3]}'\n",
    "        teams.append([dates,url,abr,reg_szn,play_in]) #regszn end, playin end\n",
    "        \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        results = list(executor.map(get_on_off,teams))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: list index out of range for team: CHO on link: https://www.nba.com/stats/team/1610612766/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=11%2F14%2F2023&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: CHO on link: https://www.nba.com/stats/team/1610612766/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=12%2F8%2F2023&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: CHI on link: https://www.nba.com/stats/team/1610612741/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=02%2F14%2F2024&SeasonType=Regular+Season\n",
      "Team: CHI, Captured: 83, Missing: 1\n",
      "Team: CHO, Captured: 78, Missing: 2, Error: name 'abr' is not defined\n",
      "Exception: list index out of range for team: BOS on link: https://www.nba.com/stats/team/1610612738/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=03%2F12%2F2024&SeasonType=Regular+Season\n",
      "Team: ATL, Captured: 83, Missing: 0\n",
      "Team: BRK, Captured: 82, Missing: 0\n",
      "Team: BOS, Captured: 94, Missing: 1, Error: name 'abr' is not defined\n",
      "Exception: list index out of range for team: DEN on link: https://www.nba.com/stats/team/1610612743/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=11%2F1%2F2023&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: DEN on link: https://www.nba.com/stats/team/1610612743/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=11%2F22%2F2023&SeasonType=Regular+Season\n",
      "Team: CLE, Captured: 94, Missing: 0\n",
      "Team: DAL, Captured: 99, Missing: 0\n",
      "Team: GSW, Captured: 83, Missing: 0\n",
      "Team: DEN, Captured: 92, Missing: 2\n",
      "Team: LAC, Captured: 0, Missing: 0\n",
      "Team: DET, Captured: 80, Missing: 0, Error: name 'abr' is not defined\n",
      "Team: LAL, Captured: 0, Missing: 0\n",
      "Team: HOU, Captured: 82, Missing: 0\n",
      "Team: IND, Captured: 100, Missing: 0\n",
      "Team: LAC, Captured: 88, Missing: 0\n",
      "Team: MEM, Captured: 82, Missing: 0\n",
      "Team: LAL, Captured: 89, Missing: 0\n",
      "Team: MIA, Captured: 89, Missing: 0\n",
      "Exception: list index out of range for team: OKC on link: https://www.nba.com/stats/team/1610612760/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=11%2F12%2F2023&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: NYK on link: https://www.nba.com/stats/team/1610612752/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=02%2F14%2F2024&SeasonType=Regular+Season\n",
      "Team: MIL, Captured: 88, Missing: 0\n",
      "Exception: list index out of range for team: NYK on link: https://www.nba.com/stats/team/1610612752/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=04%2F2%2F2024&SeasonType=Regular+Season\n",
      "Team: MIN, Captured: 98, Missing: 0\n",
      "Team: NOP, Captured: 88, Missing: 0\n",
      "Team: NYK, Captured: 93, Missing: 2\n",
      "Team: OKC, Captured: 91, Missing: 1\n",
      "Exception: list index out of range for team: PHO on link: https://www.nba.com/stats/team/1610612756/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=02%2F4%2F2024&SeasonType=Regular+Season\n",
      "Team: ORL, Captured: 89, Missing: 0\n",
      "Team: PHO, Captured: 84, Missing: 1, Error: name 'abr' is not defined\n",
      "Team: PHI, Captured: 89, Missing: 0\n",
      "Team: POR, Captured: 81, Missing: 0, Error: name 'abr' is not defined\n",
      "Exception: list index out of range for team: UTA on link: https://www.nba.com/stats/team/1610612762/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=11%2F22%2F2023&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: UTA on link: https://www.nba.com/stats/team/1610612762/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=11%2F22%2F2023&SeasonType=Regular+Season\n",
      "Team: SAC, Captured: 84, Missing: 0\n",
      "Exception: list index out of range for team: WAS on link: https://www.nba.com/stats/team/1610612764/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=12%2F6%2F2023&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: WAS on link: https://www.nba.com/stats/team/1610612764/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=12%2F17%2F2023&SeasonType=Regular+Season\n",
      "Team: SAS, Captured: 81, Missing: 0, Error: name 'abr' is not defined\n",
      "Team: UTA, Captured: 80, Missing: 2\n",
      "Exception: list index out of range for team: TOR on link: https://www.nba.com/stats/team/1610612761/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=11%2F13%2F2023&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: WAS on link: https://www.nba.com/stats/team/1610612764/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=03%2F21%2F2024&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: WAS on link: https://www.nba.com/stats/team/1610612764/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=03%2F31%2F2024&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: TOR on link: https://www.nba.com/stats/team/1610612761/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=12%2F15%2F2023&SeasonType=Regular+Season\n",
      "Team: WAS, Captured: 77, Missing: 4, Error: name 'abr' is not defined\n",
      "Exception: list index out of range for team: TOR on link: https://www.nba.com/stats/team/1610612761/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=01%2F5%2F2024&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: TOR on link: https://www.nba.com/stats/team/1610612761/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=01%2F15%2F2024&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: TOR on link: https://www.nba.com/stats/team/1610612761/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=02%2F14%2F2024&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: TOR on link: https://www.nba.com/stats/team/1610612761/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=03%2F1%2F2024&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: TOR on link: https://www.nba.com/stats/team/1610612761/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=03%2F11%2F2024&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: TOR on link: https://www.nba.com/stats/team/1610612761/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=03%2F22%2F2024&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: TOR on link: https://www.nba.com/stats/team/1610612761/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=04%2F2%2F2024&SeasonType=Regular+Season\n",
      "Exception: list index out of range for team: TOR on link: https://www.nba.com/stats/team/1610612761/onoffcourt-advanced?Season=2023-24&DateFrom=10%2F24%2F2023&DateTo=04%2F10%2F2024&SeasonType=Regular+Season\n",
      "Team: TOR, Captured: 71, Missing: 10, Error: name 'abr' is not defined\n"
     ]
    }
   ],
   "source": [
    "res = pop_on_off(games_df_2024,'2023-24',reg_szn_end_2024,play_in_end_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grug\n"
     ]
    }
   ],
   "source": [
    "print('grug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_off_dict = dict.fromkeys(TEAM_ABR_TO_URL.keys()) # ABR -> dict(date -> [cum_stats,last10])\n",
    "\n",
    "for r in res:\n",
    "    on_off_dict[r[0]] = r[1]\n",
    "    on_off_dict[r[0]][\"MISSED\"] = r[2]\n",
    "    \n",
    "with open('../NBA/conc_on_off/2023-2024_conc_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(on_off_dict,f)\n",
    "\n",
    "# with open('../NBA/conc_stats/2023-2024_conc_stats.pkl', 'rb') as f:\n",
    "#     save_me = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../NBA/on_off_stats/2023-2024_on_off.pkl', 'rb') as f:\n",
    "    on_off_2023_2024 = pickle.load(f)\n",
    "with open('../NBA/on_off_stats/2023-2024_team_stats.pkl', 'rb') as f:\n",
    "    team_stats_2023_2024 = pickle.load(f)\n",
    "    \n",
    "nba_szn_2023_2024 = Nba_Season('2023','2024',team_stats=team_stats_2023_2024,team_on_off=on_off_2023_2024)\n",
    "inj = {'DAL': ['OLIVIER-MAXENCE PROSPER'], 'BOS': []}\n",
    "home_stats,away_stats = nba_szn_2023_2024.calc_injury_impact(inj, 'BOS', 'DAL')\n",
    "greg = np.subtract(away_stats,home_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Thu Jun 6 2024',\n",
       "  'Dallas Mavericks',\n",
       "  '107',\n",
       "  'Boston Celtics',\n",
       "  '119',\n",
       "  '-6.5 (-106)',\n",
       "  'o214.5 (-112)',\n",
       "  '-250',\n",
       "  '+6.5 (-114)',\n",
       "  'u214.5 (-108)',\n",
       "  '+205']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_szn_2023_2024.add_bet_info('test_today.csv','test_today_with_bet.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
