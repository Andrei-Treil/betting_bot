{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making bets on NBA games using Bayesian Neural Networks\n",
    "The goal of this notebook is to explore the use of BNNs in predicting the outcome of NBA games. While using MLPs as seen in ```mlp_betting.ipynb``` may be computationally more efficient, personal testing has shown that tradional neural networks are overconfident in predictions making them unsuitable for betting. By learning the distributions of weights, BNNs can hopefully provide a better estimate on the outcome of games for use in betting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\OneDrive\\Desktop\\CS\\betting_bot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_validate,cross_val_predict\n",
    "from sklearn.metrics import classification_report,confusion_matrix,make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from util.client import Nba_Season\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Softmax\n",
    "from pyro.infer import MCMC, NUTS\n",
    "from pyro.infer import Predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define simple BNN using Pyro containing 1 hidden layer\n",
    "\n",
    "For this implementation, we will be using the [Pyro Probablistic Programming language](https://github.com/pyro-ppl/pyro), loosely following a [tutorial](https://colab.research.google.com/drive/1NQNMdKaE9RncuWgO_vM2k3qywV76Byfh) from the University of Amsterdam\n",
    "\n",
    "Currently, the model will only be predicting the outcomes of games (home win or away win) and compare outcomes to moneyline odds from [vegas insider](https://www.vegasinsider.com/nba/odds/las-vegas/). Because of this, the model will be learning a categorical output, 0 indicating a home win and 1 indicating away win. The model will sample each layers weights and biases from a normal distribution while the prediction will be sampled from a categorical distribution based on the output of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim, out_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru output layer\n",
    "\n",
    "        #, x.shape[0]\n",
    "        with pyro.plate(\"data\"):\n",
    "            y_hat = Softmax(dim=1)(z2) # scale output via softmax for setting categorical priors\n",
    "            # y_hat = Softmax(dim=0)(x)\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(y_hat), obs=y)\n",
    "\n",
    "        return z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old samples and features\n",
    "features = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features, samples, test_size=0.25, random_state=1)\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [07:31,  4.51s/it, step size=1.17e-02, acc. prob=0.450]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "model = BNN(in_dim=16,hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# Define Hamiltonian Monte Carlo (HMC) kernel\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(model, jit_compile=False)  # jit_compile=True is faster but requires PyTorch 1.6+\n",
    "\n",
    "# Define MCMC sampler, get 50 posterior samples\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[1969 2431 1894 2343]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48      4400\n",
      "           1       0.49      0.55      0.52      4237\n",
      "\n",
      "    accuracy                           0.50      8637\n",
      "   macro avg       0.50      0.50      0.50      8637\n",
      "weighted avg       0.50      0.50      0.50      8637\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[678 813 596 793]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.49      1491\n",
      "           1       0.49      0.57      0.53      1389\n",
      "\n",
      "    accuracy                           0.51      2880\n",
      "   macro avg       0.51      0.51      0.51      2880\n",
      "weighted avg       0.51      0.51      0.51      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1) # each x in training produces 50 predictions (0 or 1), take average\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define kelly critereon to take in average prediction score and make bets\n",
    "For placing bets, the predictions from the BNN will be used on a modified version of the [kelly critereon](https://en.wikipedia.org/wiki/Kelly_criterion) betting strategy, defined in the function ```kelly``` wrapped by ```BNN_kelly```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelly(home_pred,away_pred,home_line,away_line,max_bet=100,diff_thresh=0.05):\n",
    "    '''\n",
    "    Applies kelly critereon based on features and moneyline data\n",
    "    home_pred: Prediction from MLP for home team\n",
    "    away_pred: Prediction from MLP for away team\n",
    "    home_line: Moneyline for home team\n",
    "    away_line: Moneyline for away team\n",
    "    '''\n",
    "    bet_amount = 0\n",
    "    to_win = 0\n",
    "\n",
    "    log_home = home_pred - home_pred * away_pred / (home_pred + away_pred - (2*home_pred*away_pred))\n",
    "    log_away = away_pred - home_pred * away_pred / (home_pred + away_pred - (2*home_pred*away_pred))\n",
    "\n",
    "    # calculate ratio and implied for home\n",
    "    home_line_adj = home_line\n",
    "    away_line_adj = away_line\n",
    "    if home_line < 0:\n",
    "        home_line_adj *= -1\n",
    "        home_line_adj /= 100\n",
    "        home_ratio = 1/(home_line_adj)\n",
    "        implied_home = home_line_adj/(1+home_line_adj)\n",
    "    else:\n",
    "        home_line_adj /= 100\n",
    "        home_ratio = home_line_adj\n",
    "        implied_home = 1/(home_line+1)\n",
    "\n",
    "    # calculate ratio and implied for away\n",
    "    if away_line < 0:\n",
    "        away_line_adj *= -1\n",
    "        away_line_adj /= 100\n",
    "        away_ratio = 1/(away_line_adj)\n",
    "        implied_away = away_line_adj/(1+away_line_adj)\n",
    "    else:\n",
    "        away_line_adj /= 100\n",
    "        away_ratio = away_line_adj\n",
    "        implied_away = 1/(away_line_adj+1)\n",
    "    \n",
    "    diff_home = log_home - implied_home\n",
    "    diff_away = log_away - implied_away\n",
    "\n",
    "    kelly_home = log_home - (log_away/home_ratio)\n",
    "    kelly_away = log_away - (log_home/away_ratio)\n",
    "\n",
    "    prob = 0\n",
    "\n",
    "    # make bets, negative if away team bet\n",
    "    if diff_home > diff_away and diff_home > diff_thresh:\n",
    "        bet_amount = (max_bet*kelly_home)\n",
    "        if home_line < 0:\n",
    "            to_win = bet_amount/((home_line*-1)/100)\n",
    "        else:\n",
    "            to_win = bet_amount/((home_line)/100)\n",
    "        prob = home_pred\n",
    "\n",
    "    \n",
    "    elif diff_away > diff_home and diff_away > diff_thresh:\n",
    "        bet_amount = (max_bet*kelly_away)\n",
    "        if away_line < 0:\n",
    "            to_win = -1*bet_amount/((away_line*-1)/100)\n",
    "        else:\n",
    "            to_win = -1*bet_amount/((away_line)/100)\n",
    "        prob = away_pred\n",
    "\n",
    "    return bet_amount,to_win,prob\n",
    "\n",
    "def BNN_kelly(preds,actual,money_lines,one_hot=False,diff_thresh=0.05):\n",
    "    money_made = 0\n",
    "    money_risked = 0\n",
    "    correct = 0\n",
    "    guessed = 0\n",
    "    team_bet = []\n",
    "    amount = []\n",
    "    gained = []\n",
    "    probs = []     \n",
    "\n",
    "    for i in range(len(preds)):\n",
    "        if one_hot:\n",
    "            away_pred = preds[i][0]\n",
    "            home_pred = preds[i][1]\n",
    "        else:\n",
    "            home_pred = preds[i]\n",
    "            away_pred = 1 - home_pred\n",
    "        home_ml = money_lines[i][7]\n",
    "        away_ml = money_lines[i][10]\n",
    "\n",
    "        to_bet,to_win,prob = kelly(home_pred,away_pred,home_ml,away_ml,diff_thresh=diff_thresh)\n",
    "        probs.append(prob)\n",
    "        money_risked += to_bet\n",
    "\n",
    "        curr_gained = 0\n",
    "\n",
    "        if to_win < 0:\n",
    "            team_bet.append('Away')\n",
    "            amount.append(to_bet)\n",
    "            guessed += 1\n",
    "            curr_gained = -1*to_bet\n",
    "            if actual[i] == 1:\n",
    "                correct += 1\n",
    "                curr_gained = (-1*to_win)\n",
    "                #money_made += curr_gained\n",
    "        elif to_win > 0:\n",
    "            team_bet.append('Home')\n",
    "            amount.append(to_bet)\n",
    "            guessed += 1\n",
    "            curr_gained = -1*to_bet\n",
    "            if actual[i] == 0:\n",
    "                correct += 1\n",
    "                curr_gained = to_win\n",
    "                #money_made += curr_gained\n",
    "        else:\n",
    "            team_bet.append(0)\n",
    "            amount.append(0)\n",
    "\n",
    "        gained.append(curr_gained)\n",
    "\n",
    "        if curr_gained > 0:\n",
    "            money_made += curr_gained\n",
    "\n",
    "    return correct,guessed,team_bet,probs,amount,gained\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "104\n",
      "tensor(-465.6457)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = np.genfromtxt('NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('NBA/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "56\n",
      "tensor(-331.8321)\n"
     ]
    }
   ],
   "source": [
    "# Test on 2023-2024 data\n",
    "features_new = np.genfromtxt('NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial testing yielded better results than traditional MLPs as seen in ``mlp_betting.ipynb``, explore BNN architecture with more layers\n",
    "Add a single hidden layer to our existing architecture and increase the number of posterior samples used during MCMC training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN_Multi_Layer(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](sec_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru sec layer\n",
    "        z3 = self.activation(z2 @ self.out.weight + self.out.bias) # output layer\n",
    "\n",
    "        #, x.shape[0]\n",
    "        with pyro.plate(\"data\"):\n",
    "            y_hat = Softmax(dim=1)(z3)\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(y_hat), obs=y)\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 2014/2015-2022/2023 NBA seasons to train, make predictions on 2023/2024 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old samples and features\n",
    "feat_train = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samp_train = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samp_train_1d = [0 if j[0] == 0 else 1 for j in samp_train]\n",
    "\n",
    "feat_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',') # unnormalized\n",
    "samp_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',') # unnormalized\n",
    "feat_test_norm = [[float(i)/sum(j) for i in j ]for j in feat_test]\n",
    "samp_test_1d = [0 if j[0] == 0 else 1 for j in samp_test]\n",
    "\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test_norm)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [12:59,  7.80s/it, step size=2.89e-03, acc. prob=0.723]\n"
     ]
    }
   ],
   "source": [
    "new_model = BNN_Multi_Layer(in_dim=16,first_hid_dim=16,sec_hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(new_model, jit_compile=True)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2582 3309 2475 3151]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.44      0.47      5891\n",
      "           1       0.49      0.56      0.52      5626\n",
      "\n",
      "    accuracy                           0.50     11517\n",
      "   macro avg       0.50      0.50      0.50     11517\n",
      "weighted avg       0.50      0.50      0.50     11517\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[272 389 297 356]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.41      0.44       661\n",
      "           1       0.48      0.55      0.51       653\n",
      "\n",
      "    accuracy                           0.48      1314\n",
      "   macro avg       0.48      0.48      0.48      1314\n",
      "weighted avg       0.48      0.48      0.48      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old samples and features\n",
    "features = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features, samples, test_size=0.25, random_state=1)\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/200 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [27:06,  8.13s/it, step size=3.46e-03, acc. prob=0.594]\n"
     ]
    }
   ],
   "source": [
    "new_model = BNN_Multi_Layer(in_dim=16,first_hid_dim=16,sec_hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(new_model, jit_compile=True)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2041 2359 1925 2312]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.46      0.49      4400\n",
      "           1       0.49      0.55      0.52      4237\n",
      "\n",
      "    accuracy                           0.50      8637\n",
      "   macro avg       0.50      0.50      0.50      8637\n",
      "weighted avg       0.50      0.50      0.50      8637\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[698 793 619 770]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50      1491\n",
      "           1       0.49      0.55      0.52      1389\n",
      "\n",
      "    accuracy                           0.51      2880\n",
      "   macro avg       0.51      0.51      0.51      2880\n",
      "weighted avg       0.51      0.51      0.51      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "64\n",
      "tensor(-19.2364)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "52\n",
      "tensor(-316.8422)\n"
     ]
    }
   ],
   "source": [
    "# Test on 2023-2024 data\n",
    "features_new = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our new structure yielded better results, however at a significant cost to runtime. Explore the use of Stochastic Variational Inference for training: \n",
    "Simple single layer BNN, using SVI with AutoNormal guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax, Softmax\n",
    "\n",
    "class BNN_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](first_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.out.weight + self.out.bias) # output layer\n",
    "        y_hat = LogSoftmax(dim=1)(z2) # scale output via softmax for setting categorical priors\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(logits=y_hat).to_event(1), obs=y)\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "features = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_maxabs.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_samples.csv',delimiter=',')\n",
    "feat_test = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samp_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.Tensor(samples.T)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 1.5100\n",
      "[iteration 0101] loss: 1.4795\n",
      "[iteration 0201] loss: 1.4451\n",
      "[iteration 0301] loss: 1.4494\n",
      "[iteration 0401] loss: 1.4377\n",
      "[iteration 0501] loss: 1.4332\n",
      "[iteration 0601] loss: 1.4339\n",
      "[iteration 0701] loss: 1.4340\n",
      "[iteration 0801] loss: 1.4319\n",
      "[iteration 0901] loss: 1.4302\n",
      "[iteration 1001] loss: 1.4300\n",
      "[iteration 1101] loss: 1.4309\n",
      "[iteration 1201] loss: 1.4292\n",
      "[iteration 1301] loss: 1.4282\n",
      "[iteration 1401] loss: 1.4264\n",
      "[iteration 1501] loss: 1.4273\n",
      "[iteration 1601] loss: 1.4241\n",
      "[iteration 1701] loss: 1.4240\n",
      "[iteration 1801] loss: 1.4253\n",
      "[iteration 1901] loss: 1.4234\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "pyro.clear_param_store()\n",
    "new_model = BNN_SVI(in_dim=16,first_hid_dim=16,out_dim=2)\n",
    "guide = AutoNormal(new_model)\n",
    "\n",
    "svi = SVI(new_model, guide, Adam({\"lr\": 1e-3}), Trace_ELBO())\n",
    "steps = 2000\n",
    "\n",
    "for step in range(steps):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    if step % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (step + 1, loss / len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2547 2762 2381 2684]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.48      0.50      5309\n",
      "           1       0.49      0.53      0.51      5065\n",
      "\n",
      "    accuracy                           0.50     10374\n",
      "   macro avg       0.50      0.50      0.50     10374\n",
      "weighted avg       0.51      0.50      0.50     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[312 349 303 350]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49       661\n",
      "           1       0.50      0.54      0.52       653\n",
      "\n",
      "    accuracy                           0.50      1314\n",
      "   macro avg       0.50      0.50      0.50      1314\n",
      "weighted avg       0.50      0.50      0.50      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictive = Predictive(new_model, guide=guide, num_samples=400, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=2)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train.T] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_new = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple BNN structure saw significant improvement in runtime, and produces much less confident predictions. Lets try a more complex structure now:\n",
    "## Multi-Layer BNN w/ SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax\n",
    "\n",
    "class BNN_Multi_Layer_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, thir_hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.layer3 = PyroModule[nn.Linear](sec_hid_dim, thir_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](thir_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.layer3.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, thir_hid_dim]).to_event(2))\n",
    "        self.layer3.bias = PyroSample(dist.Normal(0., prior_scale).expand([thir_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([thir_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru sec layer\n",
    "        z3 = self.activation(z2 @ self.layer3.weight + self.layer3.bias) # output layer\n",
    "        z4 = self.activation(z3 @ self.out.weight + self.out.bias) # output layer\n",
    "\n",
    "        # y_hat = Softmax(dim=1)(z4)\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.OneHotCategorical(logits=z4).to_event(1), obs=y,\n",
    "                        infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "        return z4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax\n",
    "\n",
    "class BNN_Test(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, thir_hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.layer3 = PyroModule[nn.Linear](sec_hid_dim, thir_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](thir_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, in_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim]).to_event(1)) # output bias term\n",
    "        self.layer3.weight = PyroSample(dist.Normal(0., prior_scale).expand([thir_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer3.bias = PyroSample(dist.Normal(0., prior_scale).expand([thir_hid_dim]).to_event(1)) # output bias term\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([out_dim, thir_hid_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(self.layer1(x)) # pass thru first layer\n",
    "        z2 = self.activation(self.layer2(z1)) # pass thru sec layer\n",
    "        z3 = self.activation(self.layer3(z2)) # output layer\n",
    "        z4 = self.activation(self.out(z3)) # output layer\n",
    "\n",
    "        y_hat = LogSoftmax(dim=1)(z4)\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(logits=y_hat), obs=y,\n",
    "                        infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "        return z4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "features = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_unnorm.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_samples.csv',delimiter=',')\n",
    "feat_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samp_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.Tensor(samples)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 2.0792\n",
      "[iteration 0201] loss: 1.6820\n",
      "[iteration 0401] loss: 1.4761\n",
      "[iteration 0601] loss: 1.2856\n",
      "[iteration 0801] loss: 1.1445\n",
      "[iteration 1001] loss: 1.0356\n",
      "[iteration 1201] loss: 0.9436\n",
      "[iteration 1401] loss: 0.8903\n",
      "[iteration 1601] loss: 0.8512\n",
      "[iteration 1801] loss: 0.8203\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal, AutoDiagonalNormal\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "pyro.clear_param_store()\n",
    "new_model = BNN_Multi_Layer_SVI(in_dim=16,first_hid_dim=32,sec_hid_dim=64,thir_hid_dim=32,out_dim=2,prior_scale=2.)\n",
    "guide = AutoDiagonalNormal(new_model)\n",
    "\n",
    "svi = SVI(new_model, guide, Adam({\"lr\": 0.003}), TraceEnum_ELBO()) # max_plate_nesting=1\n",
    "# steps = 2000\n",
    "losses = []\n",
    "steps = []\n",
    "\n",
    "for i in range(2000):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    losses.append(loss)\n",
    "    steps.append(i)\n",
    "    if i % 200 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (i + 1, loss / len(x_train)))\n",
    "\n",
    "plt.plot(steps,losses)\n",
    "plt.ylabel(\"ELBO Loss\")\n",
    "plt.xlabel(\"SVI Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2586 2723 2360 2705]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.49      0.50      5309\n",
      "           1       0.50      0.53      0.52      5065\n",
      "\n",
      "    accuracy                           0.51     10374\n",
      "   macro avg       0.51      0.51      0.51     10374\n",
      "weighted avg       0.51      0.51      0.51     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[313 348 296 357]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49       661\n",
      "           1       0.51      0.55      0.53       653\n",
      "\n",
      "    accuracy                           0.51      1314\n",
      "   macro avg       0.51      0.51      0.51      1314\n",
      "weighted avg       0.51      0.51      0.51      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "predictive = Predictive(new_model, guide=guide, num_samples=200, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "# train_preds = predictive(x_train)['obs'].T.float().mean(axis=2)\n",
    "# test_preds = predictive(x_test)['obs'].T.float().mean(axis=2)\n",
    "train_preds = predictive(x_train)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "test_preds = predictive(x_test)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "\n",
    "# adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "# adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "adj_train_preds = [0 if p[0] < p[1] else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p[0] < p[1] else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> home win -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max confidence: 0.6150000095367432\n",
      "correct: 583\n",
      "guessed: 1187\n",
      "made: 768.580322265625\n",
      "max confidence: 0.6349999904632568\n",
      "correct: 590\n",
      "guessed: 1213\n",
      "made: 673.7506103515625\n"
     ]
    }
   ],
   "source": [
    "#features_new = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "features_new = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "new_y_pred = predictive(new_x_tens)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)')\n",
    "print(f'max confidence: {new_y_pred.max()}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:],one_hot=True, diff_thresh=-0.5)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'made: {sum(gained)}\\n')\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "# features_new = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "features_new = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "new_y_pred = predictive(new_x_tens)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2023-2024 DATA (UNSEEN)')\n",
    "print(f'max confidence: {new_y_pred.max()}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:], one_hot=True, diff_thresh=-0.5)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'made: {sum(gained)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     team_bet           probs           amount           gained\n",
      "0        Home  tensor(0.4600)  tensor(-6.2615)   tensor(3.9135)\n",
      "1        Away  tensor(0.5650)  tensor(12.0017)   tensor(9.5251)\n",
      "2        Home  tensor(0.4800)  tensor(-3.2427)   tensor(3.2427)\n",
      "3        Away  tensor(0.4900)  tensor(-1.6723)   tensor(1.1454)\n",
      "4        Home  tensor(0.4500)  tensor(-7.4134)   tensor(4.2121)\n",
      "...       ...             ...              ...              ...\n",
      "1309     Home  tensor(0.5450)   tensor(6.8437)  tensor(-6.8437)\n",
      "1310     Away  tensor(0.5250)   tensor(5.0900)  tensor(-5.0900)\n",
      "1311     Home  tensor(0.5250)   tensor(3.7279)  tensor(-3.7279)\n",
      "1312     Away  tensor(0.5050)   tensor(1.0000)   tensor(1.0000)\n",
      "1313     Home  tensor(0.4400)  tensor(-9.3366)   tensor(9.3366)\n",
      "\n",
      "[1314 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# bet_df = correct,guessed,team_bet,probs,amount,gained\n",
    "bet_dict = {\n",
    "    'team_bet': team_bet,\n",
    "    'probs': probs,\n",
    "    'amount': amount,\n",
    "    'gained': gained\n",
    "}\n",
    "bet_df = pd.DataFrame(bet_dict)\n",
    "print(bet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different normalization technique\n",
    "Improving quality of data could be useful, we will explore the performance of a simple BNN on unnormalized, minmax norm, maxabs norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnormalized\n",
    "First, we will construct a new unnormalized features file from 2014/2015 to 2022/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "features = []\n",
    "feat_minmax = []\n",
    "feat_maxabs = []\n",
    "samples = []\n",
    "start = 2014\n",
    "\n",
    "while start < 2023:\n",
    "    if start == 2018: # this year is missing and wont populate thru scraper!!\n",
    "        start += 1\n",
    "        continue\n",
    "\n",
    "    curr_feats = np.genfromtxt('../NBA/samps_feats/{start}-{end}_nba_features_inj.csv'.format(start=start,end=start+1),delimiter=',')\n",
    "    curr_samps = np.genfromtxt('../NBA/samps_feats/{start}-{end}_nba_samples_inj.csv'.format(start=start,end=start+1),delimiter=',')\n",
    "    feat_minmax.extend(minmax_scale(curr_feats))\n",
    "    feat_maxabs.extend(maxabs_scale(curr_feats))\n",
    "    features.extend(curr_feats)\n",
    "    samples.extend(curr_samps)\n",
    "    start += 1\n",
    "\n",
    "\n",
    "np.savetxt('../NBA/samps_feats/2015-2023_nba_features_unnorm.csv', features, delimiter=',')\n",
    "np.savetxt('../NBA/samps_feats/2015-2023_nba_samples.csv', samples, delimiter=',')\n",
    "np.savetxt('../NBA/samps_feats/2015-2023_nba_features_minmax.csv', features, delimiter=',')\n",
    "np.savetxt('../NBA/samps_feats/2015-2023_nba_features_maxabs.csv', features, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_15840\\2636246682.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  x_train = torch.FloatTensor(features)\n"
     ]
    }
   ],
   "source": [
    "feat_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',') # unnormalized\n",
    "samp_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samples)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [01:35,  1.05it/s, step size=4.07e-02, acc. prob=0.788]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "x_train = torch.FloatTensor(feat_maxabs)\n",
    "x_test = torch.FloatTensor(maxabs_scale(feat_test))\n",
    "y_train = torch.FloatTensor(samples)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "model = BNN(in_dim=16,hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# Define Hamiltonian Monte Carlo (HMC) kernel\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(model, jit_compile=False)  # jit_compile=True is faster but requires PyTorch 1.6+\n",
    "\n",
    "# Define MCMC sampler, get 50 posterior samples\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2384 2925 2191 2874]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.45      0.48      5309\n",
      "           1       0.50      0.57      0.53      5065\n",
      "\n",
      "    accuracy                           0.51     10374\n",
      "   macro avg       0.51      0.51      0.51     10374\n",
      "weighted avg       0.51      0.51      0.51     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[296 365 267 386]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.48       661\n",
      "           1       0.51      0.59      0.55       653\n",
      "\n",
      "    accuracy                           0.52      1314\n",
      "   macro avg       0.52      0.52      0.52      1314\n",
      "weighted avg       0.52      0.52      0.52      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "106\n",
      "tensor(-746.6345)\n",
      "49\n",
      "118\n",
      "tensor(-704.2104)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
