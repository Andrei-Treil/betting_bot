{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making bets on NBA games using Bayesian Neural Networks\n",
    "The goal of this notebook is to explore the use of BNNs in predicting the outcome of NBA games. While using MLPs as seen in ```mlp_betting.ipynb``` may be computationally more efficient, personal testing has shown that tradional neural networks are overconfident in predictions making them unsuitable for betting. By learning the distributions of weights, BNNs can hopefully provide a better estimate on the outcome of games for use in betting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_validate,cross_val_predict\n",
    "from sklearn.metrics import classification_report,confusion_matrix,make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from util.client import Nba_Season\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Softmax\n",
    "from pyro.infer import MCMC, NUTS\n",
    "from pyro.infer import Predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define simple BNN using Pyro containing 1 hidden layer\n",
    "\n",
    "For this implementation, we will be using the [Pyro Probablistic Programming language](https://github.com/pyro-ppl/pyro), loosely following a [tutorial](https://colab.research.google.com/drive/1NQNMdKaE9RncuWgO_vM2k3qywV76Byfh) from the University of Amsterdam\n",
    "\n",
    "Currently, the model will only be predicting the outcomes of games (home win or away win) and compare outcomes to moneyline odds from [vegas insider](https://www.vegasinsider.com/nba/odds/las-vegas/). Because of this, the model will be learning a categorical output, 0 indicating a home win and 1 indicating away win. The model will sample each layers weights and biases from a normal distribution while the prediction will be sampled from a categorical distribution based on the output of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim, out_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru output layer\n",
    "\n",
    "        #, x.shape[0]\n",
    "        with pyro.plate(\"data\"):\n",
    "            y_hat = Softmax(dim=1)(z2) # scale output via softmax for setting categorical priors\n",
    "            # y_hat = Softmax(dim=0)(x)\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(y_hat), obs=y)\n",
    "\n",
    "        return z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old samples and features\n",
    "features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features, samples, test_size=0.25, random_state=1)\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [07:31,  4.51s/it, step size=1.17e-02, acc. prob=0.450]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "model = BNN(in_dim=16,hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# Define Hamiltonian Monte Carlo (HMC) kernel\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(model, jit_compile=False)  # jit_compile=True is faster but requires PyTorch 1.6+\n",
    "\n",
    "# Define MCMC sampler, get 50 posterior samples\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[1969 2431 1894 2343]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48      4400\n",
      "           1       0.49      0.55      0.52      4237\n",
      "\n",
      "    accuracy                           0.50      8637\n",
      "   macro avg       0.50      0.50      0.50      8637\n",
      "weighted avg       0.50      0.50      0.50      8637\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[678 813 596 793]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.49      1491\n",
      "           1       0.49      0.57      0.53      1389\n",
      "\n",
      "    accuracy                           0.51      2880\n",
      "   macro avg       0.51      0.51      0.51      2880\n",
      "weighted avg       0.51      0.51      0.51      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1) # each x in training produces 50 predictions (0 or 1), take average\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define kelly critereon to take in average prediction score and make bets\n",
    "For placing bets, the predictions from the BNN will be used on a modified version of the [kelly critereon](https://en.wikipedia.org/wiki/Kelly_criterion) betting strategy, defined in the function ```kelly``` wrapped by ```BNN_kelly```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelly(home_pred,away_pred,home_line,away_line,max_bet=100,diff_thresh=0.05):\n",
    "    '''\n",
    "    Applies kelly critereon based on features and moneyline data\n",
    "    home_pred: Prediction from MLP for home team\n",
    "    away_pred: Prediction from MLP for away team\n",
    "    home_line: Moneyline for home team\n",
    "    away_line: Moneyline for away team\n",
    "    '''\n",
    "    bet_amount = 0\n",
    "    to_win = 0\n",
    "\n",
    "    log_home = (home_pred - (home_pred * away_pred)) / (home_pred + away_pred - (2*home_pred*away_pred))\n",
    "    log_away = (away_pred - (home_pred * away_pred)) / (home_pred + away_pred - (2*home_pred*away_pred))\n",
    "\n",
    "    # calculate ratio and implied for home\n",
    "    home_line_adj = home_line\n",
    "    away_line_adj = away_line\n",
    "    if home_line < 0:\n",
    "        home_line_adj *= -1\n",
    "        home_line_adj /= 100\n",
    "        home_ratio = 1/(home_line_adj)\n",
    "        implied_home = home_line_adj/(1+home_line_adj)\n",
    "    else:\n",
    "        home_line_adj /= 100\n",
    "        home_ratio = home_line_adj\n",
    "        implied_home = 1/(home_line+1)\n",
    "\n",
    "    # calculate ratio and implied for away\n",
    "    if away_line < 0:\n",
    "        away_line_adj *= -1\n",
    "        away_line_adj /= 100\n",
    "        away_ratio = 1/(away_line_adj)\n",
    "        implied_away = away_line_adj/(1+away_line_adj)\n",
    "    else:\n",
    "        away_line_adj /= 100\n",
    "        away_ratio = away_line_adj\n",
    "        implied_away = 1/(away_line_adj+1)\n",
    "    \n",
    "    diff_home = log_home - implied_home\n",
    "    diff_away = log_away - implied_away\n",
    "\n",
    "    kelly_home = log_home - (log_away/home_ratio)\n",
    "    kelly_away = log_away - (log_home/away_ratio)\n",
    "\n",
    "    prob = 0\n",
    "\n",
    "    # make bets, negative if away team bet\n",
    "    if diff_home > diff_away and diff_home > diff_thresh:\n",
    "        bet_amount = (max_bet*kelly_home)\n",
    "        if home_line < 0:\n",
    "            to_win = bet_amount/((home_line*-1)/100)\n",
    "        else:\n",
    "            to_win = bet_amount/((home_line)/100)\n",
    "        prob = home_pred\n",
    "\n",
    "    \n",
    "    elif diff_away > diff_home and diff_away > diff_thresh:\n",
    "        bet_amount = (max_bet*kelly_away)\n",
    "        if away_line < 0:\n",
    "            to_win = -1*bet_amount/((away_line*-1)/100)\n",
    "        else:\n",
    "            to_win = -1*bet_amount/((away_line)/100)\n",
    "        prob = away_pred\n",
    "\n",
    "    return bet_amount,to_win,prob\n",
    "\n",
    "def BNN_kelly(preds,actual,money_lines,one_hot=False,diff_thresh=0.05):\n",
    "    money_made = 0\n",
    "    money_risked = 0\n",
    "    correct = 0\n",
    "    guessed = 0\n",
    "    team_bet = []\n",
    "    amount = []\n",
    "    gained = []\n",
    "    probs = []     \n",
    "\n",
    "    for i in range(len(preds)):\n",
    "        if one_hot:\n",
    "            away_pred = preds[i][0]\n",
    "            home_pred = preds[i][1]\n",
    "        else:\n",
    "            home_pred = preds[i]\n",
    "            away_pred = 1 - home_pred\n",
    "        home_ml = money_lines[i][7]\n",
    "        away_ml = money_lines[i][10]\n",
    "\n",
    "        to_bet,to_win,prob = kelly(home_pred,away_pred,home_ml,away_ml,diff_thresh=diff_thresh)\n",
    "        probs.append(prob)\n",
    "        money_risked += to_bet\n",
    "\n",
    "        curr_gained = 0\n",
    "\n",
    "        if to_win < 0:\n",
    "            team_bet.append('Away')\n",
    "            amount.append(to_bet)\n",
    "            guessed += 1\n",
    "            curr_gained = -1*to_bet\n",
    "            if actual[i] == 1:\n",
    "                correct += 1\n",
    "                curr_gained = (-1*to_win)\n",
    "                #money_made += curr_gained\n",
    "        elif to_win > 0:\n",
    "            team_bet.append('Home')\n",
    "            amount.append(to_bet)\n",
    "            guessed += 1\n",
    "            curr_gained = -1*to_bet\n",
    "            if actual[i] == 0:\n",
    "                correct += 1\n",
    "                curr_gained = to_win\n",
    "                #money_made += curr_gained\n",
    "        else:\n",
    "            team_bet.append(0)\n",
    "            amount.append(0)\n",
    "\n",
    "        gained.append(curr_gained)\n",
    "\n",
    "        if curr_gained > 0:\n",
    "            money_made += curr_gained\n",
    "\n",
    "    return correct,guessed,team_bet,probs,amount,gained\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "104\n",
      "tensor(-465.6457)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "56\n",
      "tensor(-331.8321)\n"
     ]
    }
   ],
   "source": [
    "# Test on 2023-2024 data\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial testing yielded better results than traditional MLPs as seen in ``mlp_betting.ipynb``, explore BNN architecture with more layers\n",
    "Add a single hidden layer to our existing architecture and increase the number of posterior samples used during MCMC training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN_Multi_Layer(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](sec_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru sec layer\n",
    "        z3 = self.activation(z2 @ self.out.weight + self.out.bias) # output layer\n",
    "\n",
    "        #, x.shape[0]\n",
    "        with pyro.plate(\"data\"):\n",
    "            y_hat = Softmax(dim=1)(z3)\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(y_hat), obs=y)\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 2014/2015-2022/2023 NBA seasons to train, make predictions on 2023/2024 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old samples and features\n",
    "feat_train = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samp_train = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samp_train_1d = [0 if j[0] == 0 else 1 for j in samp_train]\n",
    "\n",
    "feat_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',') # unnormalized\n",
    "samp_test = np.genfromtxt('../NBA/total/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',') # unnormalized\n",
    "feat_test_norm = [[float(i)/sum(j) for i in j ]for j in feat_test]\n",
    "samp_test_1d = [0 if j[0] == 0 else 1 for j in samp_test]\n",
    "\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test_norm)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [12:59,  7.80s/it, step size=2.89e-03, acc. prob=0.723]\n"
     ]
    }
   ],
   "source": [
    "new_model = BNN_Multi_Layer(in_dim=16,first_hid_dim=16,sec_hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(new_model, jit_compile=True)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2582 3309 2475 3151]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.44      0.47      5891\n",
      "           1       0.49      0.56      0.52      5626\n",
      "\n",
      "    accuracy                           0.50     11517\n",
      "   macro avg       0.50      0.50      0.50     11517\n",
      "weighted avg       0.50      0.50      0.50     11517\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[272 389 297 356]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.41      0.44       661\n",
      "           1       0.48      0.55      0.51       653\n",
      "\n",
      "    accuracy                           0.48      1314\n",
      "   macro avg       0.48      0.48      0.48      1314\n",
      "weighted avg       0.48      0.48      0.48      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old samples and features\n",
    "features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features, samples, test_size=0.25, random_state=1)\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/200 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [27:06,  8.13s/it, step size=3.46e-03, acc. prob=0.594]\n"
     ]
    }
   ],
   "source": [
    "new_model = BNN_Multi_Layer(in_dim=16,first_hid_dim=16,sec_hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(new_model, jit_compile=True)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2041 2359 1925 2312]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.46      0.49      4400\n",
      "           1       0.49      0.55      0.52      4237\n",
      "\n",
      "    accuracy                           0.50      8637\n",
      "   macro avg       0.50      0.50      0.50      8637\n",
      "weighted avg       0.50      0.50      0.50      8637\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[698 793 619 770]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50      1491\n",
      "           1       0.49      0.55      0.52      1389\n",
      "\n",
      "    accuracy                           0.51      2880\n",
      "   macro avg       0.51      0.51      0.51      2880\n",
      "weighted avg       0.51      0.51      0.51      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "64\n",
      "tensor(-19.2364)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "52\n",
      "tensor(-316.8422)\n"
     ]
    }
   ],
   "source": [
    "# Test on 2023-2024 data\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our new structure yielded better results, however at a significant cost to runtime. Explore the use of Stochastic Variational Inference for training: \n",
    "Simple single layer BNN, using SVI with AutoNormal guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax, Softmax\n",
    "\n",
    "class BNN_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](first_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.out.weight + self.out.bias) # output layer\n",
    "        y_hat = LogSoftmax(dim=1)(z2) # scale output via softmax for setting categorical priors\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(logits=y_hat).to_event(1), obs=y)\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_maxabs.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples.csv',delimiter=',')\n",
    "feat_test = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samp_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.Tensor(samples.T)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 1.5100\n",
      "[iteration 0101] loss: 1.4795\n",
      "[iteration 0201] loss: 1.4451\n",
      "[iteration 0301] loss: 1.4494\n",
      "[iteration 0401] loss: 1.4377\n",
      "[iteration 0501] loss: 1.4332\n",
      "[iteration 0601] loss: 1.4339\n",
      "[iteration 0701] loss: 1.4340\n",
      "[iteration 0801] loss: 1.4319\n",
      "[iteration 0901] loss: 1.4302\n",
      "[iteration 1001] loss: 1.4300\n",
      "[iteration 1101] loss: 1.4309\n",
      "[iteration 1201] loss: 1.4292\n",
      "[iteration 1301] loss: 1.4282\n",
      "[iteration 1401] loss: 1.4264\n",
      "[iteration 1501] loss: 1.4273\n",
      "[iteration 1601] loss: 1.4241\n",
      "[iteration 1701] loss: 1.4240\n",
      "[iteration 1801] loss: 1.4253\n",
      "[iteration 1901] loss: 1.4234\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "pyro.clear_param_store()\n",
    "new_model = BNN_SVI(in_dim=16,first_hid_dim=16,out_dim=2)\n",
    "guide = AutoNormal(new_model)\n",
    "\n",
    "svi = SVI(new_model, guide, Adam({\"lr\": 1e-3}), Trace_ELBO())\n",
    "steps = 2000\n",
    "\n",
    "for step in range(steps):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    if step % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (step + 1, loss / len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2547 2762 2381 2684]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.48      0.50      5309\n",
      "           1       0.49      0.53      0.51      5065\n",
      "\n",
      "    accuracy                           0.50     10374\n",
      "   macro avg       0.50      0.50      0.50     10374\n",
      "weighted avg       0.51      0.50      0.50     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[312 349 303 350]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49       661\n",
      "           1       0.50      0.54      0.52       653\n",
      "\n",
      "    accuracy                           0.50      1314\n",
      "   macro avg       0.50      0.50      0.50      1314\n",
      "weighted avg       0.50      0.50      0.50      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictive = Predictive(new_model, guide=guide, num_samples=400, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=2)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train.T] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple BNN structure saw significant improvement in runtime, and produces much less confident predictions. Lets try a more complex structure now:\n",
    "## Multi-Layer BNN w/ SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax\n",
    "\n",
    "class BNN_Multi_Layer_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, thir_hid_dim=5, prior_scale=1., bias_scale=10.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.layer3 = PyroModule[nn.Linear](sec_hid_dim, thir_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](thir_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., bias_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., bias_scale).expand([sec_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.layer3.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, thir_hid_dim]).to_event(2))\n",
    "        self.layer3.bias = PyroSample(dist.Normal(0., bias_scale).expand([thir_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([thir_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., bias_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru sec layer\n",
    "        z3 = self.activation(z2 @ self.layer3.weight + self.layer3.bias) # output layer\n",
    "        z4 = self.activation(z3 @ self.out.weight + self.out.bias) # output layer\n",
    "\n",
    "        y_hat = Softmax(dim=1)(z4)\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.OneHotCategorical(probs=y_hat).to_event(1), obs=y,\n",
    "                        infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "# features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_maxabs.csv',delimiter=',')\n",
    "features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_unnorm.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples.csv',delimiter=',')\n",
    "# feat_test = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "feat_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samp_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.Tensor(samples)\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train]\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 9.0015\n",
      "[iteration 0501] loss: 8.6606\n",
      "[iteration 1001] loss: 8.6255\n",
      "[iteration 1501] loss: 8.6025\n",
      "[iteration 2001] loss: 8.5860\n",
      "[iteration 2501] loss: 8.5771\n",
      "[iteration 3001] loss: 8.5705\n",
      "[iteration 3501] loss: 8.5657\n",
      "[iteration 4001] loss: 8.5626\n",
      "[iteration 4501] loss: 8.5610\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal, AutoDiagonalNormal, AutoContinuous, AutoDelta, AutoMultivariateNormal, AutoLaplaceApproximation, AutoStructured\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "pyro.clear_param_store()\n",
    "bnn_cat = BNN_Multi_Layer_SVI(in_dim=16,first_hid_dim=128,sec_hid_dim=128,thir_hid_dim=128,out_dim=2,prior_scale=4,bias_scale=10)\n",
    "guide = AutoDelta(bnn_cat)\n",
    "num_steps = 5000\n",
    "\n",
    "init_lr = 0.001\n",
    "gamma = 0.01\n",
    "lrd = gamma ** (1/num_steps)\n",
    "optim = ClippedAdam({'lr': init_lr, 'lrd': lrd, \"betas\": (0.95, 0.999)})\n",
    "# optim = Adam({\"lr\": 0.01,\"betas\": (0.95, 0.999)})\n",
    "\n",
    "svi = SVI(bnn_cat, guide, optim, TraceEnum_ELBO())\n",
    "losses = []\n",
    "steps = []\n",
    "\n",
    "for i in range(num_steps):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    losses.append(loss)\n",
    "    steps.append(i)\n",
    "    if i % (num_steps/10) == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (i + 1, loss / len(x_train)))\n",
    "\n",
    "plt.plot(steps,losses)\n",
    "plt.ylabel(\"ELBO Loss\")\n",
    "plt.xlabel(\"SVI Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[4054 1255 1679 3386]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73      5309\n",
      "           1       0.73      0.67      0.70      5065\n",
      "\n",
      "    accuracy                           0.72     10374\n",
      "   macro avg       0.72      0.72      0.72     10374\n",
      "weighted avg       0.72      0.72      0.72     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[360 301 361 292]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.54      0.52       661\n",
      "           1       0.49      0.45      0.47       653\n",
      "\n",
      "    accuracy                           0.50      1314\n",
      "   macro avg       0.50      0.50      0.49      1314\n",
      "weighted avg       0.50      0.50      0.50      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "predictive = Predictive(bnn_cat, guide=guide, num_samples=1000, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> home win -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "adj_train_preds = [0 if p[0] < p[1] else 1 for p in train_preds]\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "test_preds = predictive(x_test)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "adj_test_preds = [0 if p[0] < p[1] else 1 for p in test_preds]\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "max confidence: 0.91\n",
      "correct: 1272\n",
      "guessed: 1277\n",
      "risked: 119647.5234375\n",
      "made: 62617.00390625\n",
      "ROI: 0.52\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "max confidence: 0.92\n",
      "correct: 661\n",
      "guessed: 1279\n",
      "risked: 113455.3203125\n",
      "made: -25223.041015625\n",
      "ROI: -0.22\n"
     ]
    }
   ],
   "source": [
    "# features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "new_y_pred = predictive(new_x_tens)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:],one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}\\n')\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "# features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "new_y_pred = predictive(new_x_tens)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2023-2024 DATA (UNSEEN)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:], one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "away_weight: 0.4625000059604645, home_weight: 0.5375000238418579\n",
      "max confidence: 0.5375000238418579\n",
      "bet on: ['Away']\n",
      "risked: [tensor(14.5136)]\n",
      "made: -14.513629913330078\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../NBA/on_off_stats/2023-2024_on_off.pkl', 'rb') as f:\n",
    "    on_off_2023_2024 = pickle.load(f)\n",
    "with open('../NBA/on_off_stats/2023-2024_team_stats.pkl', 'rb') as f:\n",
    "    team_stats_2023_2024 = pickle.load(f)\n",
    "    \n",
    "nba_szn_2023_2024 = Nba_Season('2023','2024',team_stats=team_stats_2023_2024,team_on_off=on_off_2023_2024)\n",
    "inj = {'DAL': ['OLIVIER-MAXENCE PROSPER'], 'BOS': []}\n",
    "home_stats,away_stats = nba_szn_2023_2024.calc_injury_impact(inj, 'BOS', 'DAL')\n",
    "today = torch.FloatTensor(np.subtract(away_stats,home_stats))\n",
    "\n",
    "bet_data = np.genfromtxt('test_today_with_bet.csv',delimiter=',')\n",
    "\n",
    "pyro.clear_param_store()\n",
    "today_pred = predictive(today.reshape([1,16]))['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "print(f'away_weight: {today_pred[0][0]}, home_weight: {today_pred[0][1]}')\n",
    "print(f'max confidence: {today_pred.max()}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(today_pred,samples_new_1d,bet_data[1:], one_hot=True, diff_thresh=-0.5)\n",
    "print(f'bet on: {team_bet}')\n",
    "print(f'risked: {amount}')\n",
    "print(f'made: {sum(gained)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grug\n"
     ]
    }
   ],
   "source": [
    "today_pred = predictive(today.reshape([1,16]))\n",
    "print('grug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     team_bet           probs           amount           gained\n",
      "0        Home  tensor(0.4600)  tensor(-6.2615)   tensor(3.9135)\n",
      "1        Away  tensor(0.5650)  tensor(12.0017)   tensor(9.5251)\n",
      "2        Home  tensor(0.4800)  tensor(-3.2427)   tensor(3.2427)\n",
      "3        Away  tensor(0.4900)  tensor(-1.6723)   tensor(1.1454)\n",
      "4        Home  tensor(0.4500)  tensor(-7.4134)   tensor(4.2121)\n",
      "...       ...             ...              ...              ...\n",
      "1309     Home  tensor(0.5450)   tensor(6.8437)  tensor(-6.8437)\n",
      "1310     Away  tensor(0.5250)   tensor(5.0900)  tensor(-5.0900)\n",
      "1311     Home  tensor(0.5250)   tensor(3.7279)  tensor(-3.7279)\n",
      "1312     Away  tensor(0.5050)   tensor(1.0000)   tensor(1.0000)\n",
      "1313     Home  tensor(0.4400)  tensor(-9.3366)   tensor(9.3366)\n",
      "\n",
      "[1314 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# bet_df = correct,guessed,team_bet,probs,amount,gained\n",
    "bet_dict = {\n",
    "    'team_bet': team_bet,\n",
    "    'probs': probs,\n",
    "    'amount': amount,\n",
    "    'gained': gained\n",
    "}\n",
    "bet_df = pd.DataFrame(bet_dict)\n",
    "print(bet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using consecutive game stats\n",
    "Previous training used season totals for prediction, making it unlikely (or unrealistic) that models will perform well on test sets. Data from NBA/conc_feats_samps is different as it uses the teams cumulative statistics up to the day of the game for generating features, and has 14 features instead 16. Additionally, the new samples generated are not categorical by default. First we will use the same BNN structure from above, converting the samples to 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax\n",
    "\n",
    "class BNN_Multi_Layer_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, \n",
    "                 thir_hid_dim=5, four_hid_dim=5, prior_scale=1., bias_scale=10.):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.layer3 = PyroModule[nn.Linear](sec_hid_dim, thir_hid_dim)\n",
    "        self.layer4 = PyroModule[nn.Linear](thir_hid_dim, four_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](four_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., bias_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., bias_scale).expand([sec_hid_dim,]).to_event(1))\n",
    "        self.layer3.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, thir_hid_dim]).to_event(2))\n",
    "        self.layer3.bias = PyroSample(dist.Normal(0., bias_scale).expand([thir_hid_dim,]).to_event(1))\n",
    "        self.layer4.weight = PyroSample(dist.Normal(0., prior_scale).expand([thir_hid_dim, four_hid_dim]).to_event(2))\n",
    "        self.layer4.bias = PyroSample(dist.Normal(0., bias_scale).expand([four_hid_dim,]).to_event(1))\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([four_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., bias_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias)\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias)\n",
    "        z3 = self.activation(z2 @ self.layer3.weight + self.layer3.bias)\n",
    "        z4 = self.activation(z3 @ self.layer4.weight + self.layer4.bias)\n",
    "        z5 = self.activation(z4 @ self.out.weight + self.out.bias) # output layer \n",
    "\n",
    "        y_hat = Softmax(dim=1)(z5)\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.OneHotCategorical(probs=y_hat).to_event(1), obs=y,\n",
    "                        infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale, StandardScaler\n",
    "features = np.genfromtxt('../NBA/consec/conc_feats_samps/2017-2023_features_stand.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/consec/conc_feats_samps/2017-2023_samples_stand_cat.csv',delimiter=',')\n",
    "feat_test = StandardScaler().fit_transform((np.genfromtxt('../NBA/consec/conc_feats_samps/2023-2024_nba_features_inj.csv',delimiter=',')))\n",
    "# feat_test = np.genfromtxt('../NBA/consec/conc_feats_samps/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samp_test = np.genfromtxt('../NBA/consec/conc_feats_samps/2023-2024_samples_cat.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "\n",
    "y_train = torch.Tensor(samples)\n",
    "y_test = torch.Tensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 2.9226\n",
      "[iteration 0301] loss: 2.5322\n",
      "[iteration 0601] loss: 2.4281\n",
      "[iteration 0901] loss: 2.3628\n",
      "[iteration 1201] loss: 2.3211\n",
      "[iteration 1501] loss: 2.2942\n",
      "[iteration 1801] loss: 2.2780\n",
      "[iteration 2101] loss: 2.2688\n",
      "[iteration 2401] loss: 2.2636\n",
      "[iteration 2701] loss: 2.2603\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal, AutoDiagonalNormal, AutoContinuous, AutoDelta, AutoMultivariateNormal, AutoLaplaceApproximation, AutoStructured\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "pyro.clear_param_store()\n",
    "bnn_cat = BNN_Multi_Layer_SVI(in_dim=14,first_hid_dim=56,sec_hid_dim=112,thir_hid_dim=112,four_hid_dim=56,out_dim=2,prior_scale=0.75,bias_scale=5)\n",
    "guide = AutoDelta(bnn_cat)\n",
    "# guide = AutoDiagonalNormal(bnn_cat)\n",
    "num_steps = 3000\n",
    "\n",
    "init_lr = 0.0015\n",
    "gamma = 0.01\n",
    "lrd = gamma ** (1/num_steps)\n",
    "optim = ClippedAdam({'lr': init_lr, 'lrd': lrd, \"betas\": (0.90, 0.999)})\n",
    "# optim = Adam({\"lr\": 0.001,\"betas\": (0.95, 0.999)})\n",
    "\n",
    "svi = SVI(bnn_cat, guide, optim, TraceEnum_ELBO())\n",
    "losses = []\n",
    "steps = []\n",
    "\n",
    "for i in range(num_steps):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    losses.append(loss)\n",
    "    steps.append(i)\n",
    "    if i % (num_steps/10) == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (i + 1, loss / len(x_train)))\n",
    "\n",
    "plt.plot(steps,losses)\n",
    "plt.ylabel(\"ELBO Loss\")\n",
    "plt.xlabel(\"SVI Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [1:34:04, 28.22s/it, step size=2.60e-03, acc. prob=0.921]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "pyro.clear_param_store()\n",
    "bnn_cat = BNN_Multi_Layer_SVI(in_dim=14,first_hid_dim=56,sec_hid_dim=112,thir_hid_dim=112,four_hid_dim=56,out_dim=2,prior_scale=0.75,bias_scale=5)\n",
    "nuts_kernel = NUTS(bnn_cat, jit_compile=True)\n",
    "\n",
    "# mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=200)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=100)\n",
    "\n",
    "mcmc.run(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 400/400 [1:23:37, 12.54s/it, step size=4.06e-03, acc. prob=0.881]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "pyro.clear_param_store()\n",
    "bnn_cat = BNN_Multi_Layer_SVI(in_dim=14,first_hid_dim=14,sec_hid_dim=28,thir_hid_dim=28,four_hid_dim=14,out_dim=2,prior_scale=1,bias_scale=5)\n",
    "nuts_kernel = NUTS(bnn_cat, jit_compile=True)\n",
    "\n",
    "# mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=200)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=bnn_cat, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[4165  900 1873 1952]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75      5065\n",
      "           1       0.68      0.51      0.58      3825\n",
      "\n",
      "    accuracy                           0.69      8890\n",
      "   macro avg       0.69      0.67      0.67      8890\n",
      "weighted avg       0.69      0.69      0.68      8890\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[560 158 310 286]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.71       718\n",
      "           1       0.64      0.48      0.55       596\n",
      "\n",
      "    accuracy                           0.64      1314\n",
      "   macro avg       0.64      0.63      0.63      1314\n",
      "weighted avg       0.64      0.64      0.63      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> home win -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "train_preds = predictive(x_train)['_RETURN'].float().mean(axis=0)\n",
    "adj_train_preds = [0 if p[0] < p[1] else 1 for p in train_preds]\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "test_preds = predictive(x_test)['_RETURN'].float().mean(axis=0)\n",
    "adj_test_preds = [0 if p[0] < p[1] else 1 for p in test_preds]\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "max confidence: 0.90\n",
      "correct: 686\n",
      "guessed: 1070\n",
      "risked: 39551.66015625\n",
      "made: 3483.553466796875\n",
      "ROI: 0.09\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "max confidence: 0.96\n",
      "correct: 659\n",
      "guessed: 1313\n",
      "risked: 39526.2734375\n",
      "made: -6355.5283203125\n",
      "ROI: -0.16\n"
     ]
    }
   ],
   "source": [
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "# bet_train = torch.FloatTensor(np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "# bet_train = torch.FloatTensor(minmax_scale(np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=',')))\n",
    "bet_train = torch.FloatTensor(StandardScaler().fit_transform((np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=','))))\n",
    "bet_samps = np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_samps_1d = [0 if j[0] < j[1] else 1 for j in bet_samps]\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "new_y_pred = predictive(bet_train)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "# new_y_pred = predictive(bet_train)['_RETURN'].float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,bet_samps_1d,bet_data[1:],one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}\\n')\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "new_y_pred = predictive(x_test)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "# new_y_pred = predictive(x_test)['_RETURN'].float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2023-2024 DATA (UNSEEN)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,y_test_1d,bet_data[1:], one_hot=True, diff_thresh=-50.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "max confidence: 0.85\n",
      "correct: 688\n",
      "guessed: 1009\n",
      "risked: 31201.240234375\n",
      "made: 6047.7021484375\n",
      "ROI: 0.19\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "max confidence: 0.84\n",
      "correct: 687\n",
      "guessed: 1313\n",
      "risked: 33340.66015625\n",
      "made: -5032.83984375\n",
      "ROI: -0.15\n"
     ]
    }
   ],
   "source": [
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "# bet_train = torch.FloatTensor(np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "# bet_train = torch.FloatTensor(minmax_scale(np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=',')))\n",
    "bet_train = torch.FloatTensor(StandardScaler().fit_transform((np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=','))))\n",
    "bet_samps = np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_samps_1d = [0 if j[0] < j[1] else 1 for j in bet_samps]\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(bet_train)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "new_y_pred = predictive(bet_train)['_RETURN'].float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,bet_samps_1d,bet_data[1:],one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}\\n')\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(x_test)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "new_y_pred = predictive(x_test)['_RETURN'].float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2023-2024 DATA (UNSEEN)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,y_test_1d,bet_data[1:], one_hot=True, diff_thresh=-50.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[4098  967 1316 2509]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78      5065\n",
      "           1       0.72      0.66      0.69      3825\n",
      "\n",
      "    accuracy                           0.74      8890\n",
      "   macro avg       0.74      0.73      0.73      8890\n",
      "weighted avg       0.74      0.74      0.74      8890\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[545 173 333 263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       718\n",
      "           1       0.60      0.44      0.51       596\n",
      "\n",
      "    accuracy                           0.61      1314\n",
      "   macro avg       0.61      0.60      0.60      1314\n",
      "weighted avg       0.61      0.61      0.60      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "predictive = Predictive(bnn_cat, guide=guide, num_samples=500, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> home win -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "train_preds = predictive(x_train)['_RETURN'].float().mean(axis=0)\n",
    "adj_train_preds = [0 if p[0] < p[1] else 1 for p in train_preds]\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "test_preds = predictive(x_test)['_RETURN'].float().mean(axis=0)\n",
    "adj_test_preds = [0 if p[0] < p[1] else 1 for p in test_preds]\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[4989   76  160 3665]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      5065\n",
      "           1       0.98      0.96      0.97      3825\n",
      "\n",
      "    accuracy                           0.97      8890\n",
      "   macro avg       0.97      0.97      0.97      8890\n",
      "weighted avg       0.97      0.97      0.97      8890\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[469 249 307 289]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.63       718\n",
      "           1       0.54      0.48      0.51       596\n",
      "\n",
      "    accuracy                           0.58      1314\n",
      "   macro avg       0.57      0.57      0.57      1314\n",
      "weighted avg       0.57      0.58      0.57      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "predictive = Predictive(bnn_cat, guide=guide, num_samples=500, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> home win -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "adj_train_preds = [0 if p[0] < p[1] else 1 for p in train_preds]\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "test_preds = predictive(x_test)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "adj_test_preds = [0 if p[0] < p[1] else 1 for p in test_preds]\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "predictive = Predictive(bnn_cat, guide=guide, num_samples=2000, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "max confidence: 0.93\n",
      "correct: 1241\n",
      "guessed: 1273\n",
      "risked: 116853.859375\n",
      "made: 56452.7109375\n",
      "ROI: 0.48\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "max confidence: 0.92\n",
      "correct: 745\n",
      "guessed: 1313\n",
      "risked: 109176.2734375\n",
      "made: -18509.009765625\n",
      "ROI: -0.17\n"
     ]
    }
   ],
   "source": [
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "# bet_train = torch.FloatTensor(np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "# bet_train = torch.FloatTensor(minmax_scale(np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=',')))\n",
    "bet_train = torch.FloatTensor(StandardScaler().fit_transform((np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=','))))\n",
    "bet_samps = np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_samps_1d = [0 if j[0] < j[1] else 1 for j in bet_samps]\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "new_y_pred = predictive(bet_train)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "# new_y_pred = predictive(bet_train)['_RETURN'].float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,bet_samps_1d,bet_data[1:],one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}\\n')\n",
    "\n",
    "# # Test on 2023-2024 data\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "new_y_pred = predictive(x_test)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "# new_y_pred = predictive(x_test)['_RETURN'].float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2023-2024 DATA (UNSEEN)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,y_test_1d,bet_data[1:], one_hot=True, diff_thresh=-50.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "max confidence: 0.85\n",
      "correct: 688\n",
      "guessed: 1009\n",
      "risked: 31201.240234375\n",
      "made: 6047.7021484375\n",
      "ROI: 0.19\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "max confidence: 0.84\n",
      "correct: 536\n",
      "guessed: 1031\n",
      "risked: 31616.48828125\n",
      "made: -5193.66748046875\n",
      "ROI: -0.16\n"
     ]
    }
   ],
   "source": [
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "# bet_train = torch.FloatTensor(np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "# bet_train = torch.FloatTensor(minmax_scale(np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=',')))\n",
    "bet_train = torch.FloatTensor(StandardScaler().fit_transform((np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=','))))\n",
    "bet_samps = np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_samps_1d = [0 if j[0] < j[1] else 1 for j in bet_samps]\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(bet_train)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "new_y_pred = predictive(bet_train)['_RETURN'].float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,bet_samps_1d,bet_data[1:],one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}\\n')\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(x_test)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "new_y_pred = predictive(x_test)['_RETURN'].float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2023-2024 DATA (UNSEEN)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,y_test_1d,bet_data[1:], one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different normalization technique\n",
    "Improving quality of data could be useful, we will explore the performance of a simple BNN on unnormalized, minmax norm, maxabs norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnormalized\n",
    "First, we will construct a new unnormalized features file from 2014/2015 to 2022/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "features = []\n",
    "feat_minmax = []\n",
    "feat_maxabs = []\n",
    "samples = []\n",
    "start = 2014\n",
    "\n",
    "while start < 2023:\n",
    "    if start == 2018: # this year is missing and wont populate thru scraper!!\n",
    "        start += 1\n",
    "        continue\n",
    "\n",
    "    curr_feats = np.genfromtxt('../NBA/total/samps_feats/{start}-{end}_nba_features_inj.csv'.format(start=start,end=start+1),delimiter=',')\n",
    "    curr_samps = np.genfromtxt('../NBA/total/samps_feats/{start}-{end}_nba_samples_inj.csv'.format(start=start,end=start+1),delimiter=',')\n",
    "    feat_minmax.extend(minmax_scale(curr_feats))\n",
    "    feat_maxabs.extend(maxabs_scale(curr_feats))\n",
    "    features.extend(curr_feats)\n",
    "    samples.extend(curr_samps)\n",
    "    start += 1\n",
    "\n",
    "\n",
    "np.savetxt('../NBA/total/samps_feats/2015-2023_nba_features_unnorm.csv', features, delimiter=',')\n",
    "np.savetxt('../NBA/total/samps_feats/2015-2023_nba_samples.csv', samples, delimiter=',')\n",
    "np.savetxt('../NBA/total/samps_feats/2015-2023_nba_features_minmax.csv', features, delimiter=',')\n",
    "np.savetxt('../NBA/total/samps_feats/2015-2023_nba_features_maxabs.csv', features, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_15840\\2636246682.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  x_train = torch.FloatTensor(features)\n"
     ]
    }
   ],
   "source": [
    "feat_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',') # unnormalized\n",
    "samp_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samples)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [01:35,  1.05it/s, step size=4.07e-02, acc. prob=0.788]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "x_train = torch.FloatTensor(feat_maxabs)\n",
    "x_test = torch.FloatTensor(maxabs_scale(feat_test))\n",
    "y_train = torch.FloatTensor(samples)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "model = BNN(in_dim=16,hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# Define Hamiltonian Monte Carlo (HMC) kernel\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(model, jit_compile=False)  # jit_compile=True is faster but requires PyTorch 1.6+\n",
    "\n",
    "# Define MCMC sampler, get 50 posterior samples\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2384 2925 2191 2874]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.45      0.48      5309\n",
      "           1       0.50      0.57      0.53      5065\n",
      "\n",
      "    accuracy                           0.51     10374\n",
      "   macro avg       0.51      0.51      0.51     10374\n",
      "weighted avg       0.51      0.51      0.51     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[296 365 267 386]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.48       661\n",
      "           1       0.51      0.59      0.55       653\n",
      "\n",
      "    accuracy                           0.52      1314\n",
      "   macro avg       0.52      0.52      0.52      1314\n",
      "weighted avg       0.52      0.52      0.52      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "106\n",
      "tensor(-746.6345)\n",
      "49\n",
      "118\n",
      "tensor(-704.2104)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
