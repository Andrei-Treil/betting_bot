{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making bets on NBA games using Bayesian Neural Networks\n",
    "The goal of this notebook is to explore the use of Bayesian Neural Networks (BNNs) in predicting the outcome of NBA games. While using MLPs as seen in ```mlp_betting.ipynb``` may be computationally more efficient, personal testing has shown that tradional neural networks are overconfident in predictions making them unsuitable for betting. By learning the distributions of weights, BNNs can hopefully provide a better estimate on the outcome of games for use in betting.\n",
    "\n",
    "To test betting capability, we will use historic betting data gathered from vegasinsider.com to determine the money made from each model's predictions. The goal of the model is not to maximize accuracy (as NBA games are incredibly stochastic), but instead to maximize performance relative to odds set by Vegas. The algorithm for placing bets will be a modified version of the [kelly critereon](https://en.wikipedia.org/wiki/Kelly_criterion) betting strategy, defined in the functions ```kelly``` and ```BNN_kelly``` found in **util/client.py**.\n",
    "\n",
    "NOTE: The most recent and relevant exploration in this notebook is being done in the [**Using consecutive games stats**](#Using-consecutive-game-stats) section. Previous sections use old data, which is based on end of year totals for each team. More detail on how these datasets differ is available in the afformentioned section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_validate,cross_val_predict\n",
    "from sklearn.metrics import classification_report,confusion_matrix,make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from util.client import Nba_Season, kelly, BNN_kelly, make_bets, pred_performance\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Softmax\n",
    "from pyro.infer import MCMC, NUTS\n",
    "from pyro.infer import Predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define simple BNN using Pyro containing 1 hidden layer\n",
    "\n",
    "For this implementation, we will be using the [Pyro Probablistic Programming language](https://github.com/pyro-ppl/pyro), loosely following a [tutorial](https://colab.research.google.com/drive/1NQNMdKaE9RncuWgO_vM2k3qywV76Byfh) from the University of Amsterdam\n",
    "\n",
    "Currently, the model will only be predicting the outcomes of games (home win or away win) and compare outcomes to moneyline odds from [vegas insider](https://www.vegasinsider.com/nba/odds/las-vegas/). Because of this, the model will be learning a categorical output, 0 indicating a home win and 1 indicating away win. The model will sample each layers weights and biases from a normal distribution while the prediction will be sampled from a categorical distribution based on the output of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim, out_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru output layer\n",
    "\n",
    "        #, x.shape[0]\n",
    "        with pyro.plate(\"data\"):\n",
    "            y_hat = Softmax(dim=1)(z2) # scale output via softmax for setting categorical priors\n",
    "            # y_hat = Softmax(dim=0)(x)\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(y_hat), obs=y)\n",
    "\n",
    "        return z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [07:31,  4.51s/it, step size=1.17e-02, acc. prob=0.450]\n"
     ]
    }
   ],
   "source": [
    "# load old samples and features\n",
    "features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features, samples, test_size=0.25, random_state=1)\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "model = BNN(in_dim=16,hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# Define Hamiltonian Monte Carlo (HMC) kernel\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(model, jit_compile=False)  # jit_compile=True is faster but requires PyTorch 1.6+\n",
    "\n",
    "# Define MCMC sampler, get 50 posterior samples\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[1969 2431 1894 2343]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48      4400\n",
      "           1       0.49      0.55      0.52      4237\n",
      "\n",
      "    accuracy                           0.50      8637\n",
      "   macro avg       0.50      0.50      0.50      8637\n",
      "weighted avg       0.50      0.50      0.50      8637\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[678 813 596 793]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.49      1491\n",
      "           1       0.49      0.57      0.53      1389\n",
      "\n",
      "    accuracy                           0.51      2880\n",
      "   macro avg       0.51      0.51      0.51      2880\n",
      "weighted avg       0.51      0.51      0.51      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1) # each x in training produces 50 predictions (0 or 1), take average\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place bets using `BNN_Kelly` on 2022-2023 and 2023-2024 seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "104\n",
      "tensor(-465.6457)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "56\n",
      "tensor(-331.8321)\n"
     ]
    }
   ],
   "source": [
    "# Test on 2023-2024 data\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial testing yielded better results than traditional MLPs as seen in ``mlp_betting.ipynb``, explore BNN architecture with more layers\n",
    "Add a single hidden layer to our existing architecture and increase the number of posterior samples used during MCMC training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN_Multi_Layer(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](sec_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru sec layer\n",
    "        z3 = self.activation(z2 @ self.out.weight + self.out.bias) # output layer\n",
    "\n",
    "        #, x.shape[0]\n",
    "        with pyro.plate(\"data\"):\n",
    "            y_hat = Softmax(dim=1)(z3)\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(y_hat), obs=y)\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 2014/2015-2022/2023 NBA seasons to train, make predictions on 2023/2024 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [12:59,  7.80s/it, step size=2.89e-03, acc. prob=0.723]\n"
     ]
    }
   ],
   "source": [
    "# load old samples and features\n",
    "feat_train = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samp_train = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samp_train_1d = [0 if j[0] == 0 else 1 for j in samp_train]\n",
    "\n",
    "feat_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',') # unnormalized\n",
    "samp_test = np.genfromtxt('../NBA/total/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',') # unnormalized\n",
    "feat_test_norm = [[float(i)/sum(j) for i in j ]for j in feat_test]\n",
    "samp_test_1d = [0 if j[0] == 0 else 1 for j in samp_test]\n",
    "\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test_norm)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "new_model = BNN_Multi_Layer(in_dim=16,first_hid_dim=16,sec_hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(new_model, jit_compile=True)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2582 3309 2475 3151]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.44      0.47      5891\n",
      "           1       0.49      0.56      0.52      5626\n",
      "\n",
      "    accuracy                           0.50     11517\n",
      "   macro avg       0.50      0.50      0.50     11517\n",
      "weighted avg       0.50      0.50      0.50     11517\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[272 389 297 356]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.41      0.44       661\n",
      "           1       0.48      0.55      0.51       653\n",
      "\n",
      "    accuracy                           0.48      1314\n",
      "   macro avg       0.48      0.48      0.48      1314\n",
      "weighted avg       0.48      0.48      0.48      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/200 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [27:06,  8.13s/it, step size=3.46e-03, acc. prob=0.594]\n"
     ]
    }
   ],
   "source": [
    "# load old samples and features\n",
    "features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features, samples, test_size=0.25, random_state=1)\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "new_model = BNN_Multi_Layer(in_dim=16,first_hid_dim=16,sec_hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(new_model, jit_compile=True)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2041 2359 1925 2312]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.46      0.49      4400\n",
      "           1       0.49      0.55      0.52      4237\n",
      "\n",
      "    accuracy                           0.50      8637\n",
      "   macro avg       0.50      0.50      0.50      8637\n",
      "weighted avg       0.50      0.50      0.50      8637\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[698 793 619 770]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50      1491\n",
      "           1       0.49      0.55      0.52      1389\n",
      "\n",
      "    accuracy                           0.51      2880\n",
      "   macro avg       0.51      0.51      0.51      2880\n",
      "weighted avg       0.51      0.51      0.51      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "64\n",
      "tensor(-19.2364)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "52\n",
      "tensor(-316.8422)\n"
     ]
    }
   ],
   "source": [
    "# Test on 2023-2024 data\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our new structure yielded better results, however at a significant cost to runtime. Explore the use of Stochastic Variational Inference for training: \n",
    "Simple single layer BNN, using SVI with AutoNormal guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax, Softmax\n",
    "\n",
    "class BNN_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](first_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.out.weight + self.out.bias) # output layer\n",
    "        y_hat = LogSoftmax(dim=1)(z2) # scale output via softmax for setting categorical priors\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(logits=y_hat).to_event(1), obs=y)\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 1.5100\n",
      "[iteration 0101] loss: 1.4795\n",
      "[iteration 0201] loss: 1.4451\n",
      "[iteration 0301] loss: 1.4494\n",
      "[iteration 0401] loss: 1.4377\n",
      "[iteration 0501] loss: 1.4332\n",
      "[iteration 0601] loss: 1.4339\n",
      "[iteration 0701] loss: 1.4340\n",
      "[iteration 0801] loss: 1.4319\n",
      "[iteration 0901] loss: 1.4302\n",
      "[iteration 1001] loss: 1.4300\n",
      "[iteration 1101] loss: 1.4309\n",
      "[iteration 1201] loss: 1.4292\n",
      "[iteration 1301] loss: 1.4282\n",
      "[iteration 1401] loss: 1.4264\n",
      "[iteration 1501] loss: 1.4273\n",
      "[iteration 1601] loss: 1.4241\n",
      "[iteration 1701] loss: 1.4240\n",
      "[iteration 1801] loss: 1.4253\n",
      "[iteration 1901] loss: 1.4234\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_maxabs.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples.csv',delimiter=',')\n",
    "feat_test = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samp_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.Tensor(samples.T)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "\n",
    "pyro.clear_param_store()\n",
    "new_model = BNN_SVI(in_dim=16,first_hid_dim=16,out_dim=2)\n",
    "guide = AutoNormal(new_model)\n",
    "\n",
    "svi = SVI(new_model, guide, Adam({\"lr\": 1e-3}), Trace_ELBO())\n",
    "steps = 2000\n",
    "\n",
    "for step in range(steps):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    if step % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (step + 1, loss / len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2547 2762 2381 2684]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.48      0.50      5309\n",
      "           1       0.49      0.53      0.51      5065\n",
      "\n",
      "    accuracy                           0.50     10374\n",
      "   macro avg       0.50      0.50      0.50     10374\n",
      "weighted avg       0.51      0.50      0.50     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[312 349 303 350]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49       661\n",
      "           1       0.50      0.54      0.52       653\n",
      "\n",
      "    accuracy                           0.50      1314\n",
      "   macro avg       0.50      0.50      0.50      1314\n",
      "weighted avg       0.50      0.50      0.50      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictive = Predictive(new_model, guide=guide, num_samples=400, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=2)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train.T] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple BNN structure saw significant improvement in runtime, and produces much less confident predictions. Lets try a more complex structure now:\n",
    "## Multi-Layer BNN w/ SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax\n",
    "\n",
    "class BNN_Multi_Layer_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, thir_hid_dim=5, prior_scale=1., bias_scale=10.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.layer3 = PyroModule[nn.Linear](sec_hid_dim, thir_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](thir_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., bias_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., bias_scale).expand([sec_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.layer3.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, thir_hid_dim]).to_event(2))\n",
    "        self.layer3.bias = PyroSample(dist.Normal(0., bias_scale).expand([thir_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([thir_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., bias_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru sec layer\n",
    "        z3 = self.activation(z2 @ self.layer3.weight + self.layer3.bias) # output layer\n",
    "        z4 = self.activation(z3 @ self.out.weight + self.out.bias) # output layer\n",
    "\n",
    "        y_hat = Softmax(dim=1)(z4)\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.OneHotCategorical(probs=y_hat).to_event(1), obs=y,\n",
    "                        infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "# features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_maxabs.csv',delimiter=',')\n",
    "features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_unnorm.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples.csv',delimiter=',')\n",
    "# feat_test = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "feat_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samp_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.Tensor(samples)\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train]\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 9.0015\n",
      "[iteration 0501] loss: 8.6606\n",
      "[iteration 1001] loss: 8.6255\n",
      "[iteration 1501] loss: 8.6025\n",
      "[iteration 2001] loss: 8.5860\n",
      "[iteration 2501] loss: 8.5771\n",
      "[iteration 3001] loss: 8.5705\n",
      "[iteration 3501] loss: 8.5657\n",
      "[iteration 4001] loss: 8.5626\n",
      "[iteration 4501] loss: 8.5610\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal, AutoDiagonalNormal, AutoContinuous, AutoDelta, AutoMultivariateNormal, AutoLaplaceApproximation, AutoStructured\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "pyro.clear_param_store()\n",
    "bnn_cat = BNN_Multi_Layer_SVI(in_dim=16,first_hid_dim=128,sec_hid_dim=128,thir_hid_dim=128,out_dim=2,prior_scale=4,bias_scale=10)\n",
    "guide = AutoDelta(bnn_cat)\n",
    "num_steps = 5000\n",
    "\n",
    "init_lr = 0.001\n",
    "gamma = 0.01\n",
    "lrd = gamma ** (1/num_steps)\n",
    "optim = ClippedAdam({'lr': init_lr, 'lrd': lrd, \"betas\": (0.95, 0.999)})\n",
    "# optim = Adam({\"lr\": 0.01,\"betas\": (0.95, 0.999)})\n",
    "\n",
    "svi = SVI(bnn_cat, guide, optim, TraceEnum_ELBO())\n",
    "losses = []\n",
    "steps = []\n",
    "\n",
    "for i in range(num_steps):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    losses.append(loss)\n",
    "    steps.append(i)\n",
    "    if i % (num_steps/10) == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (i + 1, loss / len(x_train)))\n",
    "\n",
    "plt.plot(steps,losses)\n",
    "plt.ylabel(\"ELBO Loss\")\n",
    "plt.xlabel(\"SVI Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[4054 1255 1679 3386]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73      5309\n",
      "           1       0.73      0.67      0.70      5065\n",
      "\n",
      "    accuracy                           0.72     10374\n",
      "   macro avg       0.72      0.72      0.72     10374\n",
      "weighted avg       0.72      0.72      0.72     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[360 301 361 292]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.54      0.52       661\n",
      "           1       0.49      0.45      0.47       653\n",
      "\n",
      "    accuracy                           0.50      1314\n",
      "   macro avg       0.50      0.50      0.49      1314\n",
      "weighted avg       0.50      0.50      0.50      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "predictive = Predictive(bnn_cat, guide=guide, num_samples=1000, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> home win -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "adj_train_preds = [0 if p[0] < p[1] else 1 for p in train_preds]\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "test_preds = predictive(x_test)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "adj_test_preds = [0 if p[0] < p[1] else 1 for p in test_preds]\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "max confidence: 0.91\n",
      "correct: 1272\n",
      "guessed: 1277\n",
      "risked: 119647.5234375\n",
      "made: 62617.00390625\n",
      "ROI: 0.52\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "max confidence: 0.92\n",
      "correct: 661\n",
      "guessed: 1279\n",
      "risked: 113455.3203125\n",
      "made: -25223.041015625\n",
      "ROI: -0.22\n"
     ]
    }
   ],
   "source": [
    "# features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "new_y_pred = predictive(new_x_tens)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:],one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}\\n')\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "# features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "new_y_pred = predictive(new_x_tens)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2023-2024 DATA (UNSEEN)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:], one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using consecutive game stats\n",
    "Previous training used season totals for prediction, making it unlikely (or unrealistic) that models will perform well on test sets. Data from NBA/conc_feats_samps is different as it uses the teams cumulative statistics up to the day of the game for generating features, and has 14 features instead 16. Additionally, the new samples generated are not categorical by default. \n",
    "\n",
    "First we will explore the efficacy of this data in SVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax\n",
    "\n",
    "class BNN_Multi_Layer_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, \n",
    "                 thir_hid_dim=5, four_hid_dim=5, prior_scale=1., bias_scale=10.):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.layer3 = PyroModule[nn.Linear](sec_hid_dim, thir_hid_dim)\n",
    "        self.layer4 = PyroModule[nn.Linear](thir_hid_dim, four_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](four_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., bias_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., bias_scale).expand([sec_hid_dim,]).to_event(1))\n",
    "        self.layer3.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, thir_hid_dim]).to_event(2))\n",
    "        self.layer3.bias = PyroSample(dist.Normal(0., bias_scale).expand([thir_hid_dim,]).to_event(1))\n",
    "        self.layer4.weight = PyroSample(dist.Normal(0., prior_scale).expand([thir_hid_dim, four_hid_dim]).to_event(2))\n",
    "        self.layer4.bias = PyroSample(dist.Normal(0., bias_scale).expand([four_hid_dim,]).to_event(1))\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([four_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., bias_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias)\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias)\n",
    "        z3 = self.activation(z2 @ self.layer3.weight + self.layer3.bias)\n",
    "        z4 = self.activation(z3 @ self.layer4.weight + self.layer4.bias)\n",
    "        z5 = self.activation(z4 @ self.out.weight + self.out.bias) # output layer \n",
    "\n",
    "        y_hat = Softmax(dim=1)(z5)\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.OneHotCategorical(probs=y_hat).to_event(1), obs=y,\n",
    "                        infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax\n",
    "\n",
    "class BNN_Adj(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, \n",
    "                 thir_hid_dim=5, four_hid_dim=5, fifth_hid_dim=5, prior_scale=1., bias_scale=10.):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.layer3 = PyroModule[nn.Linear](sec_hid_dim, thir_hid_dim)\n",
    "        self.layer4 = PyroModule[nn.Linear](thir_hid_dim, four_hid_dim)\n",
    "        self.layer5 = PyroModule[nn.Linear](four_hid_dim, fifth_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](fifth_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., bias_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., bias_scale).expand([sec_hid_dim,]).to_event(1))\n",
    "        self.layer3.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, thir_hid_dim]).to_event(2))\n",
    "        self.layer3.bias = PyroSample(dist.Normal(0., bias_scale).expand([thir_hid_dim,]).to_event(1))\n",
    "        self.layer4.weight = PyroSample(dist.Normal(0., prior_scale).expand([thir_hid_dim, four_hid_dim]).to_event(2))\n",
    "        self.layer4.bias = PyroSample(dist.Normal(0., bias_scale).expand([four_hid_dim,]).to_event(1))\n",
    "        self.layer5.weight = PyroSample(dist.Normal(0., prior_scale).expand([four_hid_dim, fifth_hid_dim]).to_event(2))\n",
    "        self.layer5.bias = PyroSample(dist.Normal(0., bias_scale).expand([fifth_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([fifth_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., bias_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias)\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias)\n",
    "        z3 = self.activation(z2 @ self.layer3.weight + self.layer3.bias)\n",
    "        z4 = self.activation(z3 @ self.layer4.weight + self.layer4.bias)\n",
    "        z5 = self.activation(z4 @ self.layer5.weight + self.layer5.bias) # output layer \n",
    "        z6 = self.activation(z5 @ self.out.weight + self.out.bias) # output layer \n",
    "\n",
    "        y_hat = Softmax(dim=1)(z6)\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.OneHotCategorical(probs=y_hat).to_event(1), obs=y,\n",
    "                        infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale, StandardScaler\n",
    "features = np.genfromtxt('../NBA/consec/conc_feats_samps/2017-2023_features_stand.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/consec/conc_feats_samps/2017-2023_samples_stand_cat.csv',delimiter=',')\n",
    "feat_test = StandardScaler().fit_transform((np.genfromtxt('../NBA/consec/conc_feats_samps/2023-2024_nba_features_inj.csv',delimiter=',')))\n",
    "# feat_test = np.genfromtxt('../NBA/consec/conc_feats_samps/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samp_test = np.genfromtxt('../NBA/consec/conc_feats_samps/2023-2024_samples_cat.csv',delimiter=',')\n",
    "bet_data_train = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "bet_data_test = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "bet_train = torch.FloatTensor(StandardScaler().fit_transform((np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=','))))\n",
    "bet_samps_train = np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "\n",
    "y_train = torch.Tensor(samples)\n",
    "y_test = torch.Tensor(samp_test)\n",
    "\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> home win -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 1.5486\n",
      "[iteration 0201] loss: 1.4371\n",
      "[iteration 0401] loss: 1.4243\n",
      "[iteration 0601] loss: 1.4165\n",
      "[iteration 0801] loss: 1.4128\n",
      "[iteration 1001] loss: 1.4112\n",
      "[iteration 1201] loss: 1.4106\n",
      "[iteration 1401] loss: 1.4103\n",
      "[iteration 1601] loss: 1.4102\n",
      "[iteration 1801] loss: 1.4101\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal, AutoDiagonalNormal, AutoContinuous, AutoDelta, AutoMultivariateNormal, AutoLaplaceApproximation, AutoStructured\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "from torch.nn import LogSoftmax\n",
    "\n",
    "pyro.clear_param_store()\n",
    "# bnn_cat = BNN_Multi_Layer_SVI(in_dim=14,first_hid_dim=28,sec_hid_dim=56,thir_hid_dim=56,four_hid_dim=28,out_dim=2,prior_scale=0.75,bias_scale=10)\n",
    "bnn_cat = BNN_Adj(in_dim=14,first_hid_dim=28,sec_hid_dim=56,thir_hid_dim=56,four_hid_dim=56,fifth_hid_dim=28,out_dim=2,prior_scale=0.75,bias_scale=5)\n",
    "guide = AutoDelta(bnn_cat)\n",
    "# guide = AutoDiagonalNormal(bnn_cat)\n",
    "\n",
    "num_steps = 2000\n",
    "\n",
    "init_lr = 0.001\n",
    "gamma = 0.0001\n",
    "lrd = gamma ** (1/num_steps)\n",
    "optim = ClippedAdam({'lr': init_lr, 'lrd': lrd, \"betas\": (0.95, 0.999)})\n",
    "# optim = Adam({\"lr\": 0.001,\"betas\": (0.95, 0.999)})\n",
    "\n",
    "svi = SVI(bnn_cat, guide, optim, TraceEnum_ELBO())\n",
    "losses = []\n",
    "steps = []\n",
    "\n",
    "for i in range(num_steps):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    losses.append(loss)\n",
    "    steps.append(i)\n",
    "    if i % (num_steps/10) == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (i + 1, loss / len(x_train)))\n",
    "\n",
    "plt.plot(steps,losses)\n",
    "plt.ylabel(\"ELBO Loss\")\n",
    "plt.xlabel(\"SVI Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "OBS:\n",
      "TN, FP, FN, TP\n",
      "[4005 1060 1841 1984]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.73      5065\n",
      "           1       0.65      0.52      0.58      3825\n",
      "\n",
      "    accuracy                           0.67      8890\n",
      "   macro avg       0.67      0.65      0.66      8890\n",
      "weighted avg       0.67      0.67      0.67      8890\n",
      "\n",
      "RET:\n",
      "TN, FP, FN, TP\n",
      "[4002 1063 1844 1981]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73      5065\n",
      "           1       0.65      0.52      0.58      3825\n",
      "\n",
      "    accuracy                           0.67      8890\n",
      "   macro avg       0.67      0.65      0.66      8890\n",
      "weighted avg       0.67      0.67      0.67      8890\n",
      "\n",
      "---TEST SET---\n",
      "OBS:\n",
      "TN, FP, FN, TP\n",
      "[563 155 324 272]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.78      0.70       718\n",
      "           1       0.64      0.46      0.53       596\n",
      "\n",
      "    accuracy                           0.64      1314\n",
      "   macro avg       0.64      0.62      0.62      1314\n",
      "weighted avg       0.64      0.64      0.62      1314\n",
      "\n",
      "RET:\n",
      "TN, FP, FN, TP\n",
      "[562 156 336 260]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.78      0.70       718\n",
      "           1       0.62      0.44      0.51       596\n",
      "\n",
      "    accuracy                           0.63      1314\n",
      "   macro avg       0.63      0.61      0.60      1314\n",
      "weighted avg       0.63      0.63      0.61      1314\n",
      "\n",
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "Using OBS:\n",
      "max confidence: 0.88\n",
      "correct: 455\n",
      "guessed: 666\n",
      "risked: 25362.447265625\n",
      "made: 1865.4874267578125\n",
      "ROI: 0.07\n",
      "\n",
      "Using RET:\n",
      "max confidence: 0.87\n",
      "correct: 452\n",
      "guessed: 664\n",
      "risked: 25066.515625\n",
      "made: 1807.0933837890625\n",
      "ROI: 0.07\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "Using OBS:\n",
      "max confidence: 0.89\n",
      "correct: 420\n",
      "guessed: 633\n",
      "risked: 25136.783203125\n",
      "made: -95.18768310546875\n",
      "ROI: -0.00\n",
      "\n",
      "Using RET:\n",
      "max confidence: 0.87\n",
      "correct: 421\n",
      "guessed: 631\n",
      "risked: 25299.1953125\n",
      "made: -83.26776123046875\n",
      "ROI: -0.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "predictive = Predictive(bnn_cat, guide=guide, num_samples=500, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "\n",
    "pred_performance(predictive,x_train,x_test,y_train,y_test)\n",
    "make_bets(predictive,bet_data_train,bet_data_test,bet_train,x_test,bet_samps_train,y_test,diff_thresh=0.05,diff_cap=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [1:34:04, 28.22s/it, step size=2.60e-03, acc. prob=0.921]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "pyro.clear_param_store()\n",
    "bnn_mcmc = BNN_Multi_Layer_SVI(in_dim=14,first_hid_dim=56,sec_hid_dim=112,thir_hid_dim=112,four_hid_dim=56,out_dim=2,prior_scale=0.75,bias_scale=5)\n",
    "nuts_kernel = NUTS(bnn_mcmc, jit_compile=True)\n",
    "\n",
    "# mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=200)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=100)\n",
    "\n",
    "mcmc.run(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c79ec9e6e944e98b2a1d12b61fe92f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [1]:   0%|          | 0/150 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c2874ae8274da380f0a768291aca01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [2]:   0%|          | 0/150 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ea9ffb02c641c2a78a35a3a775f98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [3]:   0%|          | 0/150 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ec041b1c8a4df2ae0fb261d31a520b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [4]:   0%|          | 0/150 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84afe952197f42e588230f5525c878f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [5]:   0%|          | 0/150 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=200)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m mcmc \u001b[38;5;241m=\u001b[39m MCMC(nuts_kernel, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m75\u001b[39m, num_chains\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmcmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\CS\\betting_bot\\.venv\\Lib\\site-packages\\pyro\\poutine\\messenger.py:32\u001b[0m, in \u001b[0;36m_context_wrap\u001b[1;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_context_wrap\u001b[39m(\n\u001b[0;32m     26\u001b[0m     context: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessenger\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     fn: Callable,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;241m*\u001b[39margs: Any,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m     30\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m context:\n\u001b[1;32m---> 32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\CS\\betting_bot\\.venv\\Lib\\site-packages\\pyro\\infer\\mcmc\\api.py:565\u001b[0m, in \u001b[0;36mMCMC.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m optional(\n\u001b[0;32m    557\u001b[0m     pyro\u001b[38;5;241m.\u001b[39mvalidation_enabled(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_validation),\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_validation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;66;03m# This also resolves \"RuntimeError: Cowardly refusing to serialize non-leaf tensor which\u001b[39;00m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;66;03m# requires_grad\", which happens with `jit_compile` under PyTorch 1.7\u001b[39;00m\n\u001b[0;32m    564\u001b[0m     args \u001b[38;5;241m=\u001b[39m [arg\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(arg) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 565\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchain_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchain_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\CS\\betting_bot\\.venv\\Lib\\site-packages\\pyro\\infer\\mcmc\\api.py:338\u001b[0m, in \u001b[0;36m_MultiSampler.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m active_workers:\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 338\u001b[0m         chain_id, val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\multiprocessing\\connection.py:346\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    344\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\multiprocessing\\connection.py:1084\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m   1081\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m   1082\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1084\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m   1087\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\multiprocessing\\connection.py:1016\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m   1014\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m-> 1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "pyro.clear_param_store()\n",
    "bnn_mcmc = BNN_Multi_Layer_SVI(in_dim=14,first_hid_dim=14,sec_hid_dim=14,thir_hid_dim=14,four_hid_dim=14,out_dim=2,prior_scale=0.75,bias_scale=5)\n",
    "nuts_kernel = NUTS(bnn_mcmc, jit_compile=True)\n",
    "\n",
    "# mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=200)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=75, num_chains=5)\n",
    "\n",
    "mcmc.run(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "OBS:\n",
      "TN, FP, FN, TP\n",
      "[3934 1131 2007 1818]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.78      0.71      5065\n",
      "           1       0.62      0.48      0.54      3825\n",
      "\n",
      "    accuracy                           0.65      8890\n",
      "   macro avg       0.64      0.63      0.63      8890\n",
      "weighted avg       0.64      0.65      0.64      8890\n",
      "\n",
      "RET:\n",
      "TN, FP, FN, TP\n",
      "[4022 1043 2021 1804]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72      5065\n",
      "           1       0.63      0.47      0.54      3825\n",
      "\n",
      "    accuracy                           0.66      8890\n",
      "   macro avg       0.65      0.63      0.63      8890\n",
      "weighted avg       0.65      0.66      0.65      8890\n",
      "\n",
      "---TEST SET---\n",
      "OBS:\n",
      "TN, FP, FN, TP\n",
      "[559 159 312 284]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.70       718\n",
      "           1       0.64      0.48      0.55       596\n",
      "\n",
      "    accuracy                           0.64      1314\n",
      "   macro avg       0.64      0.63      0.63      1314\n",
      "weighted avg       0.64      0.64      0.63      1314\n",
      "\n",
      "RET:\n",
      "TN, FP, FN, TP\n",
      "[572 146 320 276]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.80      0.71       718\n",
      "           1       0.65      0.46      0.54       596\n",
      "\n",
      "    accuracy                           0.65      1314\n",
      "   macro avg       0.65      0.63      0.63      1314\n",
      "weighted avg       0.65      0.65      0.63      1314\n",
      "\n",
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "Using OBS:\n",
      "max confidence: 0.93\n",
      "correct: 502\n",
      "guessed: 819\n",
      "risked: 27254.150390625\n",
      "made: 1021.8023071289062\n",
      "ROI: 0.04\n",
      "\n",
      "Using RET:\n",
      "max confidence: 0.83\n",
      "correct: 494\n",
      "guessed: 782\n",
      "risked: 23082.08203125\n",
      "made: 1860.9947509765625\n",
      "ROI: 0.08\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "Using OBS:\n",
      "max confidence: 0.93\n",
      "correct: 429\n",
      "guessed: 787\n",
      "risked: 25018.1875\n",
      "made: -1706.30224609375\n",
      "ROI: -0.07\n",
      "\n",
      "Using RET:\n",
      "max confidence: 0.82\n",
      "correct: 415\n",
      "guessed: 753\n",
      "risked: 21904.3125\n",
      "made: -1968.92041015625\n",
      "ROI: -0.09\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "pyro.clear_param_store()\n",
    "predictive = Predictive(model=bnn_mcmc, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "pred_performance(predictive,x_train,x_test,y_train,y_test)\n",
    "make_bets(predictive,bet_data_train,bet_data_test,bet_train,x_test,bet_samps_train,y_test,diff_thresh=0.05,diff_cap=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "Using OBS:\n",
      "max confidence: 0.93\n",
      "correct: 387\n",
      "guessed: 522\n",
      "risked: 29974.359375\n",
      "made: 3245.582275390625\n",
      "ROI: 0.11\n",
      "\n",
      "Using RET:\n",
      "max confidence: 0.88\n",
      "correct: 391\n",
      "guessed: 513\n",
      "risked: 29672.7421875\n",
      "made: 3665.00439453125\n",
      "ROI: 0.12\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "Using OBS:\n",
      "max confidence: 0.92\n",
      "correct: 331\n",
      "guessed: 503\n",
      "risked: 28039.880859375\n",
      "made: -1482.18408203125\n",
      "ROI: -0.05\n",
      "\n",
      "Using RET:\n",
      "max confidence: 0.88\n",
      "correct: 342\n",
      "guessed: 506\n",
      "risked: 27953.580078125\n",
      "made: -958.8001098632812\n",
      "ROI: -0.03\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bet_data_train = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "bet_data_test = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "bet_train = torch.FloatTensor(StandardScaler().fit_transform((np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=','))))\n",
    "bet_samps_train = np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "make_bets(predictive,bet_data_train,bet_data_test,bet_train,x_test,bet_samps_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different normalization technique\n",
    "Improving quality of data could be useful, we will explore the performance of a simple BNN on unnormalized, minmax norm, maxabs norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnormalized\n",
    "First, we will construct a new unnormalized features file from 2014/2015 to 2022/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "features = []\n",
    "feat_minmax = []\n",
    "feat_maxabs = []\n",
    "samples = []\n",
    "start = 2014\n",
    "\n",
    "while start < 2023:\n",
    "    if start == 2018: # this year is missing and wont populate thru scraper!!\n",
    "        start += 1\n",
    "        continue\n",
    "\n",
    "    curr_feats = np.genfromtxt('../NBA/total/samps_feats/{start}-{end}_nba_features_inj.csv'.format(start=start,end=start+1),delimiter=',')\n",
    "    curr_samps = np.genfromtxt('../NBA/total/samps_feats/{start}-{end}_nba_samples_inj.csv'.format(start=start,end=start+1),delimiter=',')\n",
    "    feat_minmax.extend(minmax_scale(curr_feats))\n",
    "    feat_maxabs.extend(maxabs_scale(curr_feats))\n",
    "    features.extend(curr_feats)\n",
    "    samples.extend(curr_samps)\n",
    "    start += 1\n",
    "\n",
    "\n",
    "np.savetxt('../NBA/total/samps_feats/2015-2023_nba_features_unnorm.csv', features, delimiter=',')\n",
    "np.savetxt('../NBA/total/samps_feats/2015-2023_nba_samples.csv', samples, delimiter=',')\n",
    "np.savetxt('../NBA/total/samps_feats/2015-2023_nba_features_minmax.csv', features, delimiter=',')\n",
    "np.savetxt('../NBA/total/samps_feats/2015-2023_nba_features_maxabs.csv', features, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_15840\\2636246682.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  x_train = torch.FloatTensor(features)\n"
     ]
    }
   ],
   "source": [
    "feat_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',') # unnormalized\n",
    "samp_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samples)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [01:35,  1.05it/s, step size=4.07e-02, acc. prob=0.788]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "x_train = torch.FloatTensor(feat_maxabs)\n",
    "x_test = torch.FloatTensor(maxabs_scale(feat_test))\n",
    "y_train = torch.FloatTensor(samples)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "model = BNN(in_dim=16,hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# Define Hamiltonian Monte Carlo (HMC) kernel\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(model, jit_compile=False)  # jit_compile=True is faster but requires PyTorch 1.6+\n",
    "\n",
    "# Define MCMC sampler, get 50 posterior samples\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2384 2925 2191 2874]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.45      0.48      5309\n",
      "           1       0.50      0.57      0.53      5065\n",
      "\n",
      "    accuracy                           0.51     10374\n",
      "   macro avg       0.51      0.51      0.51     10374\n",
      "weighted avg       0.51      0.51      0.51     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[296 365 267 386]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.48       661\n",
      "           1       0.51      0.59      0.55       653\n",
      "\n",
      "    accuracy                           0.52      1314\n",
      "   macro avg       0.52      0.52      0.52      1314\n",
      "weighted avg       0.52      0.52      0.52      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "106\n",
      "tensor(-746.6345)\n",
      "49\n",
      "118\n",
      "tensor(-704.2104)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
