{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making bets on NBA games using Bayesian Neural Networks\n",
    "The goal of this notebook is to explore the use of BNNs in predicting the outcome of NBA games. While using MLPs as seen in ```mlp_betting.ipynb``` may be computationally more efficient, personal testing has shown that tradional neural networks are overconfident in predictions making them unsuitable for betting. By learning the distributions of weights, BNNs can hopefully provide a better estimate on the outcome of games for use in betting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\OneDrive\\Desktop\\CS\\betting_bot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_validate,cross_val_predict\n",
    "from sklearn.metrics import classification_report,confusion_matrix,make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from util.client import Nba_Season\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Softmax\n",
    "from pyro.infer import MCMC, NUTS\n",
    "from pyro.infer import Predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define simple BNN using Pyro containing 1 hidden layer\n",
    "\n",
    "For this implementation, we will be using the [Pyro Probablistic Programming language](https://github.com/pyro-ppl/pyro), loosely following a [tutorial](https://colab.research.google.com/drive/1NQNMdKaE9RncuWgO_vM2k3qywV76Byfh) from the University of Amsterdam\n",
    "\n",
    "Currently, the model will only be predicting the outcomes of games (home win or away win) and compare outcomes to moneyline odds from [vegas insider](https://www.vegasinsider.com/nba/odds/las-vegas/). Because of this, the model will be learning a categorical output, 0 indicating a home win and 1 indicating away win. The model will sample each layers weights and biases from a normal distribution while the prediction will be sampled from a categorical distribution based on the output of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim, out_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru output layer\n",
    "\n",
    "        #, x.shape[0]\n",
    "        with pyro.plate(\"data\"):\n",
    "            y_hat = Softmax(dim=1)(z2) # scale output via softmax for setting categorical priors\n",
    "            # y_hat = Softmax(dim=0)(x)\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(y_hat), obs=y)\n",
    "\n",
    "        return z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old samples and features\n",
    "features = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features, samples, test_size=0.25, random_state=1)\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [07:31,  4.51s/it, step size=1.17e-02, acc. prob=0.450]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "model = BNN(in_dim=16,hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# Define Hamiltonian Monte Carlo (HMC) kernel\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(model, jit_compile=False)  # jit_compile=True is faster but requires PyTorch 1.6+\n",
    "\n",
    "# Define MCMC sampler, get 50 posterior samples\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[1969 2431 1894 2343]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48      4400\n",
      "           1       0.49      0.55      0.52      4237\n",
      "\n",
      "    accuracy                           0.50      8637\n",
      "   macro avg       0.50      0.50      0.50      8637\n",
      "weighted avg       0.50      0.50      0.50      8637\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[678 813 596 793]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.49      1491\n",
      "           1       0.49      0.57      0.53      1389\n",
      "\n",
      "    accuracy                           0.51      2880\n",
      "   macro avg       0.51      0.51      0.51      2880\n",
      "weighted avg       0.51      0.51      0.51      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1) # each x in training produces 50 predictions (0 or 1), take average\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define kelly critereon to take in average prediction score and make bets\n",
    "For placing bets, the predictions from the BNN will be used on a modified version of the [kelly critereon](https://en.wikipedia.org/wiki/Kelly_criterion) betting strategy, defined in the function ```kelly``` wrapped by ```BNN_kelly```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelly(home_pred,away_pred,home_line,away_line,max_bet=100,diff_thresh=0.05):\n",
    "    '''\n",
    "    Applies kelly critereon based on features and moneyline data\n",
    "    home_pred: Prediction from MLP for home team\n",
    "    away_pred: Prediction from MLP for away team\n",
    "    home_line: Moneyline for home team\n",
    "    away_line: Moneyline for away team\n",
    "    '''\n",
    "    bet_amount = 0\n",
    "    to_win = 0\n",
    "\n",
    "    log_home = (home_pred - (home_pred * away_pred)) / (home_pred + away_pred - (2*home_pred*away_pred))\n",
    "    log_away = (away_pred - (home_pred * away_pred)) / (home_pred + away_pred - (2*home_pred*away_pred))\n",
    "\n",
    "    # calculate ratio and implied for home\n",
    "    home_line_adj = home_line\n",
    "    away_line_adj = away_line\n",
    "    if home_line < 0:\n",
    "        home_line_adj *= -1\n",
    "        home_line_adj /= 100\n",
    "        home_ratio = 1/(home_line_adj)\n",
    "        implied_home = home_line_adj/(1+home_line_adj)\n",
    "    else:\n",
    "        home_line_adj /= 100\n",
    "        home_ratio = home_line_adj\n",
    "        implied_home = 1/(home_line+1)\n",
    "\n",
    "    # calculate ratio and implied for away\n",
    "    if away_line < 0:\n",
    "        away_line_adj *= -1\n",
    "        away_line_adj /= 100\n",
    "        away_ratio = 1/(away_line_adj)\n",
    "        implied_away = away_line_adj/(1+away_line_adj)\n",
    "    else:\n",
    "        away_line_adj /= 100\n",
    "        away_ratio = away_line_adj\n",
    "        implied_away = 1/(away_line_adj+1)\n",
    "    \n",
    "    diff_home = log_home - implied_home\n",
    "    diff_away = log_away - implied_away\n",
    "\n",
    "    kelly_home = log_home - (log_away/home_ratio)\n",
    "    kelly_away = log_away - (log_home/away_ratio)\n",
    "\n",
    "    prob = 0\n",
    "\n",
    "    # make bets, negative if away team bet\n",
    "    if diff_home > diff_away and diff_home > diff_thresh:\n",
    "        bet_amount = (max_bet*kelly_home)\n",
    "        if home_line < 0:\n",
    "            to_win = bet_amount/((home_line*-1)/100)\n",
    "        else:\n",
    "            to_win = bet_amount/((home_line)/100)\n",
    "        prob = home_pred\n",
    "\n",
    "    \n",
    "    elif diff_away > diff_home and diff_away > diff_thresh:\n",
    "        bet_amount = (max_bet*kelly_away)\n",
    "        if away_line < 0:\n",
    "            to_win = -1*bet_amount/((away_line*-1)/100)\n",
    "        else:\n",
    "            to_win = -1*bet_amount/((away_line)/100)\n",
    "        prob = away_pred\n",
    "\n",
    "    return bet_amount,to_win,prob\n",
    "\n",
    "def BNN_kelly(preds,actual,money_lines,one_hot=False,diff_thresh=0.05):\n",
    "    money_made = 0\n",
    "    money_risked = 0\n",
    "    correct = 0\n",
    "    guessed = 0\n",
    "    team_bet = []\n",
    "    amount = []\n",
    "    gained = []\n",
    "    probs = []     \n",
    "\n",
    "    for i in range(len(preds)):\n",
    "        if one_hot:\n",
    "            away_pred = preds[i][0]\n",
    "            home_pred = preds[i][1]\n",
    "        else:\n",
    "            home_pred = preds[i]\n",
    "            away_pred = 1 - home_pred\n",
    "        home_ml = money_lines[i][7]\n",
    "        away_ml = money_lines[i][10]\n",
    "\n",
    "        to_bet,to_win,prob = kelly(home_pred,away_pred,home_ml,away_ml,diff_thresh=diff_thresh)\n",
    "        probs.append(prob)\n",
    "        money_risked += to_bet\n",
    "\n",
    "        curr_gained = 0\n",
    "\n",
    "        if to_win < 0:\n",
    "            team_bet.append('Away')\n",
    "            amount.append(to_bet)\n",
    "            guessed += 1\n",
    "            curr_gained = -1*to_bet\n",
    "            if actual[i] == 1:\n",
    "                correct += 1\n",
    "                curr_gained = (-1*to_win)\n",
    "                #money_made += curr_gained\n",
    "        elif to_win > 0:\n",
    "            team_bet.append('Home')\n",
    "            amount.append(to_bet)\n",
    "            guessed += 1\n",
    "            curr_gained = -1*to_bet\n",
    "            if actual[i] == 0:\n",
    "                correct += 1\n",
    "                curr_gained = to_win\n",
    "                #money_made += curr_gained\n",
    "        else:\n",
    "            team_bet.append(0)\n",
    "            amount.append(0)\n",
    "\n",
    "        gained.append(curr_gained)\n",
    "\n",
    "        if curr_gained > 0:\n",
    "            money_made += curr_gained\n",
    "\n",
    "    return correct,guessed,team_bet,probs,amount,gained\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "104\n",
      "tensor(-465.6457)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = np.genfromtxt('NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('NBA/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "56\n",
      "tensor(-331.8321)\n"
     ]
    }
   ],
   "source": [
    "# Test on 2023-2024 data\n",
    "features_new = np.genfromtxt('NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial testing yielded better results than traditional MLPs as seen in ``mlp_betting.ipynb``, explore BNN architecture with more layers\n",
    "Add a single hidden layer to our existing architecture and increase the number of posterior samples used during MCMC training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN_Multi_Layer(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](sec_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru sec layer\n",
    "        z3 = self.activation(z2 @ self.out.weight + self.out.bias) # output layer\n",
    "\n",
    "        #, x.shape[0]\n",
    "        with pyro.plate(\"data\"):\n",
    "            y_hat = Softmax(dim=1)(z3)\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(y_hat), obs=y)\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 2014/2015-2022/2023 NBA seasons to train, make predictions on 2023/2024 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old samples and features\n",
    "feat_train = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samp_train = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samp_train_1d = [0 if j[0] == 0 else 1 for j in samp_train]\n",
    "\n",
    "feat_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',') # unnormalized\n",
    "samp_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',') # unnormalized\n",
    "feat_test_norm = [[float(i)/sum(j) for i in j ]for j in feat_test]\n",
    "samp_test_1d = [0 if j[0] == 0 else 1 for j in samp_test]\n",
    "\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test_norm)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [12:59,  7.80s/it, step size=2.89e-03, acc. prob=0.723]\n"
     ]
    }
   ],
   "source": [
    "new_model = BNN_Multi_Layer(in_dim=16,first_hid_dim=16,sec_hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(new_model, jit_compile=True)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2582 3309 2475 3151]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.44      0.47      5891\n",
      "           1       0.49      0.56      0.52      5626\n",
      "\n",
      "    accuracy                           0.50     11517\n",
      "   macro avg       0.50      0.50      0.50     11517\n",
      "weighted avg       0.50      0.50      0.50     11517\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[272 389 297 356]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.41      0.44       661\n",
      "           1       0.48      0.55      0.51       653\n",
      "\n",
      "    accuracy                           0.48      1314\n",
      "   macro avg       0.48      0.48      0.48      1314\n",
      "weighted avg       0.48      0.48      0.48      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old samples and features\n",
    "features = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features, samples, test_size=0.25, random_state=1)\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/200 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [27:06,  8.13s/it, step size=3.46e-03, acc. prob=0.594]\n"
     ]
    }
   ],
   "source": [
    "new_model = BNN_Multi_Layer(in_dim=16,first_hid_dim=16,sec_hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(new_model, jit_compile=True)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2041 2359 1925 2312]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.46      0.49      4400\n",
      "           1       0.49      0.55      0.52      4237\n",
      "\n",
      "    accuracy                           0.50      8637\n",
      "   macro avg       0.50      0.50      0.50      8637\n",
      "weighted avg       0.50      0.50      0.50      8637\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[698 793 619 770]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50      1491\n",
      "           1       0.49      0.55      0.52      1389\n",
      "\n",
      "    accuracy                           0.51      2880\n",
      "   macro avg       0.51      0.51      0.51      2880\n",
      "weighted avg       0.51      0.51      0.51      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "64\n",
      "tensor(-19.2364)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "52\n",
      "tensor(-316.8422)\n"
     ]
    }
   ],
   "source": [
    "# Test on 2023-2024 data\n",
    "features_new = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our new structure yielded better results, however at a significant cost to runtime. Explore the use of Stochastic Variational Inference for training: \n",
    "Simple single layer BNN, using SVI with AutoNormal guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax, Softmax\n",
    "\n",
    "class BNN_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](first_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.out.weight + self.out.bias) # output layer\n",
    "        y_hat = LogSoftmax(dim=1)(z2) # scale output via softmax for setting categorical priors\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(logits=y_hat).to_event(1), obs=y)\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "features = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_maxabs.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_samples.csv',delimiter=',')\n",
    "feat_test = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samp_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.Tensor(samples.T)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 1.5100\n",
      "[iteration 0101] loss: 1.4795\n",
      "[iteration 0201] loss: 1.4451\n",
      "[iteration 0301] loss: 1.4494\n",
      "[iteration 0401] loss: 1.4377\n",
      "[iteration 0501] loss: 1.4332\n",
      "[iteration 0601] loss: 1.4339\n",
      "[iteration 0701] loss: 1.4340\n",
      "[iteration 0801] loss: 1.4319\n",
      "[iteration 0901] loss: 1.4302\n",
      "[iteration 1001] loss: 1.4300\n",
      "[iteration 1101] loss: 1.4309\n",
      "[iteration 1201] loss: 1.4292\n",
      "[iteration 1301] loss: 1.4282\n",
      "[iteration 1401] loss: 1.4264\n",
      "[iteration 1501] loss: 1.4273\n",
      "[iteration 1601] loss: 1.4241\n",
      "[iteration 1701] loss: 1.4240\n",
      "[iteration 1801] loss: 1.4253\n",
      "[iteration 1901] loss: 1.4234\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "pyro.clear_param_store()\n",
    "new_model = BNN_SVI(in_dim=16,first_hid_dim=16,out_dim=2)\n",
    "guide = AutoNormal(new_model)\n",
    "\n",
    "svi = SVI(new_model, guide, Adam({\"lr\": 1e-3}), Trace_ELBO())\n",
    "steps = 2000\n",
    "\n",
    "for step in range(steps):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    if step % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (step + 1, loss / len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2547 2762 2381 2684]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.48      0.50      5309\n",
      "           1       0.49      0.53      0.51      5065\n",
      "\n",
      "    accuracy                           0.50     10374\n",
      "   macro avg       0.50      0.50      0.50     10374\n",
      "weighted avg       0.51      0.50      0.50     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[312 349 303 350]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49       661\n",
      "           1       0.50      0.54      0.52       653\n",
      "\n",
      "    accuracy                           0.50      1314\n",
      "   macro avg       0.50      0.50      0.50      1314\n",
      "weighted avg       0.50      0.50      0.50      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictive = Predictive(new_model, guide=guide, num_samples=400, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=2)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train.T] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_new = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple BNN structure saw significant improvement in runtime, and produces much less confident predictions. Lets try a more complex structure now:\n",
    "## Multi-Layer BNN w/ SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax\n",
    "\n",
    "class BNN_Multi_Layer_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, thir_hid_dim=5, prior_scale=1., bias_scale=10.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.layer3 = PyroModule[nn.Linear](sec_hid_dim, thir_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](thir_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., bias_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., bias_scale).expand([sec_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.layer3.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, thir_hid_dim]).to_event(2))\n",
    "        self.layer3.bias = PyroSample(dist.Normal(0., bias_scale).expand([thir_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([thir_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., bias_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru sec layer\n",
    "        z3 = self.activation(z2 @ self.layer3.weight + self.layer3.bias) # output layer\n",
    "        z4 = self.activation(z3 @ self.out.weight + self.out.bias) # output layer\n",
    "\n",
    "        y_hat = Softmax(dim=1)(z4)\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.OneHotCategorical(probs=y_hat).to_event(1), obs=y,\n",
    "                        infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "# features = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_maxabs.csv',delimiter=',')\n",
    "features = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_features_unnorm.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/samps_feats/2015-2023_nba_samples.csv',delimiter=',')\n",
    "# feat_test = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "feat_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samp_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.Tensor(samples)\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train]\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 2.5404\n",
      "[iteration 0151] loss: 2.1998\n",
      "[iteration 0301] loss: 1.9756\n",
      "[iteration 0451] loss: 1.8971\n",
      "[iteration 0601] loss: 1.8749\n",
      "[iteration 0751] loss: 1.8658\n",
      "[iteration 0901] loss: 1.8611\n",
      "[iteration 1051] loss: 1.8582\n",
      "[iteration 1201] loss: 1.8565\n",
      "[iteration 1351] loss: 1.8554\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal, AutoDiagonalNormal, AutoContinuous, AutoDelta, AutoMultivariateNormal, AutoLaplaceApproximation, AutoStructured\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "pyro.clear_param_store()\n",
    "bnn_cat = BNN_Multi_Layer_SVI(in_dim=16,first_hid_dim=64,sec_hid_dim=128,thir_hid_dim=64,out_dim=2,prior_scale=1,bias_scale=5)\n",
    "guide = AutoDelta(bnn_cat)\n",
    "num_steps = 1500\n",
    "\n",
    "init_lr = 0.0025\n",
    "gamma = 0.01\n",
    "lrd = gamma ** (1/num_steps)\n",
    "optim = ClippedAdam({'lr': init_lr, 'lrd': lrd, \"betas\": (0.95, 0.999)})\n",
    "# optim = Adam({\"lr\": 0.01,\"betas\": (0.95, 0.999)})\n",
    "\n",
    "svi = SVI(bnn_cat, guide, optim, TraceEnum_ELBO())\n",
    "losses = []\n",
    "steps = []\n",
    "\n",
    "for i in range(num_steps):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    losses.append(loss)\n",
    "    steps.append(i)\n",
    "    if i % (num_steps/10) == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (i + 1, loss / len(x_train)))\n",
    "\n",
    "plt.plot(steps,losses)\n",
    "plt.ylabel(\"ELBO Loss\")\n",
    "plt.xlabel(\"SVI Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[5206  103   49 5016]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      5309\n",
      "           1       0.98      0.99      0.99      5065\n",
      "\n",
      "    accuracy                           0.99     10374\n",
      "   macro avg       0.99      0.99      0.99     10374\n",
      "weighted avg       0.99      0.99      0.99     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[348 313 294 359]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.53       661\n",
      "           1       0.53      0.55      0.54       653\n",
      "\n",
      "    accuracy                           0.54      1314\n",
      "   macro avg       0.54      0.54      0.54      1314\n",
      "weighted avg       0.54      0.54      0.54      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "predictive = Predictive(bnn_cat, guide=guide, num_samples=10, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> home win -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "adj_train_preds = [0 if p[0] < p[1] else 1 for p in train_preds]\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "test_preds = predictive(x_test)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "adj_test_preds = [0 if p[0] < p[1] else 1 for p in test_preds]\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "max confidence: 1.00\n",
      "correct: 1223\n",
      "guessed: 1260\n",
      "risked: 107495.609375\n",
      "made: 55186.39453125\n",
      "ROI: 0.51\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "max confidence: 1.00\n",
      "correct: 658\n",
      "guessed: 1253\n",
      "risked: 102215.828125\n",
      "made: -20461.75\n",
      "ROI: -0.20\n"
     ]
    }
   ],
   "source": [
    "# features_new = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "features_new = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "new_y_pred = predictive(new_x_tens)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:],one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}\\n')\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "# features_new = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "features_new = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "new_y_pred = predictive(new_x_tens)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2023-2024 DATA (UNSEEN)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:], one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "away_weight: 0.4625000059604645, home_weight: 0.5375000238418579\n",
      "max confidence: 0.5375000238418579\n",
      "bet on: ['Away']\n",
      "risked: [tensor(14.5136)]\n",
      "made: -14.513629913330078\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../NBA/on_off_stats/2023-2024_on_off.pkl', 'rb') as f:\n",
    "    on_off_2023_2024 = pickle.load(f)\n",
    "with open('../NBA/on_off_stats/2023-2024_team_stats.pkl', 'rb') as f:\n",
    "    team_stats_2023_2024 = pickle.load(f)\n",
    "    \n",
    "nba_szn_2023_2024 = Nba_Season('2023','2024',team_stats=team_stats_2023_2024,team_on_off=on_off_2023_2024)\n",
    "inj = {'DAL': ['OLIVIER-MAXENCE PROSPER'], 'BOS': []}\n",
    "home_stats,away_stats = nba_szn_2023_2024.calc_injury_impact(inj, 'BOS', 'DAL')\n",
    "today = torch.FloatTensor(np.subtract(away_stats,home_stats))\n",
    "\n",
    "bet_data = np.genfromtxt('test_today_with_bet.csv',delimiter=',')\n",
    "\n",
    "pyro.clear_param_store()\n",
    "today_pred = predictive(today.reshape([1,16]))['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "print(f'away_weight: {today_pred[0][0]}, home_weight: {today_pred[0][1]}')\n",
    "print(f'max confidence: {today_pred.max()}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(today_pred,samples_new_1d,bet_data[1:], one_hot=True, diff_thresh=-0.5)\n",
    "print(f'bet on: {team_bet}')\n",
    "print(f'risked: {amount}')\n",
    "print(f'made: {sum(gained)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grug\n"
     ]
    }
   ],
   "source": [
    "today_pred = predictive(today.reshape([1,16]))\n",
    "print('grug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     team_bet           probs           amount           gained\n",
      "0        Home  tensor(0.4600)  tensor(-6.2615)   tensor(3.9135)\n",
      "1        Away  tensor(0.5650)  tensor(12.0017)   tensor(9.5251)\n",
      "2        Home  tensor(0.4800)  tensor(-3.2427)   tensor(3.2427)\n",
      "3        Away  tensor(0.4900)  tensor(-1.6723)   tensor(1.1454)\n",
      "4        Home  tensor(0.4500)  tensor(-7.4134)   tensor(4.2121)\n",
      "...       ...             ...              ...              ...\n",
      "1309     Home  tensor(0.5450)   tensor(6.8437)  tensor(-6.8437)\n",
      "1310     Away  tensor(0.5250)   tensor(5.0900)  tensor(-5.0900)\n",
      "1311     Home  tensor(0.5250)   tensor(3.7279)  tensor(-3.7279)\n",
      "1312     Away  tensor(0.5050)   tensor(1.0000)   tensor(1.0000)\n",
      "1313     Home  tensor(0.4400)  tensor(-9.3366)   tensor(9.3366)\n",
      "\n",
      "[1314 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# bet_df = correct,guessed,team_bet,probs,amount,gained\n",
    "bet_dict = {\n",
    "    'team_bet': team_bet,\n",
    "    'probs': probs,\n",
    "    'amount': amount,\n",
    "    'gained': gained\n",
    "}\n",
    "bet_df = pd.DataFrame(bet_dict)\n",
    "print(bet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different normalization technique\n",
    "Improving quality of data could be useful, we will explore the performance of a simple BNN on unnormalized, minmax norm, maxabs norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnormalized\n",
    "First, we will construct a new unnormalized features file from 2014/2015 to 2022/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "features = []\n",
    "feat_minmax = []\n",
    "feat_maxabs = []\n",
    "samples = []\n",
    "start = 2014\n",
    "\n",
    "while start < 2023:\n",
    "    if start == 2018: # this year is missing and wont populate thru scraper!!\n",
    "        start += 1\n",
    "        continue\n",
    "\n",
    "    curr_feats = np.genfromtxt('../NBA/samps_feats/{start}-{end}_nba_features_inj.csv'.format(start=start,end=start+1),delimiter=',')\n",
    "    curr_samps = np.genfromtxt('../NBA/samps_feats/{start}-{end}_nba_samples_inj.csv'.format(start=start,end=start+1),delimiter=',')\n",
    "    feat_minmax.extend(minmax_scale(curr_feats))\n",
    "    feat_maxabs.extend(maxabs_scale(curr_feats))\n",
    "    features.extend(curr_feats)\n",
    "    samples.extend(curr_samps)\n",
    "    start += 1\n",
    "\n",
    "\n",
    "np.savetxt('../NBA/samps_feats/2015-2023_nba_features_unnorm.csv', features, delimiter=',')\n",
    "np.savetxt('../NBA/samps_feats/2015-2023_nba_samples.csv', samples, delimiter=',')\n",
    "np.savetxt('../NBA/samps_feats/2015-2023_nba_features_minmax.csv', features, delimiter=',')\n",
    "np.savetxt('../NBA/samps_feats/2015-2023_nba_features_maxabs.csv', features, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_15840\\2636246682.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  x_train = torch.FloatTensor(features)\n"
     ]
    }
   ],
   "source": [
    "feat_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',') # unnormalized\n",
    "samp_test = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samples)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [01:35,  1.05it/s, step size=4.07e-02, acc. prob=0.788]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "x_train = torch.FloatTensor(feat_maxabs)\n",
    "x_test = torch.FloatTensor(maxabs_scale(feat_test))\n",
    "y_train = torch.FloatTensor(samples)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "model = BNN(in_dim=16,hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# Define Hamiltonian Monte Carlo (HMC) kernel\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(model, jit_compile=False)  # jit_compile=True is faster but requires PyTorch 1.6+\n",
    "\n",
    "# Define MCMC sampler, get 50 posterior samples\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2384 2925 2191 2874]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.45      0.48      5309\n",
      "           1       0.50      0.57      0.53      5065\n",
      "\n",
      "    accuracy                           0.51     10374\n",
      "   macro avg       0.51      0.51      0.51     10374\n",
      "weighted avg       0.51      0.51      0.51     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[296 365 267 386]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.48       661\n",
      "           1       0.51      0.59      0.55       653\n",
      "\n",
      "    accuracy                           0.52      1314\n",
      "   macro avg       0.52      0.52      0.52      1314\n",
      "weighted avg       0.52      0.52      0.52      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "106\n",
      "tensor(-746.6345)\n",
      "49\n",
      "118\n",
      "tensor(-704.2104)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
