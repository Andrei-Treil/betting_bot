{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making bets on NBA games using Bayesian Neural Networks\n",
    "The goal of this notebook is to explore the use of Bayesian Neural Networks (BNNs) in predicting the outcome of NBA games. While using MLPs as seen in ```mlp_betting.ipynb``` may be computationally more efficient, personal testing has shown that tradional neural networks are overconfident in predictions making them unsuitable for betting. By learning the distributions of weights, BNNs can hopefully provide a better estimate on the outcome of games for use in betting.\n",
    "\n",
    "To test betting capability, we will use historic betting data gathered from vegasinsider.com to determine the money made from each model's predictions. The goal of the model is not to maximize accuracy (as NBA games are incredibly stochastic), but instead to maximize performance relative to odds set by Vegas. The algorithm for placing bets will be a modified version of the [kelly critereon](https://en.wikipedia.org/wiki/Kelly_criterion) betting strategy, defined in the functions ```kelly``` and ```BNN_kelly``` found in **util/client.py**.\n",
    "\n",
    "NOTE: The most recent and relevant exploration in this notebook is being done in the [**Using consecutive games stats**](#Using-consecutive-game-stats) section. Previous sections use old data, which is based on end of year totals for each team. More detail on how these datasets differ is available in the afformentioned section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_validate,cross_val_predict\n",
    "from sklearn.metrics import classification_report,confusion_matrix,make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from util.client import Nba_Season, kelly, BNN_kelly, make_bets, pred_performance\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Softmax\n",
    "from pyro.infer import MCMC, NUTS\n",
    "from pyro.infer import Predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define simple BNN using Pyro containing 1 hidden layer\n",
    "\n",
    "For this implementation, we will be using the [Pyro Probablistic Programming language](https://github.com/pyro-ppl/pyro), loosely following a [tutorial](https://colab.research.google.com/drive/1NQNMdKaE9RncuWgO_vM2k3qywV76Byfh) from the University of Amsterdam\n",
    "\n",
    "Currently, the model will only be predicting the outcomes of games (home win or away win) and compare outcomes to moneyline odds from [vegas insider](https://www.vegasinsider.com/nba/odds/las-vegas/). Because of this, the model will be learning a categorical output, 0 indicating a home win and 1 indicating away win. The model will sample each layers weights and biases from a normal distribution while the prediction will be sampled from a categorical distribution based on the output of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim, out_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru output layer\n",
    "\n",
    "        #, x.shape[0]\n",
    "        with pyro.plate(\"data\"):\n",
    "            y_hat = Softmax(dim=1)(z2) # scale output via softmax for setting categorical priors\n",
    "            # y_hat = Softmax(dim=0)(x)\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(y_hat), obs=y)\n",
    "\n",
    "        return z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [07:31,  4.51s/it, step size=1.17e-02, acc. prob=0.450]\n"
     ]
    }
   ],
   "source": [
    "# load old samples and features\n",
    "features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features, samples, test_size=0.25, random_state=1)\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "model = BNN(in_dim=16,hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# Define Hamiltonian Monte Carlo (HMC) kernel\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(model, jit_compile=False)  # jit_compile=True is faster but requires PyTorch 1.6+\n",
    "\n",
    "# Define MCMC sampler, get 50 posterior samples\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[1969 2431 1894 2343]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48      4400\n",
      "           1       0.49      0.55      0.52      4237\n",
      "\n",
      "    accuracy                           0.50      8637\n",
      "   macro avg       0.50      0.50      0.50      8637\n",
      "weighted avg       0.50      0.50      0.50      8637\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[678 813 596 793]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.49      1491\n",
      "           1       0.49      0.57      0.53      1389\n",
      "\n",
      "    accuracy                           0.51      2880\n",
      "   macro avg       0.51      0.51      0.51      2880\n",
      "weighted avg       0.51      0.51      0.51      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1) # each x in training produces 50 predictions (0 or 1), take average\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place bets using `BNN_Kelly` on 2022-2023 and 2023-2024 seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "104\n",
      "tensor(-465.6457)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "56\n",
      "tensor(-331.8321)\n"
     ]
    }
   ],
   "source": [
    "# Test on 2023-2024 data\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial testing yielded better results than traditional MLPs as seen in ``mlp_betting.ipynb``, explore BNN architecture with more layers\n",
    "Add a single hidden layer to our existing architecture and increase the number of posterior samples used during MCMC training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN_Multi_Layer(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](sec_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru sec layer\n",
    "        z3 = self.activation(z2 @ self.out.weight + self.out.bias) # output layer\n",
    "\n",
    "        #, x.shape[0]\n",
    "        with pyro.plate(\"data\"):\n",
    "            y_hat = Softmax(dim=1)(z3)\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(y_hat), obs=y)\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 2014/2015-2022/2023 NBA seasons to train, make predictions on 2023/2024 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [12:59,  7.80s/it, step size=2.89e-03, acc. prob=0.723]\n"
     ]
    }
   ],
   "source": [
    "# load old samples and features\n",
    "feat_train = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samp_train = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samp_train_1d = [0 if j[0] == 0 else 1 for j in samp_train]\n",
    "\n",
    "feat_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',') # unnormalized\n",
    "samp_test = np.genfromtxt('../NBA/total/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',') # unnormalized\n",
    "feat_test_norm = [[float(i)/sum(j) for i in j ]for j in feat_test]\n",
    "samp_test_1d = [0 if j[0] == 0 else 1 for j in samp_test]\n",
    "\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test_norm)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "new_model = BNN_Multi_Layer(in_dim=16,first_hid_dim=16,sec_hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(new_model, jit_compile=True)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2582 3309 2475 3151]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.44      0.47      5891\n",
      "           1       0.49      0.56      0.52      5626\n",
      "\n",
      "    accuracy                           0.50     11517\n",
      "   macro avg       0.50      0.50      0.50     11517\n",
      "weighted avg       0.50      0.50      0.50     11517\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[272 389 297 356]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.41      0.44       661\n",
      "           1       0.48      0.55      0.51       653\n",
      "\n",
      "    accuracy                           0.48      1314\n",
      "   macro avg       0.48      0.48      0.48      1314\n",
      "weighted avg       0.48      0.48      0.48      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/200 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [27:06,  8.13s/it, step size=3.46e-03, acc. prob=0.594]\n"
     ]
    }
   ],
   "source": [
    "# load old samples and features\n",
    "features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_norm_inj.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples_inj.csv',delimiter=',')\n",
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features, samples, test_size=0.25, random_state=1)\n",
    "x_train = torch.FloatTensor(feat_train)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samp_train)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "new_model = BNN_Multi_Layer(in_dim=16,first_hid_dim=16,sec_hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(new_model, jit_compile=True)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2041 2359 1925 2312]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.46      0.49      4400\n",
      "           1       0.49      0.55      0.52      4237\n",
      "\n",
      "    accuracy                           0.50      8637\n",
      "   macro avg       0.50      0.50      0.50      8637\n",
      "weighted avg       0.50      0.50      0.50      8637\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[698 793 619 770]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50      1491\n",
      "           1       0.49      0.55      0.52      1389\n",
      "\n",
      "    accuracy                           0.51      2880\n",
      "   macro avg       0.51      0.51      0.51      2880\n",
      "weighted avg       0.51      0.51      0.51      2880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "64\n",
      "tensor(-19.2364)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "52\n",
      "tensor(-316.8422)\n"
     ]
    }
   ],
   "source": [
    "# Test on 2023-2024 data\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=new_model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our new structure yielded better results, however at a significant cost to runtime. Explore the use of Stochastic Variational Inference for training: \n",
    "Simple single layer BNN, using SVI with AutoNormal guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax, Softmax\n",
    "\n",
    "class BNN_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, prior_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](first_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.out.weight + self.out.bias) # output layer\n",
    "        y_hat = LogSoftmax(dim=1)(z2) # scale output via softmax for setting categorical priors\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(logits=y_hat).to_event(1), obs=y)\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 1.5100\n",
      "[iteration 0101] loss: 1.4795\n",
      "[iteration 0201] loss: 1.4451\n",
      "[iteration 0301] loss: 1.4494\n",
      "[iteration 0401] loss: 1.4377\n",
      "[iteration 0501] loss: 1.4332\n",
      "[iteration 0601] loss: 1.4339\n",
      "[iteration 0701] loss: 1.4340\n",
      "[iteration 0801] loss: 1.4319\n",
      "[iteration 0901] loss: 1.4302\n",
      "[iteration 1001] loss: 1.4300\n",
      "[iteration 1101] loss: 1.4309\n",
      "[iteration 1201] loss: 1.4292\n",
      "[iteration 1301] loss: 1.4282\n",
      "[iteration 1401] loss: 1.4264\n",
      "[iteration 1501] loss: 1.4273\n",
      "[iteration 1601] loss: 1.4241\n",
      "[iteration 1701] loss: 1.4240\n",
      "[iteration 1801] loss: 1.4253\n",
      "[iteration 1901] loss: 1.4234\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_maxabs.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples.csv',delimiter=',')\n",
    "feat_test = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samp_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.Tensor(samples.T)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "\n",
    "pyro.clear_param_store()\n",
    "new_model = BNN_SVI(in_dim=16,first_hid_dim=16,out_dim=2)\n",
    "guide = AutoNormal(new_model)\n",
    "\n",
    "svi = SVI(new_model, guide, Adam({\"lr\": 1e-3}), Trace_ELBO())\n",
    "steps = 2000\n",
    "\n",
    "for step in range(steps):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    if step % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (step + 1, loss / len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2547 2762 2381 2684]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.48      0.50      5309\n",
      "           1       0.49      0.53      0.51      5065\n",
      "\n",
      "    accuracy                           0.50     10374\n",
      "   macro avg       0.50      0.50      0.50     10374\n",
      "weighted avg       0.51      0.50      0.50     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[312 349 303 350]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49       661\n",
      "           1       0.50      0.54      0.52       653\n",
      "\n",
      "    accuracy                           0.50      1314\n",
      "   macro avg       0.50      0.50      0.50      1314\n",
      "weighted avg       0.50      0.50      0.50      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictive = Predictive(new_model, guide=guide, num_samples=400, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=2)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train.T] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple BNN structure saw significant improvement in runtime, and produces much less confident predictions. Lets try a more complex structure now:\n",
    "## Multi-Layer BNN w/ SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax\n",
    "\n",
    "class BNN_Multi_Layer_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, thir_hid_dim=5, prior_scale=1., bias_scale=10.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.layer3 = PyroModule[nn.Linear](sec_hid_dim, thir_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](thir_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., bias_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., bias_scale).expand([sec_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.layer3.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, thir_hid_dim]).to_event(2))\n",
    "        self.layer3.bias = PyroSample(dist.Normal(0., bias_scale).expand([thir_hid_dim,]).to_event(1)) # output bias term\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([thir_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., bias_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias) # pass thru first layer\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias) # pass thru sec layer\n",
    "        z3 = self.activation(z2 @ self.layer3.weight + self.layer3.bias) # output layer\n",
    "        z4 = self.activation(z3 @ self.out.weight + self.out.bias) # output layer\n",
    "\n",
    "        y_hat = Softmax(dim=1)(z4)\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.OneHotCategorical(probs=y_hat).to_event(1), obs=y,\n",
    "                        infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "# features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_maxabs.csv',delimiter=',')\n",
    "features = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_features_unnorm.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/total/samps_feats/2015-2023_nba_samples.csv',delimiter=',')\n",
    "# feat_test = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "feat_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samp_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.Tensor(samples)\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train]\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 9.0015\n",
      "[iteration 0501] loss: 8.6606\n",
      "[iteration 1001] loss: 8.6255\n",
      "[iteration 1501] loss: 8.6025\n",
      "[iteration 2001] loss: 8.5860\n",
      "[iteration 2501] loss: 8.5771\n",
      "[iteration 3001] loss: 8.5705\n",
      "[iteration 3501] loss: 8.5657\n",
      "[iteration 4001] loss: 8.5626\n",
      "[iteration 4501] loss: 8.5610\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal, AutoDiagonalNormal, AutoContinuous, AutoDelta, AutoMultivariateNormal, AutoLaplaceApproximation, AutoStructured\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "pyro.clear_param_store()\n",
    "bnn_cat = BNN_Multi_Layer_SVI(in_dim=16,first_hid_dim=128,sec_hid_dim=128,thir_hid_dim=128,out_dim=2,prior_scale=4,bias_scale=10)\n",
    "guide = AutoDelta(bnn_cat)\n",
    "num_steps = 5000\n",
    "\n",
    "init_lr = 0.001\n",
    "gamma = 0.01\n",
    "lrd = gamma ** (1/num_steps)\n",
    "optim = ClippedAdam({'lr': init_lr, 'lrd': lrd, \"betas\": (0.95, 0.999)})\n",
    "# optim = Adam({\"lr\": 0.01,\"betas\": (0.95, 0.999)})\n",
    "\n",
    "svi = SVI(bnn_cat, guide, optim, TraceEnum_ELBO())\n",
    "losses = []\n",
    "steps = []\n",
    "\n",
    "for i in range(num_steps):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    losses.append(loss)\n",
    "    steps.append(i)\n",
    "    if i % (num_steps/10) == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (i + 1, loss / len(x_train)))\n",
    "\n",
    "plt.plot(steps,losses)\n",
    "plt.ylabel(\"ELBO Loss\")\n",
    "plt.xlabel(\"SVI Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[4054 1255 1679 3386]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73      5309\n",
      "           1       0.73      0.67      0.70      5065\n",
      "\n",
      "    accuracy                           0.72     10374\n",
      "   macro avg       0.72      0.72      0.72     10374\n",
      "weighted avg       0.72      0.72      0.72     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[360 301 361 292]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.54      0.52       661\n",
      "           1       0.49      0.45      0.47       653\n",
      "\n",
      "    accuracy                           0.50      1314\n",
      "   macro avg       0.50      0.50      0.49      1314\n",
      "weighted avg       0.50      0.50      0.50      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "predictive = Predictive(bnn_cat, guide=guide, num_samples=1000, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> home win -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "adj_train_preds = [0 if p[0] < p[1] else 1 for p in train_preds]\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "test_preds = predictive(x_test)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "adj_test_preds = [0 if p[0] < p[1] else 1 for p in test_preds]\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "max confidence: 0.91\n",
      "correct: 1272\n",
      "guessed: 1277\n",
      "risked: 119647.5234375\n",
      "made: 62617.00390625\n",
      "ROI: 0.52\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "max confidence: 0.92\n",
      "correct: 661\n",
      "guessed: 1279\n",
      "risked: 113455.3203125\n",
      "made: -25223.041015625\n",
      "ROI: -0.22\n"
     ]
    }
   ],
   "source": [
    "# features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "new_y_pred = predictive(new_x_tens)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:],one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}\\n')\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "# features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "features_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# new_y_pred = predictive(new_x_tens)['obs'].T.float().mean(axis=2)\n",
    "new_y_pred = predictive(new_x_tens)['obs'].float().mean(axis=1).float().mean(axis=0)\n",
    "print('PREDICTIONS ON 2023-2024 DATA (UNSEEN)')\n",
    "print(f'max confidence: {new_y_pred.max():.2f}')\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:], one_hot=True, diff_thresh=0.05)\n",
    "print(f'correct: {correct}')\n",
    "print(f'guessed: {guessed}')\n",
    "print(f'risked: {sum(amount)}')\n",
    "print(f'made: {sum(gained)}')\n",
    "print(f'ROI: {(sum(gained)/sum(amount)):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using consecutive game stats\n",
    "Previous training used season totals for prediction, making it unlikely (or unrealistic) that models will perform well on test sets. Data from NBA/conc_feats_samps is different as it uses the teams cumulative statistics up to the day of the game for generating features, and has 14 features instead 16. Additionally, the new samples generated are not categorical by default. \n",
    "\n",
    "First we will explore the efficacy of this data in SVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LogSoftmax\n",
    "\n",
    "class BNN_Multi_Layer_SVI(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, first_hid_dim=5, sec_hid_dim=5, \n",
    "                 thir_hid_dim=5, four_hid_dim=5, prior_scale=1., bias_scale=10.):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, first_hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](first_hid_dim, sec_hid_dim)\n",
    "        self.layer3 = PyroModule[nn.Linear](sec_hid_dim, thir_hid_dim)\n",
    "        self.layer4 = PyroModule[nn.Linear](thir_hid_dim, four_hid_dim)\n",
    "        self.out = PyroModule[nn.Linear](four_hid_dim, out_dim)\n",
    "\n",
    "        # Set layer parameters as random variables\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, first_hid_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., bias_scale).expand([first_hid_dim,]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([first_hid_dim, sec_hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., bias_scale).expand([sec_hid_dim,]).to_event(1))\n",
    "        self.layer3.weight = PyroSample(dist.Normal(0., prior_scale).expand([sec_hid_dim, thir_hid_dim]).to_event(2))\n",
    "        self.layer3.bias = PyroSample(dist.Normal(0., bias_scale).expand([thir_hid_dim,]).to_event(1))\n",
    "        self.layer4.weight = PyroSample(dist.Normal(0., prior_scale).expand([thir_hid_dim, four_hid_dim]).to_event(2))\n",
    "        self.layer4.bias = PyroSample(dist.Normal(0., bias_scale).expand([four_hid_dim,]).to_event(1))\n",
    "        self.out.weight = PyroSample(dist.Normal(0., prior_scale).expand([four_hid_dim, out_dim]).to_event(2))\n",
    "        self.out.bias = PyroSample(dist.Normal(0., bias_scale).expand([out_dim,]).to_event(1)) # output bias term\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        z1 = self.activation(x @ self.layer1.weight + self.layer1.bias)\n",
    "        z2 = self.activation(z1 @ self.layer2.weight + self.layer2.bias)\n",
    "        z3 = self.activation(z2 @ self.layer3.weight + self.layer3.bias)\n",
    "        z4 = self.activation(z3 @ self.layer4.weight + self.layer4.bias)\n",
    "        z5 = self.activation(z4 @ self.out.weight + self.out.bias) # output layer \n",
    "\n",
    "        y_hat = Softmax(dim=1)(z5)\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            obs = pyro.sample(\"obs\", dist.OneHotCategorical(probs=y_hat).to_event(1), obs=y,\n",
    "                        infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale, StandardScaler\n",
    "features = np.genfromtxt('../NBA/consec/conc_feats_samps/2017-2023_features_stand.csv',delimiter=',')\n",
    "samples = np.genfromtxt('../NBA/consec/conc_feats_samps/2017-2023_samples_stand_cat.csv',delimiter=',')\n",
    "feat_test = StandardScaler().fit_transform((np.genfromtxt('../NBA/consec/conc_feats_samps/2023-2024_nba_features_inj.csv',delimiter=',')))\n",
    "# feat_test = np.genfromtxt('../NBA/consec/conc_feats_samps/2023-2024_nba_features_inj.csv',delimiter=',')\n",
    "samp_test = np.genfromtxt('../NBA/consec/conc_feats_samps/2023-2024_samples_cat.csv',delimiter=',')\n",
    "bet_data_train = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "bet_data_test = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "bet_train = torch.FloatTensor(StandardScaler().fit_transform((np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=','))))\n",
    "bet_samps_train = np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "\n",
    "y_train = torch.Tensor(samples)\n",
    "y_test = torch.Tensor(samp_test)\n",
    "\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> home win -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 5.0303\n",
      "[iteration 0251] loss: 4.5821\n",
      "[iteration 0501] loss: 4.4381\n",
      "[iteration 0751] loss: 4.3483\n",
      "[iteration 1001] loss: 4.3018\n",
      "[iteration 1251] loss: 4.2798\n",
      "[iteration 1501] loss: 4.2679\n",
      "[iteration 1751] loss: 4.2616\n",
      "[iteration 2001] loss: 4.2578\n",
      "[iteration 2251] loss: 4.2555\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGzCAYAAAAyiiOsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABa9ElEQVR4nO3deVwV9f4/8NdZOIf1gOyiuCuKuCGBWKkliUqLXW+Zes3UNP1hV6XSbNHq3i5km5qm3rqJfVtcKq3UNMQ1JUUQxQVzB5cDLsBBkO2cz+8PZPQI6kGBOQdez8djHjgznzPzntE4r2Y+8xmFEEKAiIiIiO5IKXcBRERERLaAoYmIiIjIAgxNRERERBZgaCIiIiKyAEMTERERkQUYmoiIiIgswNBEREREZAGGJiIiIiILMDQRERERWYChiYiIiMgCarkLqBQXF4eZM2diypQpmDt3LgCgX79+2LZtm1m7l156CYsXL5bmMzMzMWnSJGzZsgXOzs4YPXo0YmNjoVbfOLStW7ciJiYGhw4dgr+/P9566y288MILZttduHAhPvzwQ+j1enTr1g2fffYZQkNDLa7fZDLh/PnzcHFxgUKhqPkJICIiononhEBBQQH8/PygVN7lWpKwAnv27BGtWrUSXbt2FVOmTJGW9+3bV4wfP15cuHBBmvLz86X15eXlIigoSERERIh9+/aJ9evXC09PTzFz5kypzcmTJ4Wjo6OIiYkRhw8fFp999plQqVRiw4YNUpvly5cLjUYjvvrqK3Ho0CExfvx44ebmJrKzsy0+hqysLAGAEydOnDhx4mSDU1ZW1l2/6xVCyPvC3qtXryI4OBiff/45/v3vf6N79+5mV5punr/Vb7/9hscffxznz5+Hj48PAGDx4sWYMWMGLl68CI1GgxkzZmDdunU4ePCg9LnnnnsOeXl52LBhAwAgLCwMDzzwABYsWACg4qqRv78/Xn75Zbz++usWHUd+fj7c3NyQlZUFnU53j2eDiIiI6pPBYIC/vz/y8vLg6up6x7ay356Ljo5GVFQUIiIi8O9//7vK+m+//RbffPMNfH198cQTT+Dtt9+Go6MjACApKQldunSRAhMAREZGYtKkSTh06BB69OiBpKQkREREmG0zMjISU6dOBQCUlpYiJSUFM2fOlNYrlUpEREQgKSnptnWXlJSgpKREmi8oKAAA6HQ6hiYiIiIbY0nXGllD0/Lly5Gamork5ORq148YMQItW7aEn58fDhw4gBkzZuDo0aP46aefAAB6vd4sMAGQ5vV6/R3bGAwGXLt2Dbm5uTAajdW2ycjIuG3tsbGxePfdd2t2wERERGSzZAtNWVlZmDJlChISEmBvb19tmwkTJkh/7tKlC5o2bYr+/fvjxIkTaNu2bX2VWq2ZM2ciJiZGmq+8vEdEREQNk2yhKSUlBTk5OQgODpaWGY1GbN++HQsWLEBJSQlUKpXZZ8LCwgAAx48fR9u2beHr64s9e/aYtcnOzgYA+Pr6Sj8rl93cRqfTwcHBASqVCiqVqto2lduojlarhVarreFRExERka2SbZym/v37Iz09HWlpadIUEhKCkSNHIi0trUpgAoC0tDQAQNOmTQEA4eHhSE9PR05OjtQmISEBOp0OgYGBUpvExESz7SQkJCA8PBwAoNFo0LNnT7M2JpMJiYmJUhsiIiIi2a40ubi4ICgoyGyZk5MTPDw8EBQUhBMnTuC7777D4MGD4eHhgQMHDmDatGno06cPunbtCgAYMGAAAgMDMWrUKMyZMwd6vR5vvfUWoqOjpatAEydOxIIFCzB9+nSMHTsWmzdvxsqVK7Fu3TppvzExMRg9ejRCQkIQGhqKuXPnorCwEGPGjKm/E0JERERWTfan525Ho9Fg06ZNUoDx9/fH0KFD8dZbb0ltVCoV1q5di0mTJiE8PBxOTk4YPXo03nvvPalN69atsW7dOkybNg3z5s1D8+bN8eWXXyIyMlJqM2zYMFy8eBGzZs2CXq9H9+7dsWHDhiqdw4mIiKjxkn2cpobCYDDA1dUV+fn5HHKAiIjIRtTk+5vvniMiIiKyAEMTERERkQUYmoiIiIgswNBEREREZAGGJiIiIiILWO2QA1ShqLQcVwpLoVEr4e1S/etmiIiIqO7xSpOVSzicjYc+2IKpy9PkLoWIiKhRY2iycgqFAgDA0bSIiIjkxdBk5ZQVmQkmpiYiIiJZMTRZOSWvNBEREVkFhiYrd/1CE680ERERyYyhycpJfZpkroOIiKixY2iycuzTREREZB0YmqxcZZ8mEzMTERGRrBiarNz1zATBK01ERESyYmiycnx6joiIyDowNFk5Bfs0ERERWQWGJiunYJ8mIiIiq8DQZOWU7NNERERkFRiarBz7NBEREVkHhiYrxz5NRERE1oGhycopUNmniaGJiIhITgxNVk7q0yRvGURERI0eQ5OVUyrZp4mIiMgaMDRZuesXmnh7joiISGYMTVbuxjhNDE1ERERyYmiycjfGaZK3DiIiosaOocnKcZwmIiIi68DQZOU4ThMREZF1YGiycrzSREREZB0YmqwcrzQRERFZB4YmK6eUnp6TuRAiIqJGjqHJyimkp+eYmoiIiOTE0GTlpD5NMtdBRETU2DE0WTkl+zQRERFZBYYmq3e9TxM7NREREcmKocnKcURwIiIi68DQZOXYp4mIiMg6WE1oiouLg0KhwNSpU6usE0Jg0KBBUCgUWLNmjdm6zMxMREVFwdHREd7e3njttddQXl5u1mbr1q0IDg6GVqtFu3btEB8fX2UfCxcuRKtWrWBvb4+wsDDs2bOnFo/u3in5wl4iIiKrYBWhKTk5GUuWLEHXrl2rXT937lwoKp+9v4nRaERUVBRKS0uxa9cuLFu2DPHx8Zg1a5bU5tSpU4iKisIjjzyCtLQ0TJ06FS+++CI2btwotVmxYgViYmIwe/ZspKamolu3boiMjEROTk7tH2wNcXBLIiIi6yB7aLp69SpGjhyJL774Ak2aNKmyPi0tDR9//DG++uqrKut+//13HD58GN988w26d++OQYMG4V//+hcWLlyI0tJSAMDixYvRunVrfPzxx+jUqRMmT56Mv//97/j000+l7XzyyScYP348xowZg8DAQCxevBiOjo7V7rO+KdiniYiIyCrIHpqio6MRFRWFiIiIKuuKioowYsQILFy4EL6+vlXWJyUloUuXLvDx8ZGWRUZGwmAw4NChQ1KbW7cdGRmJpKQkAEBpaSlSUlLM2iiVSkREREhtqlNSUgKDwWA21QW+e46IiMg6qOXc+fLly5Gamork5ORq10+bNg29e/fGU089Ve16vV5vFpgASPN6vf6ObQwGA65du4bc3FwYjcZq22RkZNy29tjYWLz77rt3PsBawD5NRERE1kG20JSVlYUpU6YgISEB9vb2Vdb/8ssv2Lx5M/bt2ydDdXc3c+ZMxMTESPMGgwH+/v61vh/2aSIiIrIOst2eS0lJQU5ODoKDg6FWq6FWq7Ft2zbMnz8farUaCQkJOHHiBNzc3KT1ADB06FD069cPAODr64vs7Gyz7VbOV97Ou10bnU4HBwcHeHp6QqVSVdumuluClbRaLXQ6ndlUF6Q+TXWydSIiIrKUbFea+vfvj/T0dLNlY8aMQceOHTFjxgx4enripZdeMlvfpUsXfPrpp3jiiScAAOHh4Xj//feRk5MDb29vAEBCQgJ0Oh0CAwOlNuvXrzfbTkJCAsLDwwEAGo0GPXv2RGJiIoYMGQIAMJlMSExMxOTJk2v9uGvq5j5NQohqnyIkIiKiuidbaHJxcUFQUJDZMicnJ3h4eEjLq7vS06JFC7Ru3RoAMGDAAAQGBmLUqFGYM2cO9Ho93nrrLURHR0Or1QIAJk6ciAULFmD69OkYO3YsNm/ejJUrV2LdunXSNmNiYjB69GiEhIQgNDQUc+fORWFhIcaMGVNXh2+xmyOSEDeuPBEREVH9krUj+P1SqVRYu3YtJk2ahPDwcDg5OWH06NF47733pDatW7fGunXrMG3aNMybNw/NmzfHl19+icjISKnNsGHDcPHiRcyaNQt6vR7du3fHhg0bqnQOl4PyppRkEgJKMDURERHJQSEEexjXBoPBAFdXV+Tn59dq/6b8ojJ0e+93AMCx9wfBTiX7KBFEREQNRk2+v/kNbOUUN/0N8Qk6IiIi+TA0Wblb+zQRERGRPBiarNzNfZoYmoiIiOTD0GTlbu0ITkRERPJgaLJyNw8xwNBEREQkH4YmK2cemuSrg4iIqLFjaLJyN9+e47tUiIiI5MPQZOXYp4mIiMg6MDRZuZuHHGBoIiIikg9Dk5VjnyYiIiLrwNBk5RQKhRScBDs1ERERyYahyQZU9msymWQuhIiIqBFjaLIBdqqK0FRmZGoiIiKSC0OTDbBTVvw1MTQRERHJh6HJBtipK/6aytkTnIiISDYMTTZAray4PVdazitNREREcmFosgF2Kt6eIyIikhtDkw3Q8PYcERGR7BiabEDl7bky3p4jIiKSDUOTDZBuz/FKExERkWwYmmyANE4TrzQRERHJhqHJBlReaSrnkOBERESyYWiyAerrV5pKjbw9R0REJBeGJhsgXWnikANERESyYWiyARqO00RERCQ7hiYboJZe2Mvbc0RERHJhaLIBHBGciIhIfgxNNoChiYiISH4MTTbAjrfniIiIZMfQZAPUvNJEREQkO4YmG6CRhhzglSYiIiK5MDTZgBu353iliYiISC4MTTbgxu05XmkiIiKSC0OTDeDTc0RERPJjaLIBdsqK23N8YS8REZF8GJpsgJ264q+ptJy354iIiOTC0GQD1LzSREREJDurCU1xcXFQKBSYOnWqtOyll15C27Zt4eDgAC8vLzz11FPIyMgw+1xmZiaioqLg6OgIb29vvPbaaygvLzdrs3XrVgQHB0Or1aJdu3aIj4+vsv+FCxeiVatWsLe3R1hYGPbs2VMXh3lPNGr2aSIiIpKbVYSm5ORkLFmyBF27djVb3rNnTyxduhRHjhzBxo0bIYTAgAEDYDQaAQBGoxFRUVEoLS3Frl27sGzZMsTHx2PWrFnSNk6dOoWoqCg88sgjSEtLw9SpU/Hiiy9i48aNUpsVK1YgJiYGs2fPRmpqKrp164bIyEjk5OTUzwm4C7WSt+eIiIhkJ2RWUFAg2rdvLxISEkTfvn3FlClTbtt2//79AoA4fvy4EEKI9evXC6VSKfR6vdRm0aJFQqfTiZKSEiGEENOnTxedO3c2286wYcNEZGSkNB8aGiqio6OleaPRKPz8/ERsbKzFx5Gfny8AiPz8fIs/Y6mVyZmi5Yy1YvRXu2t920RERI1ZTb6/Zb/SFB0djaioKERERNyxXWFhIZYuXYrWrVvD398fAJCUlIQuXbrAx8dHahcZGQmDwYBDhw5JbW7ddmRkJJKSkgAApaWlSElJMWujVCoREREhtZEbb88RERHJTy3nzpcvX47U1FQkJyffts3nn3+O6dOno7CwEAEBAUhISIBGowEA6PV6s8AEQJrX6/V3bGMwGHDt2jXk5ubCaDRW2+bW/lM3KykpQUlJiTRvMBgsOOJ7U3l7joNbEhERyUe2K01ZWVmYMmUKvv32W9jb29+23ciRI7Fv3z5s27YNHTp0wLPPPovi4uJ6rLR6sbGxcHV1labKq191ga9RISIikp9soSklJQU5OTkIDg6GWq2GWq3Gtm3bMH/+fKjVaqmzt6urK9q3b48+ffrghx9+QEZGBlavXg0A8PX1RXZ2ttl2K+d9fX3v2Ean08HBwQGenp5QqVTVtqncRnVmzpyJ/Px8acrKyrq/E3IHdnxhLxERkexkC039+/dHeno60tLSpCkkJAQjR45EWloaVCpVlc8IISCEkG6LhYeHIz093ewpt4SEBOh0OgQGBkptEhMTzbaTkJCA8PBwAIBGo0HPnj3N2phMJiQmJkptqqPVaqHT6cymulLZp6mk3Fhn+yAiIqI7k61Pk4uLC4KCgsyWOTk5wcPDA0FBQTh58iRWrFiBAQMGwMvLC2fPnkVcXBwcHBwwePBgAMCAAQMQGBiIUaNGYc6cOdDr9XjrrbcQHR0NrVYLAJg4cSIWLFiA6dOnY+zYsdi8eTNWrlyJdevWSfuNiYnB6NGjERISgtDQUMydOxeFhYUYM2ZM/Z2QO3DSVvw1FZYwNBEREclF1o7gd2Jvb48dO3Zg7ty5yM3NhY+PD/r06YNdu3bB29sbAKBSqbB27VpMmjQJ4eHhcHJywujRo/Hee+9J22ndujXWrVuHadOmYd68eWjevDm+/PJLREZGSm2GDRuGixcvYtasWdDr9ejevTs2bNhQpXO4XJyvh6aC4jKZKyEiImq8FEIIdpSpBQaDAa6ursjPz6/1W3U5hmKE/icRSgVw7P3BUF1/rQoRERHdn5p8f8s+ThPdnYezFhqVEiYBZF0pkrscIiKiRomhyQaolAp093cDAPx2UC9vMURERI0UQ5ONeLK7HwBgS4Z1vA+PiIiosWFoshF9O3gBAFIyc2Fgh3AiIqJ6x9BkI/zdHdHGywlGk8Cu45fkLoeIiKjRYWiyIX3aV1xt2nr0osyVEBERNT4MTTakf6eK8ak2HcmG0cSRIoiIiOoTQ5MN6dXGAy72aly6Wor0c/lyl0NERNSoMDTZEDuVEmGt3QEAu09elrkaIiKixoWhycaEtfYAAOw+dUXmSoiIiBoXhiYbE9am4kpT8qkr7NdERERUjxiabExgUx2ctWoUlJTjyAWD3OUQERE1GgxNNkatUiKkVRMAvEVHRERUnxiabFCvNhX9mnZykEsiIqJ6w9BkgyoHuUw6cRkl5UaZqyEiImocGJpsUKemLvBy0eJamRHJp3LlLoeIiKhRYGiyQQqFQnqB77a/cmSuhoiIqHFgaLJRN0IT30NHRERUHxiabNTD7T2hVAB/ZV/F2dwiucshIiJq8BiabJSbowY9W1YMPbAlg7foiIiI6hpDkw17tKMPACCRoYmIiKjOMTTZsP6dvAEAu05cRlFpuczVEBERNWwMTTasvbcz/N0dUFpuwo5jHOiSiIioLjE02TCFQoGIThW36DYdzpa5GiIiooaNocnGPXY9NG3OyIHRJGSuhoiIqOFiaLJxD7R2h4u9GpcLS5GWxdHBiYiI6gpDk42zUynRL6CiQ/imI3yKjoiIqK4wNDUAEdefomO/JiIiorrD0NQA9OvgDbVSgWM5V3H6UqHc5RARETVIDE0NgKujHUJbuwMANh3h1SYiIqK6wNDUQPS//hRdAm/RERER1QmGpgZiQGBFaNpz+gou5F+TuRoiIqKGh6GpgfB3d8QDrZpACOCXtPNyl0NERNTgMDQ1IE/3aA4AWL3vnMyVEBERNTwMTQ1IVJem0KiUyNAX4MgFg9zlEBERNSgMTQ2Iq6MdHu1YMWbTGl5tIiIiqlUMTQ3MkB7NAABr0s7xXXRERES1iKGpgXmkoxdcHeyQbShB0onLcpdDRETUYFhNaIqLi4NCocDUqVMBAFeuXMHLL7+MgIAAODg4oEWLFvjnP/+J/Px8s89lZmYiKioKjo6O8Pb2xmuvvYby8nKzNlu3bkVwcDC0Wi3atWuH+Pj4KvtfuHAhWrVqBXt7e4SFhWHPnj11dah1SqtW4fGuTQEAP6RkyVwNERFRw2EVoSk5ORlLlixB165dpWXnz5/H+fPn8dFHH+HgwYOIj4/Hhg0bMG7cOKmN0WhEVFQUSktLsWvXLixbtgzx8fGYNWuW1ObUqVOIiorCI488grS0NEydOhUvvvgiNm7cKLVZsWIFYmJiMHv2bKSmpqJbt26IjIxETo5tvgD32RB/AMBvB/XIv1YmczVEREQNhJBZQUGBaN++vUhISBB9+/YVU6ZMuW3blStXCo1GI8rKyoQQQqxfv14olUqh1+ulNosWLRI6nU6UlJQIIYSYPn266Ny5s9l2hg0bJiIjI6X50NBQER0dLc0bjUbh5+cnYmNjLT6O/Px8AUDk5+db/Jm6YjKZxIBPtomWM9aK/0s6LXc5REREVqsm39+yX2mKjo5GVFQUIiIi7to2Pz8fOp0OarUaAJCUlIQuXbrAx8dHahMZGQmDwYBDhw5JbW7ddmRkJJKSkgAApaWlSElJMWujVCoREREhtalOSUkJDAaD2WQtFAoFngmpGLNpVcpZmashIiJqGGQNTcuXL0dqaipiY2Pv2vbSpUv417/+hQkTJkjL9Hq9WWACIM3r9fo7tjEYDLh27RouXboEo9FYbZvKbVQnNjYWrq6u0uTv73/XY6hPQ3o0g1qpwP6sPBzVF8hdDhERkc2TLTRlZWVhypQp+Pbbb2Fvb3/HtgaDAVFRUQgMDMQ777xTPwXexcyZM5Gfny9NWVnW1ena01mL/p0qxmxatde6aiMiIrJFNQ5NqampSE9Pl+Z//vlnDBkyBG+88QZKS0st3k5KSgpycnIQHBwMtVoNtVqNbdu2Yf78+VCr1TAajQCAgoICDBw4EC4uLli9ejXs7Oykbfj6+iI7O9tsu5Xzvr6+d2yj0+ng4OAAT09PqFSqattUbqM6Wq0WOp3ObLI2lR3CV+87h9Jyk8zVEBER2bYah6aXXnoJf/31FwDg5MmTeO655+Do6IhVq1Zh+vTpFm+nf//+SE9PR1pamjSFhIRg5MiRSEtLg0qlgsFgwIABA6DRaPDLL79UuSIVHh6O9PR0s6fcEhISoNPpEBgYKLVJTEw0+1xCQgLCw8MBABqNBj179jRrYzKZkJiYKLWxVX07eMHLRYvLhaXYnGGbTwISERFZixqHpr/++gvdu3cHAKxatQp9+vTBd999h/j4ePz4448Wb8fFxQVBQUFmk5OTEzw8PBAUFCQFpsLCQvzvf/+DwWCAXq+HXq+XrkINGDAAgYGBGDVqFPbv34+NGzfirbfeQnR0NLRaLQBg4sSJOHnyJKZPn46MjAx8/vnnWLlyJaZNmybVEhMTgy+++ALLli3DkSNHMGnSJBQWFmLMmDE1PT1WRa1S4m/BFSOE8xYdERHR/VHX9ANCCJhMFbd6Nm3ahMcffxwA4O/vj0uXLtVaYampqdi9ezcAoF27dmbrTp06hVatWkGlUmHt2rWYNGkSwsPD4eTkhNGjR+O9996T2rZu3Rrr1q3DtGnTMG/ePDRv3hxffvklIiMjpTbDhg3DxYsXMWvWLOj1enTv3h0bNmyo0jncFj3T0x9Ltp3E1r8uIsdQDG/dnfuPERERUfUUQogavaDs0Ucfhb+/PyIiIjBu3DgcPnwY7dq1w7Zt2zB69GicPn26jkq1bgaDAa6urtKwCNZk6KJdSDmTi9cHdcTEvm3lLoeIiMhq1OT7u8a35+bOnYvU1FRMnjwZb775pnQV6IcffkDv3r3vrWKqU89eH7Np5d4s1DAjExER0XU1vtJ0O8XFxVCpVGZPtzUm1nyl6WpJOR749yZcKzPix0nh6NnSXe6SiIiIrEKdXmnKysrC2bM3Rpnes2cPpk6diq+//rrRBiZr56xVY3CXipf4frebHcKJiIjuRY1D04gRI7BlyxYAFaNtP/bYY9izZw/efPNNsw7YZF1G9moBAPh1/3lcLCiRuRoiIiLbU+PQdPDgQYSGhgIAVq5ciaCgIOzatQvffvst4uPja7s+qiXBLZqgu78bSo0mfLv7jNzlEBER2Zwah6aysjJpDKRNmzbhySefBAB07NgRFy5cqN3qqFaNe6g1AOCbP8+gpNwoczVERES2pcahqXPnzli8eDF27NiBhIQEDBw4EABw/vx5eHh41HqBVHsGBvmiqas9Ll0txS9p5+Uuh4iIyKbUODR98MEHWLJkCfr164fhw4ejW7duAIBffvlFum1H1slOpcTz4a0AAF/tPM3hB4iIiGrgnoYcMBqNMBgMaNKkibTs9OnTcHR0hLe3d60WaCuseciBm+UVlSI8djOulRnx/fheCG/Lq4NERNR41emQAwCgUqlQXl6OP/74A3/88QcuXryIVq1aNdrAZEvcHDUY2rPifXRf7TwlczVERES2o8ahqbCwEGPHjkXTpk3Rp08f9OnTB35+fhg3bhyKiorqokaqZS/0rugQvulINs5cLpS5GiIiIttQ49AUExODbdu24ddff0VeXh7y8vLw888/Y9u2bXjllVfqokaqZe28ndEvwAtCAEt3npa7HCIiIptQ49D0448/4n//+x8GDRoEnU4HnU6HwYMH44svvsAPP/xQFzVSHRj7YMXVplV7s2AoLpO5GiIiIutX49BUVFQEHx+fKsu9vb15e86GPNzeE+29nVFYasTKZL5ahYiI6G5qHJrCw8Mxe/ZsFBcXS8uuXbuGd999F+Hh4bVaHNUdhUKBsdcHu1y68zTKjCaZKyIiIrJu6pp+YN68eYiMjETz5s2lMZr2798PrVaL33//vdYLpLrzdI9m+Pj3v3Au7xp+3X8efwtuLndJREREVqvGV5qCgoJw7NgxxMbGonv37ujevTvi4uJw/PhxdO7cuS5qpDpib6fC2IdaAQA+33oCJhMHuyQiIrqdexrcsjonT57ExIkTG+3VJlsZ3PJWhuIyPBi3GQXF5VgyqiciO/vKXRIREVG9qfPBLatTUFCAxMTE2toc1ROdvR2eD28JoOJqE1+tQkREVL1aC01ku8Y82BpatRL7s/Kw68RlucshIiKySgxNBE9nLYaHtgAAfL71uMzVEBERWSeGJgIAjO/TBmqlAjuPX8b+rDy5yyEiIrI6Fg850KNHDygUituu58CWtq2ZmwOe6t4MP6aexedbj2PJqBC5SyIiIrIqFoemIUOG1GEZZA0m9WuDn/adxcZD2TiWXYD2Pi5yl0RERGQ1am3IgcbOVoccuNXE/0vBhkN6PN61KRaMCJa7HCIiojoly5AD1DBMiWgPAFiXfgFH9QUyV0NERGQ9GJrITKemOkR1aQohgHmJf8ldDhERkdVgaKIqpkS0h0IBrE/X4/B5g9zlEBERWQWGJqqig48LHu/qBwCYu4lXm4iIiACGJrqNKf3bQ6kAfj+cjfSz+XKXQ0REJLsahaby8nJ8+OGHCA4OhrOzM5ydnREcHIyPPvoIZWVldVUjyaCdtzOe6t4MAPDBhgyZqyEiIpKfxaHp2rVr6NevH15//XV4eXnhxRdfxIsvvggvLy/MmDED/fv3R3FxcV3WSvUs5rEO0KiU+OP4JWz/66Lc5RAREcnK4sEt4+LikJWVhX379qFr165m6/bv348nn3wScXFxeOedd2q7RpKJv7sj/tGrJb7aeQpxv2XgoXaeUCpvPyo8ERFRQ2bxlably5fjk08+qRKYAKBbt2746KOP8N1339VqcSS/yY+2g4tWjcMXDPh5/zm5yyEiIpKNxaHpzJkzCA0Nve36Xr16ITMzs1aKIuvh7qTBxH5tAQAfbfwLxWVGmSsiIiKSh8WhSafTIScn57br9Xo9XFz4rrKGaOyDreGrs8e5vGv45s8zcpdDREQkC4tD0yOPPIL//Oc/t10fFxeHRx55pFaKIuvioFFh2mMVr1dZsOU48q/xSUkiImp8LA5Ns2fPxu+//45evXph5cqVOHDgAPbv34/ly5cjLCwMv//+O2bPnl2XtZKMhgY3R3tvZ+QVlWHR1hNyl0NERFTvLA5NgYGBSEhIQEFBAZ577jn06NEDwcHBGDFiBAoKCvD777+jc+fO91xIXFwcFAoFpk6dKi3773//i379+kGn00GhUCAvL6/K565cuYKRI0dCp9PBzc0N48aNw9WrV83aHDhwAA8//DDs7e3h7++POXPmVNnOqlWr0LFjR9jb26NLly5Yv379PR9LQ6RWKTFjYEcAwFc7TyHrSpHMFREREdWvGg1u2atXLxw6dAipqan4/vvv8f333yM1NRWHDx9GeHj4PReRnJyMJUuWVHkyr6ioCAMHDsQbb7xx28+OHDkShw4dQkJCAtauXYvt27djwoQJ0nqDwYABAwagZcuWSElJwYcffoh33nkH//3vf6U2u3btwvDhwzFu3Djs27cPQ4YMwZAhQ3Dw4MF7PqaGqH8nb4S38UBpuQlxv3HASyIiamTEfSopKREFBQX3/PmCggLRvn17kZCQIPr27SumTJlSpc2WLVsEAJGbm2u2/PDhwwKASE5Olpb99ttvQqFQiHPnzgkhhPj8889FkyZNRElJidRmxowZIiAgQJp/9tlnRVRUlNm2w8LCxEsvvWTxceTn5wsAIj8/3+LP2KLD5/NF69fXipYz1oo/T1ySuxwiIqL7UpPv7xpdaVq6dClefvllfPvttwCAN954Ay4uLnB1dcVjjz2Gy5cv1zi0RUdHIyoqChERETX+bFJSEtzc3BASEiIti4iIgFKpxO7du6U2ffr0gUajkdpERkbi6NGjyM3Nldrcuv/IyEgkJSXddt8lJSUwGAxmU2PQqakOz4W2AAC8t/YwjCYhc0VERET1w+LQ9P777yM6OhoZGRn45z//iUmTJmHp0qV47733EBcXh4yMDLz11ls12vny5cuRmpqK2NjYGhcOVAxz4O3tbbZMrVbD3d0der1eauPj42PWpnL+bm0q11cnNjYWrq6u0uTv739Px2CLXnmsA1zs1Th03oAfUrLkLoeIiKheWPwalfj4ePzvf//D8OHDsXfvXoSFhWHlypUYOnQoACAoKAgTJ060eMdZWVmYMmUKEhISYG9vX/PKZTZz5kzExMRI8waDodEEJw9nLab0b49/rzuCDzf+hcFdmsLF3k7usoiIiOqUxVeaMjMz8dBDDwEAQkJCoFarERQUJK3v2rUrLly4YPGOU1JSkJOTg+DgYKjVaqjVamzbtg3z58+HWq2G0Xj3kad9fX2rDLhZXl6OK1euwNfXV2qTnZ1t1qZy/m5tKtdXR6vVQqfTmU2NyfPhrdDG0wmXrpZgfuIxucshIiKqcxaHprKyMmi1Wmleo9HAzu7G1QVLg06l/v37Iz09HWlpadIUEhKCkSNHIi0tDSqV6q7bCA8PR15eHlJSUqRlmzdvhslkQlhYmNRm+/btKCu7MSBjQkICAgIC0KRJE6lNYmKi2bYTEhLu64nAhk6jVuLtJwIBAF/tPI0jFxpHny4iImq8LL49BwCHDx+W+vkIIZCRkSGNiXTp0qUa7djFxcXsShUAODk5wcPDQ1qu1+uh1+tx/PhxAEB6ejpcXFzQokULuLu7o1OnThg4cCDGjx+PxYsXo6ysDJMnT8Zzzz0HPz8/AMCIESPw7rvvYty4cZgxYwYOHjyIefPm4dNPP5X2O2XKFPTt2xcff/wxoqKisHz5cuzdu9dsWAKq6pEAbwwK8sVvB/V4c3U6fpjYG0qlQu6yiIiI6oalj+QpFAqhVCqFQqGoMlUuVyqV9/PUX5UhB2bPni0AVJmWLl0qtbl8+bIYPny4cHZ2FjqdTowZM6bKEAj79+8XDz30kNBqtaJZs2YiLi6uyr5XrlwpOnToIDQajejcubNYt25djWpvLEMO3Op8XpEIfPs30XLGWvHd7jNyl0NERFQjNfn+VgghLHpm/MwZy17U2rJly3tLbzbOYDDA1dUV+fn5ja5/0//+OIV/rT0MVwc7JL7SF57O2rt/iIiIyArU5Pvb4ttzdwtDeXl5WL9+faMNTY3Z6PCW+DHlLA5fMOA/647gk2Hd5S6JiIio1tVocMs7OXPmDEaNGlVbmyMbolYp8f7TQVAogJ/2ncOuEzXr30ZERGQLai00UePWo0UTjAyrGCn8rdUHUVxm+ZOUREREtoChiWrNa5Ed4eWixclLhfh86wm5yyEiIqpVDE1Ua1wd7PDOE50BAIu2Hsex7AKZKyIiIqo9FncEnz9//h3Xnzt37r6LIds3uIsv+nf0RmJGDmb+lI6VL4Vz7CYiImoQLB5yoHXr1hZt8NSpU/dVkK1qzEMO3Opc3jU89sk2FJUa8f7TQRgZxicqiYjIOtXJkAONNQxRzTVzc8CrAwLw3trDiFufgYhOPvDR2d5LmYmIiG7GPk1UJ0b3boWuzV1RUFKOd389JHc5RERE983i0DR48GDk5+dL83FxccjLy5PmL1++jMDAwFotjmyXSqlA3N+6QqVUYH26HgmHs+UuiYiI6L5YHJo2btyIkpISaf4///kPrly5Is2Xl5fj6NGjtVsd2bRAPx3GP9wGADDr54O4WlIuc0VERET3zuLQdGt/cQv7j1MjN6V/e7Rwd8SF/GJ8tJGhmoiIbBf7NFGdctCo8P7TQQCAZUmnsS8zV+aKiIiI7o3FoUmhUEChUFRZRnQ3D7f3wt96NIMQwMyf0lFmNMldEhERUY1ZPOSAEAIvvPACtFotAKC4uBgTJ06Ek5MTAJj1dyK61ZtRnbDlaA4y9AX4YsdJ/L9+7eQuiYiIqEYsHtxyzJgxFm1w6dKl91WQreLglnf3Y8pZvLJqP7RqJTZO7YNWnk5yl0RERI1cTb6/LQ5NdGcMTXcnhMA//rcbO49fxoPtPPDNuDDe4iUiIlnV5PubHcGp3igUCrw/pAu0aiV2Hr+Mn1L5vkIiIrIdDE1Ur1p5OmFqRAcAwL/XHcblq+wLR0REtoGhierdiw+3RkdfF+QWleH9dUfkLoeIiMgiDE1U7+xUSsQN7QqFAvhp3znsOHZR7pKIiIjuiqGJZNHd3w2jw1sBAN5cfRDXSo3yFkRERHQXDE0km1cjA9DU1R6ZV4owL/GY3OUQERHdEUMTycZZq8a/nqp4xcoXO07i8HmDzBURERHdHkMTySoi0AeDu/jCaBKY+dMBGE0cNoyIiKwTQxPJ7p0nOsPFXo39Z/MRv+u03OUQERFVi6GJZOets8fMQZ0AAHM2ZOB4ToHMFREREVXF0ERWYXioP/p08EJJuQlTV6ShtNwkd0lERERmGJrIKigUCnz4965wc7TDwXMGfLaZT9MREZF1YWgiq+Gjs8f7Q7oAABZuOY6UM7kyV0RERHQDQxNZlaiuTfF0j2YwCSBmZRoKS8rlLomIiAgAQxNZoXee7Aw/V3ucuVyEf687LHc5REREABiayAq5Otjho2e7QaEAvt+ThY2H9HKXRERExNBE1ql3W09MeLgNAOD1Hw8gx1Asc0VERNTYMTSR1YoZ0AGBTXXILSrDK6v2w8TRwomISEYMTWS1tGoV5g/vDq1aiR3HLnG0cCIikhVDE1m1dt4ueCuqYrTwuA0ZyNDzpb5ERCQPqwlNcXFxUCgUmDp1qrSsuLgY0dHR8PDwgLOzM4YOHYrs7Gyzz2VmZiIqKgqOjo7w9vbGa6+9hvJy88fUt27diuDgYGi1WrRr1w7x8fFV9r9w4UK0atUK9vb2CAsLw549e+riMOke/KNXSzza0Rul5SZM+T4NxWVGuUsiIqJGyCpCU3JyMpYsWYKuXbuaLZ82bRp+/fVXrFq1Ctu2bcP58+fxt7/9TVpvNBoRFRWF0tJS7Nq1C8uWLUN8fDxmzZoltTl16hSioqLwyCOPIC0tDVOnTsWLL76IjRs3Sm1WrFiBmJgYzJ49G6mpqejWrRsiIyORk5NT9wdPd6VQKDDn713h6azB0ewCzNlwVO6SiIioMRIyKygoEO3btxcJCQmib9++YsqUKUIIIfLy8oSdnZ1YtWqV1PbIkSMCgEhKShJCCLF+/XqhVCqFXq+X2ixatEjodDpRUlIihBBi+vTponPnzmb7HDZsmIiMjJTmQ0NDRXR0tDRvNBqFn5+fiI2Ntfg48vPzBQCRn59v+cFTjWw+ki1azlgrWs5YK7YdzZG7HCIiagBq8v0t+5Wm6OhoREVFISIiwmx5SkoKysrKzJZ37NgRLVq0QFJSEgAgKSkJXbp0gY+Pj9QmMjISBoMBhw4dktrcuu3IyEhpG6WlpUhJSTFro1QqERERIbUh6/BIR288H94SAPDKqv24Ulgqc0VERNSYyBqali9fjtTUVMTGxlZZp9frodFo4ObmZrbcx8cHer1eanNzYKpcX7nuTm0MBgOuXbuGS5cuwWg0VtumchvVKSkpgcFgMJuo7r0xuBPaeTvjYkEJZvx4AEJwGAIiIqofsoWmrKwsTJkyBd9++y3s7e3lKuOexcbGwtXVVZr8/f3lLqlRsLdTYd5z3WGnUiDhcDaWJ2fJXRIRETUSsoWmlJQU5OTkIDg4GGq1Gmq1Gtu2bcP8+fOhVqvh4+OD0tJS5OXlmX0uOzsbvr6+AABfX98qT9NVzt+tjU6ng4ODAzw9PaFSqaptU7mN6sycORP5+fnSlJXFL+/60tnPFdMjOwIA3vv1ME5evCpzRURE1BjIFpr69++P9PR0pKWlSVNISAhGjhwp/dnOzg6JiYnSZ44ePYrMzEyEh4cDAMLDw5Genm72lFtCQgJ0Oh0CAwOlNjdvo7JN5TY0Gg169uxp1sZkMiExMVFqUx2tVgudTmc2Uf0Z91BrPNjOA9fKjJiyPA2l5Sa5SyIiogZOLdeOXVxcEBQUZLbMyckJHh4e0vJx48YhJiYG7u7u0Ol0ePnllxEeHo5evXoBAAYMGIDAwECMGjUKc+bMgV6vx1tvvYXo6GhotVoAwMSJE7FgwQJMnz4dY8eOxebNm7Fy5UqsW7dO2m9MTAxGjx6NkJAQhIaGYu7cuSgsLMSYMWPq6WxQTSmVCnz8THcMnLcd6efy8cGGDLz9eKDcZRERUQMmW2iyxKeffgqlUomhQ4eipKQEkZGR+Pzzz6X1KpUKa9euxaRJkxAeHg4nJyeMHj0a7733ntSmdevWWLduHaZNm4Z58+ahefPm+PLLLxEZGSm1GTZsGC5evIhZs2ZBr9eje/fu2LBhQ5XO4WRdfF3t8eHfu2H813vxvz9OIbS1OyI73/6WKhER0f1QCD5+VCsMBgNcXV2Rn5/PW3X17P11h/HFjlPQ2aux7p8Pw9/dUe6SiIjIRtTk+1v2cZqI7tf0gR3Ro4UbDMXlmPxdKvs3ERFRnWBoIptnp1JiwYhguDrYYf/ZfMT+dkTukoiIqAFiaKIGoZmbAz55thsAYOnO09hw8ILMFRERUUPD0EQNRv9OPnipTxsAwCsr9+N4ToHMFRERUUPC0EQNyquRAejVxh2FpUZM+DoFhuIyuUsiIqIGgqGJGpTK/k1+rvY4eakQ05anwWTiA6JERHT/GJqowfF01mLJqBBo1UokZuRg7qa/5C6JiIgaAIYmapC6NHdF7N+6AADmbz6ODQf1MldERES2jqGJGqy/BTfHmAdbAQBeWZmGY9nsGE5ERPeOoYkatDcGd5I6hr/49V5cKSyVuyQiIrJRDE3UoNmplFg4Ihj+7g44c7kIL/3fXpSUG+Uui4iIbBBDEzV4Hs5afDX6AbjYq5F8OhfTfzgAvnKRiIhqiqGJGoX2Pi5YNLIn1EoFfk47j3mJx+QuiYiIbAxDEzUaD7X3xL+GBAEA5m46hjX7zslcERER2RKGJmpUhoe2kF61Mv2HA9h1/JLMFRERka1gaKJGZ8bAjhjcxRelRhMm/F8KDp7Ll7skIiKyAQxN1OgolQp88mx39Grjjqsl5Xhh6R6cuVwod1lERGTlGJqoUbK3U+G/z4cgsKkOl66WYtT/9iCnoFjusoiIyIoxNFGjpbO3Q/zYB9DC3RGZV4rwwlfJKCguk7ssIiKyUgxN1Kh5u9jj67Gh8HTW4PAFAyZ8nYLiMg5+SUREVTE0UaPXytMJ8WNC4aRRIenkZcSsTIPRxMEviYjIHEMTEYCgZq747/Mh0KiUWJ+ux+xfDnLUcCIiMsPQRHTdg+088cmwblAogG/+zMT8xONyl0RERFaEoYnoJo939cO7T3YGAHy66S988+cZmSsiIiJrwdBEdIvnw1vhn4+2AwC8/fNB/JZ+QeaKiIjIGjA0EVVj2mMdMDy0BYQApixPw06+boWIqNFjaCKqhkKhwL+HBCGysw9KjSaMW5aMXScYnIiIGjOGJqLbUCkVmPdcD/QL8EJxmQlj45ORdOKy3GUREZFMGJqI7sDeToXF/+iJvh1uBKc/TzI4ERE1RgxNRHdhb6fCklEVwelamRFjljI4ERE1RgxNRBaoDE59GJyIiBothiYiC9nbqfDfUT3xcHtPXCsz4oWle7D9r4tyl0VERPWEoYmoBuztVPji+RA8cr1z+IvL9iLhcLbcZRERUT1gaCKqoYpbdSEY2NkXpUYTJn2TgrUHzstdFhER1TGGJqJ7oFErsWBEDwzp7odyk8A/v9+HH1POyl0WERHVIYYmonukVinx8bPd8dwD/jAJ4JVV+/muOiKiBoyhieg+qJQKxP6tC17o3QoA8Naag5ifeAxCCHkLIyKiWsfQRHSfFAoFZj8RiJevv+T3k4S/MOvnQzCaGJyIiBoSWUPTokWL0LVrV+h0Ouh0OoSHh+O3336T1p84cQJPP/00vLy8oNPp8OyzzyI72/xJpStXrmDkyJHQ6XRwc3PDuHHjcPXqVbM2Bw4cwMMPPwx7e3v4+/tjzpw5VWpZtWoVOnbsCHt7e3Tp0gXr16+vm4OmBkmhUOCVAQF476nOUCiA//vzDCZ/l4riMqPcpRERUS2RNTQ1b94ccXFxSElJwd69e/Hoo4/iqaeewqFDh1BYWIgBAwZAoVBg8+bN2LlzJ0pLS/HEE0/AZDJJ2xg5ciQOHTqEhIQErF27Ftu3b8eECROk9QaDAQMGDEDLli2RkpKCDz/8EO+88w7++9//Sm127dqF4cOHY9y4cdi3bx+GDBmCIUOG4ODBg/V6Psj2PR/eCguGB0OjUuK3g3qM/moPDMVlcpdFRES1QCGsrPOFu7s7PvzwQ/j7+2PQoEHIzc2FTqcDAOTn56NJkyb4/fffERERgSNHjiAwMBDJyckICQkBAGzYsAGDBw/G2bNn4efnh0WLFuHNN9+EXq+HRqMBALz++utYs2YNMjIyAADDhg1DYWEh1q5dK9XRq1cvdO/eHYsXL7aoboPBAFdXV+Tn50v1UuO168QlTPg6BVdLytHR1wXLxobCR2cvd1lERHSLmnx/W02fJqPRiOXLl6OwsBDh4eEoKSmBQqGAVquV2tjb20OpVOKPP/4AACQlJcHNzU0KTAAQEREBpVKJ3bt3S2369OkjBSYAiIyMxNGjR5Gbmyu1iYiIMKsnMjISSUlJt623pKQEBoPBbCKq1LutJ1a81AteLlpk6AswdNEuHM8pkLssIiK6D7KHpvT0dDg7O0Or1WLixIlYvXo1AgMD0atXLzg5OWHGjBkoKipCYWEhXn31VRiNRly4cAEAoNfr4e3tbbY9tVoNd3d36PV6qY2Pj49Zm8r5u7WpXF+d2NhYuLq6SpO/v//9nQhqcDr7ueKnSb3RysMRZ3Ov4enPd2Hn8Utyl0VERPdI9tAUEBCAtLQ07N69G5MmTcLo0aNx+PBheHl5YdWqVfj111/h7OwMV1dX5OXlITg4GEql7GVj5syZyM/Pl6asrCy5SyIr5O/uiB8n9UZIyyYoKC7H6K/24Ps9mXKXRURE90AtdwEajQbt2lU8qt2zZ08kJydj3rx5WLJkCQYMGIATJ07g0qVLUKvVcHNzg6+vL9q0aQMA8PX1RU5Ojtn2ysvLceXKFfj6+kptbn3irnL+bm0q11dHq9Wa3Tokuh0PZy2+eTEMM348gJ/TzmPmT+k4fakQMwZ2hFKpkLs8IiKykPyXbG5hMplQUlJitszT0xNubm7YvHkzcnJy8OSTTwIAwsPDkZeXh5SUFKnt5s2bYTKZEBYWJrXZvn07yspuPMGUkJCAgIAANGnSRGqTmJhots+EhASEh4fXyTFS42Nvp8LcYd0xNaI9AGDJ9pOY9G0KCkvKZa6MiIgsJWtomjlzJrZv347Tp08jPT0dM2fOxNatWzFy5EgAwNKlS/Hnn3/ixIkT+Oabb/DMM89g2rRpCAgIAAB06tQJAwcOxPjx47Fnzx7s3LkTkydPxnPPPQc/Pz8AwIgRI6DRaDBu3DgcOnQIK1aswLx58xATEyPVMWXKFGzYsAEff/wxMjIy8M4772Dv3r2YPHly/Z8UarAUCgWmRnTA3GHdoVEpsfFQNoYs3IlTlwrlLo2IiCwhZDR27FjRsmVLodFohJeXl+jfv7/4/fffpfUzZswQPj4+ws7OTrRv3158/PHHwmQymW3j8uXLYvjw4cLZ2VnodDoxZswYUVBQYNZm//794qGHHhJarVY0a9ZMxMXFVall5cqVokOHDkKj0YjOnTuLdevW1ehY8vPzBQCRn59fo89R47T39BXxwL8TRMsZa0XQrA1i02G93CURETVKNfn+trpxmmwVx2mimsoxFOP/fZuKvWcqhr6YGtEe/3y0Pfs5ERHVI5scp4mosfHW2eO78b3wfHhLAMDcTccwblkyLl8tucsniYhIDgxNRDLSqJV476kgfPj3rtColdhy9CIGzduBXRzPiYjI6jA0EVmBZ0L8seb/PYi2Xk7IKSjByP/txocbM1BmNN39w0REVC8YmoisRKCfDr++/BCee8AfQgALt5zAsCVJfLqOiMhKMDQRWRFHjRpxQ7tiwYgecLFXIzUzD4PmbUf8zlMwmfjMBhGRnBiaiKzQ41398NuUh9G7rQeKy0x459fDGPHln8i6UiR3aUREjRZDE5GVat7EEd+MC8N7T3WGg50Kf568goFzt+Pb3WfAkUKIiOofQxORFVMqFXg+vBU2TH0Yoa3cUVhqxJurD2Lkl7tx8uJVucsjImpUGJqIbEBLDycsn9ALbz8eCK1aiV0nLmPgvB2Yt+kYSsqNcpdHRNQoMDQR2QilUoFxD7XG79P64OH2nigtN+HTTX9h0LwdSDpxWe7yiIgaPIYmIhvT0sMJX48NxfzhPeDprMXJi4UY/sWfeGXlflwpLJW7PCKiBouhicgGKRQKPNnND4mv9MU/erWAQgH8mHoWj368Fd/uPgMjhycgIqp1fGFvLeELe0lOqZm5eOOndGToCwAAQc10ePfJIPRs2UTmyoiIrFtNvr8ZmmoJQxPJrdxowv/9eQafJPyFguJyAMDfgpthemRH+Lray1wdEZF1YmiSAUMTWYtLV0vw4YajWLE3CwBgb6fE2AdbY2K/ttDZ28lcHRGRdWFokgFDE1mbtKw8/HvtYew9kwsAaOJoh8mPtsc/erWAVq2SuToiIuvA0CQDhiayRkIIJBzOxgcbMnDiYsWLf/3dHfDqgAA80dUPSqVC5gqJiOTF0CQDhiayZuVGE35IOYtPN/2FbEMJAKC9tzMmP9oOj3f1g4rhiYgaKYYmGTA0kS24VmrEVztPYcm2EzBc7yzextMJ0Y+0w1Pd/aBWcRQSImpcGJpkwNBEtsRQXIavd53Gl3+cQl5RGQCgpYcjJvZti6d7NIO9Hfs8EVHjwNAkA4YmskVXS8rxf0ln8MWOk9Jo4h5OGjwf3gr/6NUCHs5amSskIqpbDE0yYGgiW1ZUWo7vdmdi6c7TOJd3DQCgVSsxtGdzjHuoNdp6OctcIRFR3WBokgFDEzUE5UYT1h/U48sdJ3HgbL60/KF2nhgR1gKPBfrAjv2eiKgBYWiSAUMTNSRCCOw5dQVf7DiFxIxsVP6W8HLRYliIP54L9UfzJo7yFklEVAsYmmTA0EQN1dncIizfk4XlyVm4dLViuAKFAni4vRf+1qMZBnT2gaNGLXOVRET3hqFJBgxN1NCVGU1IOJyN73Zn4o/jl6TljhoVBnb2xdPBzdC7rSfHfCIim8LQJAOGJmpMTl8qxE/7zmHNvnPIvFIkLfd20WJQkC8ig3wR2sqd4z4RkdVjaJIBQxM1RkIIpGbmYfW+s1h74II05hMAuDtp8FgnHwwM8kXvdh583x0RWSWGJhkwNFFjV1puwo5jF7HxkB4Jh7ORe1OActaq0beDF/oFeKFvgBe8XexlrJSI6AaGJhkwNBHdUG40Yc+pK9hwSI+Nh/TS++4qBTXT4ZEAb/QL8EZ3fzf2gyIi2TA0yYChiah6JpPA/rN52HL0IrYezTEb/wkA3Bzt8HB7L/Ru64HebT3Qwt0RCgVDFBHVD4YmGTA0EVnmYkEJtv11EVuO5mD7XxdRcP3FwZX8XO0R3tYTvdt6ILytB/zcHGSqlIgaA4YmGTA0EdVcudGE1Mw8/HH8Ev48cRn7snJRZjT/ldTKwxGhrd0R3KIJerZsgrZezlDydh4R1RKGJhkwNBHdv6LScuw9nYukk5ex68RlpJ/Ng+mW31A6ezV6tGgihahu/q5wsbeTp2AisnkMTTJgaCKqfYbiMiSfuoK9Z3KReiYX+8/mobjMZNZGoQDaezsjqJkrulyfAv10HKWciCzC0CQDhiaiuldmNCHjQgFSM3ORciYXqZm5OJt7rUo7pQJo61URpCrDVKemLrwiRURVMDTJgKGJSB45hmIcOJuP9HP5OHiu4mdOQUm1bZs3cUBHXx06+rqgY1MXdPTVoZWHI0cuJ2rEGJpkwNBEZD1yDMU4eD4f6WcNSD+Xj0Pn83Ehv7jathq1Eh18nBHgo0On60EqwNcFns4aDn1A1AjYTGhatGgRFi1ahNOnTwMAOnfujFmzZmHQoEEAAL1ej9deew0JCQkoKChAQEAA3nzzTQwdOlTaxpUrV/Dyyy/j119/hVKpxNChQzFv3jw4OztLbQ4cOIDo6GgkJyfDy8sLL7/8MqZPn25Wy6pVq/D222/j9OnTaN++PT744AMMHjzY4mNhaCKybnlFpcjQFyDjggFHswtw5EIBjuoLcK3MWG17N0c7tPVyRlsvp+s/ndHGywkt3Hlliqghqcn3t6w9JZs3b464uDi0b98eQggsW7YMTz31FPbt24fOnTvj+eefR15eHn755Rd4enriu+++w7PPPou9e/eiR48eAICRI0fiwoULSEhIQFlZGcaMGYMJEybgu+++A1BxMgYMGICIiAgsXrwY6enpGDt2LNzc3DBhwgQAwK5duzB8+HDExsbi8ccfx3fffYchQ4YgNTUVQUFBsp0fIqo9bo4a9GrjgV5tPKRlJpNAVm6RFKAy9AZk6Atw+nIh8orKkHKmou/UzexUCrT0cDILU229KwKVjn2miBo0q7s95+7ujg8//BDjxo2Ds7MzFi1ahFGjRknrPTw88MEHH+DFF1/EkSNHEBgYiOTkZISEhAAANmzYgMGDB+Ps2bPw8/PDokWL8Oabb0Kv10Oj0QAAXn/9daxZswYZGRkAgGHDhqGwsBBr166V9tOrVy90794dixcvtqhuXmkiajiKy4w4dakQJy5exYmc6z+vT7c+vXczT2ct/N0d0LyJI/ybXP95fd7PzZ4vLSayQjZzpelmRqMRq1atQmFhIcLDwwEAvXv3xooVKxAVFQU3NzesXLkSxcXF6NevHwAgKSkJbm5uUmACgIiICCiVSuzevRtPP/00kpKS0KdPHykwAUBkZCQ++OAD5ObmokmTJkhKSkJMTIxZPZGRkVizZs1t6y0pKUFJyY3OpgaDoRbOAhFZA3s7FTo11aFTU/NfoCaTwAVDMU7k3AhRlaEqp6AEl65WTPsy86psU6EAfFzspRDV1NUeTV3t4evqcP2nPdwdNRy4k8iKyR6a0tPTER4ejuLiYjg7O2P16tUIDAwEAKxcuRLDhg2Dh4cH1Go1HB0dsXr1arRr1w5ARZ8nb29vs+2p1Wq4u7tDr9dLbVq3bm3WxsfHR1rXpEkT6PV6adnNbSq3UZ3Y2Fi8++6793fwRGRTlEoFmrk5oJmbA/p08DJbZyguQ+blImRdKcLZ3GvIyr3+8/r8tTIj9IZi6A3FSD6dW+327VQK+OjMw5SXsxZeLlp4Omvh6aKBl7MWTRiuiGQhe2gKCAhAWloa8vPz8cMPP2D06NHYtm0bAgMD8fbbbyMvLw+bNm2Cp6cn1qxZg2effRY7duxAly5dZK175syZZlenDAYD/P39ZayIiOSks7eTxoW6lRAClwtLpRB1Lu8a9PnFuJBf+bMYF6+WoMwocDb32vWxp6oPVgCgUirg7lQRoDxdtPB01sDLRQsvZy3cHDVo4mgn/WziqIHOwQ4qhiyi+yZ7aNJoNNKVo549eyI5ORnz5s3D9OnTsWDBAhw8eBCdO3cGAHTr1g07duzAwoULsXjxYvj6+iInJ8dse+Xl5bhy5Qp8fX0BAL6+vsjOzjZrUzl/tzaV66uj1Wqh1Wrv48iJqLFQKBQVV4qcteju71ZtmzKjCTkFJdDnX8OF/OIbYeqm234XC0qQW1QGo0ngYkHFPC5Ysn/A1aEiQLk5mv+sDFiuDnZwsVdD52AHnb0ddNf/rFUrOfQC0XWyh6ZbmUwmlJSUoKioCACgVJo/2qtSqWAyVXTEDA8PR15eHlJSUtCzZ08AwObNm2EymRAWFia1efPNN1FWVgY7u4onWxISEhAQEIAmTZpIbRITEzF16lRpPwkJCVLfKiKiumanUkq3/u6kzGjClcLSitB0tQSXCkpw6WqpFKxyi8qQV1SK3KJS5BWWoaCkHEIAeUVlyCsqu4e6FBUhqjJU2d/4qXNQw+WmgFX5Z5frbZy1ajhp1dCoOUQDNQyyPj03c+ZMDBo0CC1atEBBQQG+++47fPDBB9i4cSP69euHwMBANG3aFB999BE8PDywZs0avPbaa1i7dq00htKgQYOQnZ2NxYsXS0MOhISESEMO5OfnIyAgAAMGDMCMGTNw8OBBjB07Fp9++qnZkAN9+/ZFXFwcoqKisHz5cvznP/+p0ZADfHqOiKxRmdF0PTCVIreorCJMFZXiSuGNcJVbVIaC4jIYrpXDUFyGguJyFBSXVXlZ8r2yUyngpFXDSaOGk1YFJ+31QKVRw1GrksKVs1YNR43K7M+3rnPUqKFVK9mni2qNzQxuOW7cOCQmJuLChQtwdXVF165dMWPGDDz22GMAgGPHjuH111/HH3/8gatXr6Jdu3Z49dVXzYYguHLlCiZPnmw2uOX8+fNvO7ilp6cnXn75ZcyYMcOsllWrVuGtt96SBrecM2cOB7ckokbLZBIoLC1HQfGNIGW4VnbLn8vNwpahuBwF19sYistRWn774Rnul1athINGBXu1Cg4aVZV5BzsVtHZKONipYG9XMX9rO3s7FTRqZcWkqvipvT5VXa6CnUrBW5UNkM2EpoaEoYmIyFyZ0YSiEiMKS8tRWFKOqyXlKLxpvrCkHIWlxpvW3ZgvrNLWeNvR2+uTRq2E9qaApbklYGnVKrNlWpUSWrsb4auiXUUbO5UCGrUSamXFn+1UStiplFCrFNBc/6lWKqFRK663udHuRhvzz7LDf83Z5DhNRETUsNiplHB1VMLVsXZGSjeaBIrLKsJTsTSZpPlrpRXrSm5eVnbTslIjistvalduQmnlZDShpNx4Y/76sjKj+XWFynWo/p3QslMoKs67nVIBu+uBTKNSQC2FMAVU10OaSlk5XxHKbqyvmFcpFWafqVxX8VnlTW2vb79y/vq27a5v4+ZJqbjxGaVSAZXi5vWAUlGxb6Wy4inRm9crFQo4a9Vo4qS5+4moIwxNRERkE1TK632jtPX31WUyieuB6kaQKi2vGrBKjCaUlN1YXzEZq/nc9YBWZkK5yYSy68GszGhCubFiX+U3LSszmlBuEigrN6HMZN6uzGjCrfeKhLge7ACgVP4rc7Xt8a5NsWBEsGz7Z2giIiK6DaVSAXtlRf8na2Q03RSuKoPW9ZBVbjKhtFxI4azcKCramwSMphvz5SYhbefm+fLr7cqM5vPlJgGjsWK+3HT9M7fZdplJwHR9e0aTgFFU/DSJis+YRDXrru+rcl155TaEkP1VRAxNRERENqri1pX1hrqGhoNnEBEREVmAoYmIiIjIAgxNRERERBZgaCIiIiKyAEMTERERkQUYmoiIiIgswNBEREREZAGGJiIiIiILMDQRERERWYChiYiIiMgCDE1EREREFmBoIiIiIrIAQxMRERGRBRiaiIiIiCyglruAhkIIAQAwGAwyV0JERESWqvzervwevxOGplpSUFAAAPD395e5EiIiIqqpgoICuLq63rGNQlgSreiuTCYTzp8/DxcXFygUilrdtsFggL+/P7KysqDT6Wp123QDz3P94HmuHzzP9Yfnun7U1XkWQqCgoAB+fn5QKu/ca4lXmmqJUqlE8+bN63QfOp2O/0HWA57n+sHzXD94nusPz3X9qIvzfLcrTJXYEZyIiIjIAgxNRERERBZgaLIBWq0Ws2fPhlarlbuUBo3nuX7wPNcPnuf6w3NdP6zhPLMjOBEREZEFeKWJiIiIyAIMTUREREQWYGgiIiIisgBDExEREZEFGJqs3MKFC9GqVSvY29sjLCwMe/bskbskm/LOO+9AoVCYTR07dpTWFxcXIzo6Gh4eHnB2dsbQoUORnZ1tto3MzExERUXB0dER3t7eeO2111BeXl7fh2JVtm/fjieeeAJ+fn5QKBRYs2aN2XohBGbNmoWmTZvCwcEBEREROHbsmFmbK1euYOTIkdDpdHBzc8O4ceNw9epVszYHDhzAww8/DHt7e/j7+2POnDl1fWhW5W7n+YUXXqjy73vgwIFmbXie7y42NhYPPPAAXFxc4O3tjSFDhuDo0aNmbWrrd8XWrVsRHBwMrVaLdu3aIT4+vq4Pz2pYcp779etX5d/0xIkTzdrIep4FWa3ly5cLjUYjvvrqK3Ho0CExfvx44ebmJrKzs+UuzWbMnj1bdO7cWVy4cEGaLl68KK2fOHGi8Pf3F4mJiWLv3r2iV69eonfv3tL68vJyERQUJCIiIsS+ffvE+vXrhaenp5g5c6Ych2M11q9fL958803x008/CQBi9erVZuvj4uKEq6urWLNmjdi/f7948sknRevWrcW1a9ekNgMHDhTdunUTf/75p9ixY4do166dGD58uLQ+Pz9f+Pj4iJEjR4qDBw+K77//Xjg4OIglS5bU12HK7m7nefTo0WLgwIFm/76vXLli1obn+e4iIyPF0qVLxcGDB0VaWpoYPHiwaNGihbh69arUpjZ+V5w8eVI4OjqKmJgYcfjwYfHZZ58JlUolNmzYUK/HKxdLznPfvn3F+PHjzf5N5+fnS+vlPs8MTVYsNDRUREdHS/NGo1H4+fmJ2NhYGauyLbNnzxbdunWrdl1eXp6ws7MTq1atkpYdOXJEABBJSUlCiIovLaVSKfR6vdRm0aJFQqfTiZKSkjqt3Vbc+mVuMpmEr6+v+PDDD6VleXl5QqvViu+//14IIcThw4cFAJGcnCy1+e2334RCoRDnzp0TQgjx+eefiyZNmpid5xkzZoiAgIA6PiLrdLvQ9NRTT932MzzP9yYnJ0cAENu2bRNC1N7viunTp4vOnTub7WvYsGEiMjKyrg/JKt16noWoCE1Tpky57WfkPs+8PWelSktLkZKSgoiICGmZUqlEREQEkpKSZKzM9hw7dgx+fn5o06YNRo4ciczMTABASkoKysrKzM5xx44d0aJFC+kcJyUloUuXLvDx8ZHaREZGwmAw4NChQ/V7IDbi1KlT0Ov1ZufV1dUVYWFhZufVzc0NISEhUpuIiAgolUrs3r1batOnTx9oNBqpTWRkJI4ePYrc3Nx6Ohrrt3XrVnh7eyMgIACTJk3C5cuXpXU8z/cmPz8fAODu7g6g9n5XJCUlmW2jsk1j/Z1+63mu9O2338LT0xNBQUGYOXMmioqKpHVyn2e+sNdKXbp0CUaj0ewfBgD4+PggIyNDpqpsT1hYGOLj4xEQEIALFy7g3XffxcMPP4yDBw9Cr9dDo9HAzc3N7DM+Pj7Q6/UAAL1eX+3fQeU6qqryvFR33m4+r97e3mbr1Wo13N3dzdq0bt26yjYq1zVp0qRO6rclAwcOxN/+9je0bt0aJ06cwBtvvIFBgwYhKSkJKpWK5/kemEwmTJ06FQ8++CCCgoIAoNZ+V9yujcFgwLVr1+Dg4FAXh2SVqjvPADBixAi0bNkSfn5+OHDgAGbMmIGjR4/ip59+AiD/eWZoogZt0KBB0p+7du2KsLAwtGzZEitXrmxUv6CoYXruueekP3fp0gVdu3ZF27ZtsXXrVvTv31/GymxXdHQ0Dh48iD/++EPuUhq0253nCRMmSH/u0qULmjZtiv79++PEiRNo27ZtfZdZBW/PWSlPT0+oVKoqT2dkZ2fD19dXpqpsn5ubGzp06IDjx4/D19cXpaWlyMvLM2tz8zn29fWt9u+gch1VVXle7vRv19fXFzk5OWbry8vLceXKFZ77+9CmTRt4enri+PHjAHiea2ry5MlYu3YttmzZgubNm0vLa+t3xe3a6HS6RvU/cbc7z9UJCwsDALN/03KeZ4YmK6XRaNCzZ08kJiZKy0wmExITExEeHi5jZbbt6tWrOHHiBJo2bYqePXvCzs7O7BwfPXoUmZmZ0jkODw9Henq62RdPQkICdDodAgMD671+W9C6dWv4+vqanVeDwYDdu3ebnde8vDykpKRIbTZv3gyTyST9kgwPD8f27dtRVlYmtUlISEBAQECju2VkqbNnz+Ly5cto2rQpAJ5nSwkhMHnyZKxevRqbN2+ucruytn5XhIeHm22jsk1j+Z1+t/NcnbS0NAAw+zct63m+767kVGeWL18utFqtiI+PF4cPHxYTJkwQbm5uZk8N0J298sorYuvWreLUqVNi586dIiIiQnh6eoqcnBwhRMVjxC1atBCbN28We/fuFeHh4SI8PFz6fOXjrQMGDBBpaWliw4YNwsvLq9EPOVBQUCD27dsn9u3bJwCITz75ROzbt0+cOXNGCFEx5ICbm5v4+eefxYEDB8RTTz1V7ZADPXr0ELt37xZ//PGHaN++vdmj8Hl5ecLHx0eMGjVKHDx4UCxfvlw4Ojo2qkfh73SeCwoKxKuvviqSkpLEqVOnxKZNm0RwcLBo3769KC4ulrbB83x3kyZNEq6urmLr1q1mj7oXFRVJbWrjd0Xlo/CvvfaaOHLkiFi4cGGjGnLgbuf5+PHj4r333hN79+4Vp06dEj///LNo06aN6NOnj7QNuc8zQ5OV++yzz0SLFi2ERqMRoaGh4s8//5S7JJsybNgw0bRpU6HRaESzZs3EsGHDxPHjx6X1165dE//v//0/0aRJE+Ho6CiefvppceHCBbNtnD59WgwaNEg4ODgIT09P8corr4iysrL6PhSrsmXLFgGgyjR69GghRMWwA2+//bbw8fERWq1W9O/fXxw9etRsG5cvXxbDhw8Xzs7OQqfTiTFjxoiCggKzNvv37xcPPfSQ0Gq1olmzZiIuLq6+DtEq3Ok8FxUViQEDBggvLy9hZ2cnWrZsKcaPH1/lf6p4nu+uunMMQCxdulRqU1u/K7Zs2SK6d+8uNBqNaNOmjdk+Grq7nefMzEzRp08f4e7uLrRarWjXrp147bXXzMZpEkLe86y4fiBEREREdAfs00RERERkAYYmIiIiIgswNBERERFZgKGJiIiIyAIMTUREREQWYGgiIiIisgBDExEREZEFGJqIiIiILMDQREQ26eLFi5g0aRJatGgBrVYLX19fREZGYufOnSgtLYWnpyfi4uKq/ey//vUv+Pj4oKysDPHx8XBzc7vjvrZt24ZHH30U7u7ucHR0RPv27TF69GiUlpYCgEXbICLbx9BERDZp6NCh2LdvH5YtW4a//voLv/zyC/r164fLly9Do9HgH//4B5YuXVrlc0IIxMfH4/nnn4ednd1d93P48GEMHDgQISEh2L59O9LT0/HZZ59Bo9HAaDTWxaERkbWqlZexEBHVo9zcXAFAbN269bZtDhw4IACIHTt2mC2vfJ/bkSNHhBBCLF26VLi6ut52O59++qlo1arVbddX93642bNnCyGEKC4uFq+88orw8/MTjo6OIjQ0VGzZskX6bOW+V69eLdq1aye0Wq0YMGCAyMzMvPtJIKJ6xytNRGRznJ2d4ezsjDVr1qCkpKTaNl26dMEDDzyAr776ymz50qVL0bt3b3Ts2NGiffn6+uLChQvYvn17tet79+6NuXPnQqfT4cKFC7hw4QJeffVVAMDkyZORlJSE5cuX48CBA3jmmWcwcOBAHDt2TPp8UVER3n//fXz99dfYuXMn8vLy8Nxzz1lUGxHVL4YmIrI5arUa8fHxWLZsGdzc3PDggw/ijTfewIEDB8zajRs3DqtWrcLVq1cBAAUFBfjhhx8wduxYi/f1zDPPYPjw4ejbty+aNm2Kp59+GgsWLIDBYAAAaDQauLq6QqFQwNfXF76+vnB2dkZmZiaWLl2KVatW4eGHH0bbtm3x6quv4qGHHjK7bVhWVoYFCxYgPDwcPXv2xLJly7Br1y7s2bOnFs4UEdUmhiYisklDhw7F+fPn8csvv2DgwIHYunUrgoODER8fL7UZPnw4jEYjVq5cCQBYsWIFlEolhg0bZvF+VCoVli5dirNnz2LOnDlo1qwZ/vOf/6Bz5864cOHCbT+Xnp4Oo9GIDh06SFfGnJ2dsW3bNpw4cUJqp1ar8cADD0jzHTt2hJubG44cOVKDs0FE9YGhiYhslr29PR577DG8/fbb2LVrF1544QXMnj1bWq/T6fD3v/9durKzdOlSPPvss3B2dq7xvpo1a4ZRo0ZhwYIFOHToEIqLi7F48eLbtr969SpUKhVSUlKQlpYmTUeOHMG8efNqfrBEJDuGJiJqMAIDA1FYWGi2bNy4cfjjjz+wdu1a7Nq1C+PGjbvv/TRp0gRNmzaV9lXdk3Q9evSA0WhETk4O2rVrZzb5+vpK7crLy7F3715p/ujRo8jLy0OnTp3uu04iql1quQsgIqqpy5cv45lnnsHYsWPRtWtXuLi4YO/evZgzZw6eeuops7Z9+vRBu3bt8Pzzz6Njx47o3bt3jfa1ZMkSpKWl4emnn0bbtm1RXFyMr7/+GocOHcJnn30GAGjVqhWuXr2KxMREdOvWDY6OjujQoQNGjhyJ559/Hh9//DF69OiBixcvIjExEV27dkVUVBQAwM7ODi+//DLmz58PtVqNyZMno1evXggNDa2dk0VEtYZXmojI5jg7OyMsLAyffvop+vTpg6CgILz99tsYP348FixYYNZWoVBg7NixyM3NrVEH8EqhoaG4evUqJk6ciM6dO6Nv3774888/sWbNGvTt2xdAxRN0EydOxLBhw+Dl5YU5c+YAqLgd+Pzzz+OVV15BQEAAhgwZguTkZLRo0ULavqOjI2bMmIERI0bgwQcfhLOzM1asWHEfZ4eI6opCCCHkLoKIqDGKj4/H1KlTkZeXJ3cpRGQBXmkiIiIisgBDExEREZEFeHuOiIiIyAK80kRERERkAYYmIiIiIgswNBERERFZgKGJiIiIyAIMTUREREQWYGgiIiIisgBDExEREZEFGJqIiIiILMDQRERERGSB/w+x0z91ArIO/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal, AutoDiagonalNormal, AutoContinuous, AutoDelta, AutoMultivariateNormal, AutoLaplaceApproximation, AutoStructured\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import TraceEnum_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "pyro.clear_param_store()\n",
    "bnn_cat = BNN_Multi_Layer_SVI(in_dim=14,first_hid_dim=56,sec_hid_dim=112,thir_hid_dim=112,four_hid_dim=56,out_dim=2,prior_scale=1.5,bias_scale=10)\n",
    "guide = AutoDelta(bnn_cat)\n",
    "# guide = AutoDiagonalNormal(bnn_cat)\n",
    "num_steps = 2500\n",
    "\n",
    "init_lr = 0.0015\n",
    "gamma = 0.01\n",
    "lrd = gamma ** (1/num_steps)\n",
    "optim = ClippedAdam({'lr': init_lr, 'lrd': lrd, \"betas\": (0.95, 0.999)})\n",
    "# optim = Adam({\"lr\": 0.001,\"betas\": (0.95, 0.999)})\n",
    "\n",
    "svi = SVI(bnn_cat, guide, optim, TraceEnum_ELBO())\n",
    "losses = []\n",
    "steps = []\n",
    "\n",
    "for i in range(num_steps):\n",
    "    loss = svi.step(x_train,y_train)\n",
    "    losses.append(loss)\n",
    "    steps.append(i)\n",
    "    if i % (num_steps/10) == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (i + 1, loss / len(x_train)))\n",
    "\n",
    "plt.plot(steps,losses)\n",
    "plt.ylabel(\"ELBO Loss\")\n",
    "plt.xlabel(\"SVI Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "OBS:\n",
      "TN, FP, FN, TP\n",
      "[5049   16   43 3782]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5065\n",
      "           1       1.00      0.99      0.99      3825\n",
      "\n",
      "    accuracy                           0.99      8890\n",
      "   macro avg       0.99      0.99      0.99      8890\n",
      "weighted avg       0.99      0.99      0.99      8890\n",
      "\n",
      "RET:\n",
      "TN, FP, FN, TP\n",
      "[5047   18   47 3778]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5065\n",
      "           1       1.00      0.99      0.99      3825\n",
      "\n",
      "    accuracy                           0.99      8890\n",
      "   macro avg       0.99      0.99      0.99      8890\n",
      "weighted avg       0.99      0.99      0.99      8890\n",
      "\n",
      "---TEST SET---\n",
      "OBS:\n",
      "TN, FP, FN, TP\n",
      "[460 258 294 302]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62       718\n",
      "           1       0.54      0.51      0.52       596\n",
      "\n",
      "    accuracy                           0.58      1314\n",
      "   macro avg       0.57      0.57      0.57      1314\n",
      "weighted avg       0.58      0.58      0.58      1314\n",
      "\n",
      "RET:\n",
      "TN, FP, FN, TP\n",
      "[461 257 295 301]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63       718\n",
      "           1       0.54      0.51      0.52       596\n",
      "\n",
      "    accuracy                           0.58      1314\n",
      "   macro avg       0.57      0.57      0.57      1314\n",
      "weighted avg       0.58      0.58      0.58      1314\n",
      "\n",
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "Using OBS:\n",
      "max confidence: 0.94\n",
      "correct: 339\n",
      "guessed: 342\n",
      "risked: 29426.427734375\n",
      "made: 7143.8037109375\n",
      "ROI: 0.24\n",
      "\n",
      "Using RET:\n",
      "max confidence: 0.88\n",
      "correct: 340\n",
      "guessed: 342\n",
      "risked: 29471.787109375\n",
      "made: 7155.6943359375\n",
      "ROI: 0.24\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "Using OBS:\n",
      "max confidence: 0.92\n",
      "correct: 323\n",
      "guessed: 427\n",
      "risked: 28576.576171875\n",
      "made: 163.08285522460938\n",
      "ROI: 0.01\n",
      "\n",
      "Using RET:\n",
      "max confidence: 0.88\n",
      "correct: 312\n",
      "guessed: 418\n",
      "risked: 28216.61328125\n",
      "made: 60.244606018066406\n",
      "ROI: 0.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "predictive = Predictive(bnn_cat, guide=guide, num_samples=500, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "\n",
    "pred_performance(predictive,x_train,x_test,y_train,y_test)\n",
    "make_bets(predictive,bet_data_train,bet_data_test,bet_train,x_test,bet_samps_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [1:34:04, 28.22s/it, step size=2.60e-03, acc. prob=0.921]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "pyro.clear_param_store()\n",
    "bnn_mcmc = BNN_Multi_Layer_SVI(in_dim=14,first_hid_dim=56,sec_hid_dim=112,thir_hid_dim=112,four_hid_dim=56,out_dim=2,prior_scale=0.75,bias_scale=5)\n",
    "nuts_kernel = NUTS(bnn_mcmc, jit_compile=True)\n",
    "\n",
    "# mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=200)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=100)\n",
    "\n",
    "mcmc.run(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [43:53, 13.17s/it, step size=4.35e-03, acc. prob=0.889]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "pyro.clear_param_store()\n",
    "bnn_mcmc = BNN_Multi_Layer_SVI(in_dim=14,first_hid_dim=14,sec_hid_dim=28,thir_hid_dim=28,four_hid_dim=14,out_dim=2,prior_scale=1,bias_scale=5)\n",
    "nuts_kernel = NUTS(bnn_mcmc, jit_compile=True)\n",
    "\n",
    "# mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=200)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=100)\n",
    "\n",
    "mcmc.run(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=bnn_mcmc, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "OBS:\n",
      "TN, FP, FN, TP\n",
      "[4237  828 1354 2471]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80      5065\n",
      "           1       0.75      0.65      0.69      3825\n",
      "\n",
      "    accuracy                           0.75      8890\n",
      "   macro avg       0.75      0.74      0.74      8890\n",
      "weighted avg       0.75      0.75      0.75      8890\n",
      "\n",
      "RET:\n",
      "TN, FP, FN, TP\n",
      "[4449  616 1667 2158]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80      5065\n",
      "           1       0.78      0.56      0.65      3825\n",
      "\n",
      "    accuracy                           0.74      8890\n",
      "   macro avg       0.75      0.72      0.72      8890\n",
      "weighted avg       0.75      0.74      0.73      8890\n",
      "\n",
      "---TEST SET---\n",
      "OBS:\n",
      "TN, FP, FN, TP\n",
      "[539 179 340 256]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.68       718\n",
      "           1       0.59      0.43      0.50       596\n",
      "\n",
      "    accuracy                           0.61      1314\n",
      "   macro avg       0.60      0.59      0.59      1314\n",
      "weighted avg       0.60      0.61      0.59      1314\n",
      "\n",
      "RET:\n",
      "TN, FP, FN, TP\n",
      "[571 147 386 210]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.80      0.68       718\n",
      "           1       0.59      0.35      0.44       596\n",
      "\n",
      "    accuracy                           0.59      1314\n",
      "   macro avg       0.59      0.57      0.56      1314\n",
      "weighted avg       0.59      0.59      0.57      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "predictive = Predictive(bnn_cat, guide=guide, num_samples=500, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence\n",
    "\n",
    "pred_performance(predictive,x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "predictive = Predictive(bnn_cat, guide=guide, num_samples=200, return_sites=[\"obs\",\"_RETURN\"]) # confidence scales inversely w/ num_samples, low num_samp -> high confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS ON 2022-2023 DATA (SEEN IN TRAINING)\n",
      "Using OBS:\n",
      "max confidence: 0.93\n",
      "correct: 387\n",
      "guessed: 522\n",
      "risked: 29974.359375\n",
      "made: 3245.582275390625\n",
      "ROI: 0.11\n",
      "\n",
      "Using RET:\n",
      "max confidence: 0.88\n",
      "correct: 391\n",
      "guessed: 513\n",
      "risked: 29672.7421875\n",
      "made: 3665.00439453125\n",
      "ROI: 0.12\n",
      "\n",
      "PREDICTIONS ON 2023-2024 DATA (UNSEEN)\n",
      "Using OBS:\n",
      "max confidence: 0.92\n",
      "correct: 331\n",
      "guessed: 503\n",
      "risked: 28039.880859375\n",
      "made: -1482.18408203125\n",
      "ROI: -0.05\n",
      "\n",
      "Using RET:\n",
      "max confidence: 0.88\n",
      "correct: 342\n",
      "guessed: 506\n",
      "risked: 27953.580078125\n",
      "made: -958.8001098632812\n",
      "ROI: -0.03\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bet_data_train = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "bet_data_test = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "bet_train = torch.FloatTensor(StandardScaler().fit_transform((np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_features_inj.csv',delimiter=','))))\n",
    "bet_samps_train = np.genfromtxt('../NBA/consec/conc_feats_samps/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "make_bets(predictive,bet_data_train,bet_data_test,bet_train,x_test,bet_samps_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different normalization technique\n",
    "Improving quality of data could be useful, we will explore the performance of a simple BNN on unnormalized, minmax norm, maxabs norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnormalized\n",
    "First, we will construct a new unnormalized features file from 2014/2015 to 2022/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, maxabs_scale\n",
    "features = []\n",
    "feat_minmax = []\n",
    "feat_maxabs = []\n",
    "samples = []\n",
    "start = 2014\n",
    "\n",
    "while start < 2023:\n",
    "    if start == 2018: # this year is missing and wont populate thru scraper!!\n",
    "        start += 1\n",
    "        continue\n",
    "\n",
    "    curr_feats = np.genfromtxt('../NBA/total/samps_feats/{start}-{end}_nba_features_inj.csv'.format(start=start,end=start+1),delimiter=',')\n",
    "    curr_samps = np.genfromtxt('../NBA/total/samps_feats/{start}-{end}_nba_samples_inj.csv'.format(start=start,end=start+1),delimiter=',')\n",
    "    feat_minmax.extend(minmax_scale(curr_feats))\n",
    "    feat_maxabs.extend(maxabs_scale(curr_feats))\n",
    "    features.extend(curr_feats)\n",
    "    samples.extend(curr_samps)\n",
    "    start += 1\n",
    "\n",
    "\n",
    "np.savetxt('../NBA/total/samps_feats/2015-2023_nba_features_unnorm.csv', features, delimiter=',')\n",
    "np.savetxt('../NBA/total/samps_feats/2015-2023_nba_samples.csv', samples, delimiter=',')\n",
    "np.savetxt('../NBA/total/samps_feats/2015-2023_nba_features_minmax.csv', features, delimiter=',')\n",
    "np.savetxt('../NBA/total/samps_feats/2015-2023_nba_features_maxabs.csv', features, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_15840\\2636246682.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  x_train = torch.FloatTensor(features)\n"
     ]
    }
   ],
   "source": [
    "feat_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=',') # unnormalized\n",
    "samp_test = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "\n",
    "x_train = torch.FloatTensor(features)\n",
    "x_test = torch.FloatTensor(feat_test)\n",
    "y_train = torch.FloatTensor(samples)\n",
    "y_test = torch.FloatTensor(samp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 100/100 [01:35,  1.05it/s, step size=4.07e-02, acc. prob=0.788]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "x_train = torch.FloatTensor(feat_maxabs)\n",
    "x_test = torch.FloatTensor(maxabs_scale(feat_test))\n",
    "y_train = torch.FloatTensor(samples)\n",
    "y_test = torch.FloatTensor(samp_test)\n",
    "\n",
    "model = BNN(in_dim=16,hid_dim=16,out_dim=2)\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "# Define Hamiltonian Monte Carlo (HMC) kernel\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "nuts_kernel = NUTS(model, jit_compile=False)  # jit_compile=True is faster but requires PyTorch 1.6+\n",
    "\n",
    "# Define MCMC sampler, get 50 posterior samples\n",
    "mcmc = MCMC(nuts_kernel, num_samples=50)\n",
    "\n",
    "mcmc.run(x_train, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAINING SET---\n",
      "TN, FP, FN, TP\n",
      "[2384 2925 2191 2874]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.45      0.48      5309\n",
      "           1       0.50      0.57      0.53      5065\n",
      "\n",
      "    accuracy                           0.51     10374\n",
      "   macro avg       0.51      0.51      0.51     10374\n",
      "weighted avg       0.51      0.51      0.51     10374\n",
      "\n",
      "---TEST SET---\n",
      "TN, FP, FN, TP\n",
      "[296 365 267 386]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.48       661\n",
      "           1       0.51      0.59      0.55       653\n",
      "\n",
      "    accuracy                           0.52      1314\n",
      "   macro avg       0.52      0.52      0.52      1314\n",
      "weighted avg       0.52      0.52      0.52      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions based on posteriors\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(), return_sites=['obs','_RETURN'])\n",
    "\n",
    "train_preds = predictive(x_train)['obs'].T.float().mean(axis=1)\n",
    "test_preds = predictive(x_test)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "adj_train_preds = [0 if p < 0.5 else 1 for p in train_preds]\n",
    "adj_test_preds = [0 if p < 0.5 else 1 for p in test_preds]\n",
    "y_train_1d = [0 if j[0] == 0 else 1 for j in y_train] # [0,1] -> [away,home] -> 0 indicates home win, 1 indicates away\n",
    "y_test_1d = [0 if j[0] == 0 else 1 for j in y_test]\n",
    "\n",
    "print('---TRAINING SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_train_1d,adj_train_preds).ravel())\n",
    "print(classification_report(y_train_1d,adj_train_preds))\n",
    "print('---TEST SET---')\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(y_test_1d,adj_test_preds).ravel())\n",
    "print(classification_report(y_test_1d,adj_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "106\n",
      "tensor(-746.6345)\n",
      "49\n",
      "118\n",
      "tensor(-704.2104)\n"
     ]
    }
   ],
   "source": [
    "# Get 2022-2023 game data and betting information\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2022-2023_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2022-2023_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))\n",
    "\n",
    "# Test on 2023-2024 data\n",
    "features_new = maxabs_scale(np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_features_inj.csv',delimiter=','))\n",
    "samples_new = np.genfromtxt('../NBA/total/samps_feats/2023-2024_nba_samples_inj.csv',delimiter=',')\n",
    "bet_data = np.genfromtxt('../NBA/with_bets/2023-2024_season.csv',delimiter=',')\n",
    "\n",
    "samples_new_1d = [0 if j[0] == 0 else 1 for j in samples_new]\n",
    "\n",
    "new_x_tens = torch.FloatTensor(features_new)\n",
    "new_y_tens = torch.FloatTensor(samples_new)\n",
    "\n",
    "new_predictive = Predictive(model=model, posterior_samples=mcmc.get_samples(),return_sites=(\"obs\",\"_RETURN\"))\n",
    "new_y_pred = new_predictive(new_x_tens)['obs'].T.float().mean(axis=1)\n",
    "\n",
    "correct,guessed,team_bet,probs,amount,gained = BNN_kelly(new_y_pred,samples_new_1d,bet_data[1:])\n",
    "print(correct)\n",
    "print(guessed)\n",
    "print(sum(gained))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
