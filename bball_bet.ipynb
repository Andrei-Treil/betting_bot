{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basketball_reference_web_scraper import client\n",
    "from basketball_reference_web_scraper.data import OutputType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import time\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#from basketball_reference_web_scraper import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAM_NAME_TO_ABR = {\n",
    "    \"ATLANTA HAWKS\": 'ATL',\n",
    "    \"BOSTON CELTICS\": 'BOS',\n",
    "    \"BROOKLYN NETS\": 'BRK',\n",
    "    \"CHARLOTTE HORNETS\": 'CHO',\n",
    "    \"CHICAGO BULLS\": 'CHI',\n",
    "    \"CLEVELAND CAVALIERS\": 'CLE',\n",
    "    \"DALLAS MAVERICKS\": 'DAL',\n",
    "    \"DENVER NUGGETS\": 'DEN',\n",
    "    \"DETROIT PISTONS\": 'DET',\n",
    "    \"GOLDEN STATE WARRIORS\": 'GSW',\n",
    "    \"HOUSTON ROCKETS\": 'HOU',\n",
    "    \"INDIANA PACERS\": 'IND',\n",
    "    \"LOS ANGELES CLIPPERS\": 'LAC',\n",
    "    \"LOS ANGELES LAKERS\": 'LAL',\n",
    "    \"MEMPHIS GRIZZLIES\": 'MEM',\n",
    "    \"MIAMI HEAT\": 'MIA',\n",
    "    \"MILWAUKEE BUCKS\": 'MIL',\n",
    "    \"MINNESOTA TIMBERWOLVES\": 'MIN',\n",
    "    \"NEW ORLEANS PELICANS\": 'NOP',\n",
    "    \"NEW YORK KNICKS\": 'NYK',\n",
    "    \"OKLAHOMA CITY THUNDER\": 'OKC',\n",
    "    \"ORLANDO MAGIC\": 'ORL',\n",
    "    \"PHILADELPHIA 76ERS\": 'PHI',\n",
    "    \"PHOENIX SUNS\": 'PHO',\n",
    "    \"PORTLAND TRAIL BLAZERS\": 'POR',\n",
    "    \"SACRAMENTO KINGS\": 'SAC',\n",
    "    \"SAN ANTONIO SPURS\": 'SAS',\n",
    "    \"TORONTO RAPTORS\": 'TOR',\n",
    "    \"UTAH JAZZ\": 'UTA',\n",
    "    \"WASHINGTON WIZARDS\": 'WAS',\n",
    "\n",
    "    # DEPRECATED TEAMS\n",
    "    # \"CHARLOTTE BOBCATS\": 'CHA',\n",
    "    # \"KANSAS CITY KINGS\": 'KCK',\n",
    "    # \"NEW JERSEY NETS\": 'NJN',\n",
    "    # \"NEW ORLEANS HORNETS\": 'NOH',\n",
    "    # \"NEW ORLEANS/OKLAHOMA CITY HORNETS\": 'NOK',\n",
    "    # \"SEATTLE SUPERSONICS\": 'SEA',\n",
    "    # \"ST. LOUIS HAWKS\": 'STL',\n",
    "    # \"VANCOUVER GRIZZLIES\": 'VAN',\n",
    "    # \"WASHINGTON BULLETS\": 'WSB',\n",
    "}\n",
    "\n",
    "MONTH_TO_NUM = {\n",
    "    \"Jan\" : \"01\",\n",
    "    \"Feb\" : \"02\",\n",
    "    \"Mar\" : \"03\",\n",
    "    \"Apr\" : \"04\",\n",
    "    \"May\" : \"05\",\n",
    "    \"Jun\" : \"06\",\n",
    "    \"Sep\" : \"09\",\n",
    "    \"Oct\" : \"10\",\n",
    "    \"Nov\" : \"11\",\n",
    "    \"Dec\" : \"12\",\n",
    "}\n",
    "\n",
    "TEAM_STATS = defaultdict(list)\n",
    "\n",
    "TEAM_ON_OFF = defaultdict(dict)\n",
    "\n",
    "\n",
    "# get team stats for a given season from https://www.basketball-reference.com/teams/\n",
    "def get_team_stats(team_abr,end_year):\n",
    "    '''\n",
    "    team_abr: string abbreviation from basketball-reference\n",
    "    end_year: string representing end year of season to get stats\n",
    "    '''\n",
    "    URL = \"https://www.basketball-reference.com/teams/{team_abr}/{end_year}.html\".format(team_abr=team_abr,end_year=end_year)\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find('div',id='all_team_misc')\n",
    "    dec = results.decode_contents()\n",
    "    new_soup = BeautifulSoup(dec,'lxml')\n",
    "    comment = new_soup.find(text=lambda text:isinstance(text, Comment))\n",
    "    com_soup = BeautifulSoup(comment,'lxml')\n",
    "    table = com_soup.find_all('td')\n",
    "\n",
    "    team_res = []\n",
    "\n",
    "    # MOV\tSOS\tSRS\tORtg\tDRtg\tPace\tFTr\t3PAr\teFG%\tTOV%\tORB%\tFT/FGA\teFG%\tTOV%\tDRB%\tFT/FGA\t\n",
    "    for i in range(4,20):\n",
    "        team_res.append(float(table[i].text))\n",
    "\n",
    "    return team_res\n",
    " \n",
    "\n",
    "# populate team stats based on season year\n",
    "def pop_team_stats(end_year):\n",
    "    for abr in TEAM_NAME_TO_ABR.values():\n",
    "        TEAM_STATS[abr] = get_team_stats(abr,end_year)\n",
    "\n",
    "\n",
    "# get team on off stats\n",
    "def get_on_off(team_abr,end_year):\n",
    "    url = (\"https://www.basketball-reference.com/teams/{team_abr}/{end_year}/on-off/\").format(team_abr=team_abr,end_year=end_year)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find('table',id='on_off')\n",
    "    on_off_list = list(results.find_all('th',scope='row'))\n",
    "    on_off_dict = defaultdict(list)\n",
    "\n",
    "    for i in range(0,len(on_off_list)-2,3):\n",
    "        name = on_off_list[i].text.upper()\n",
    "        on_off_dict[name] = list(on_off_list[i+2].previous.stripped_strings)[1:]\n",
    "    \n",
    "    return on_off_dict\n",
    "\n",
    "\n",
    "# populate team on off stats\n",
    "def pop_team_on_off(end_year):\n",
    "    for abr in TEAM_NAME_TO_ABR.values():\n",
    "        TEAM_ON_OFF[abr] = get_on_off(abr,end_year)\n",
    "\n",
    "\n",
    "def calc_injury_impact(injured,home_abr,away_abr):\n",
    "\n",
    "    home_injured = injured[home_abr]\n",
    "    away_injured = injured[away_abr]\n",
    "    home_stats = TEAM_STATS[home_abr]\n",
    "    away_stats = TEAM_STATS[away_abr]\n",
    "\n",
    "    # map available on-off stats to respective index in team stats, ignore rest for now\n",
    "    # mapping [on_off_idx,team_stats_idx]\n",
    "    affected_stats_idx = [[1,8],[2,10],[3,14],[8,9],[9,5],[10,3],[18,13]]\n",
    "\n",
    "    # eFG%\tORB%\tDRB%\tTRB%\tAST%\tSTL%\tBLK%\tTOV%\tPace\tORtg\teFG%\tORB%\tDRB%\tTRB%\tAST%\tSTL%\tBLK%\tTOV%\tPace\tORtg\n",
    "    # 8      10       14    NAN     NAN      NAN     NAN     9       5       3       NAN     NAN     NAN     NAN     NAN     NAN     NAN     13      NAN     NAN\n",
    "\n",
    "    for player in home_injured:\n",
    "        on_off = TEAM_ON_OFF[home_abr][player]\n",
    "        weight = float(on_off[0].strip('%'))/100\n",
    "        \n",
    "        for pair in affected_stats_idx:\n",
    "            home_stats[pair[1]] -= (weight * on_off[pair[0]])\n",
    "\n",
    "    for player in away_injured:\n",
    "        on_off = TEAM_ON_OFF[away_abr][player]\n",
    "        weight = float(on_off[0].strip('%'))/100\n",
    "        \n",
    "        for pair in affected_stats_idx:\n",
    "            away_stats[pair[1]] -= (weight * on_off[pair[0]])\n",
    "\n",
    "    return home_stats,away_stats\n",
    "\n",
    "\n",
    "def check_injured(box_score_page,home_abr,away_abr):\n",
    "    '''\n",
    "    checks list of injured players for a given game and returns a dict mapping teams to injured player\n",
    "    end_year: string representing end year of NBA season\n",
    "    box_score_page: string representing URL for a given game\n",
    "    home_team: string abbreviation of home team\n",
    "    away_team: string abbreviation of away team\n",
    "    '''\n",
    "    page = requests.get(box_score_page)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find_all('strong')\n",
    "    player_links = results[3].previous.find_all('a')\n",
    "\n",
    "    curr_team = \" \"\n",
    "    players_dict = {home_abr : [], away_abr : []}\n",
    "\n",
    "    for link in player_links:\n",
    "        player_name = link.text.upper()\n",
    "        prev = list(link.previous_sibling.stripped_strings)\n",
    "\n",
    "        if prev[0] == home_abr:\n",
    "            curr_team = home_abr\n",
    "\n",
    "        elif prev[0] == away_abr:\n",
    "            curr_team = away_abr\n",
    "\n",
    "        players_dict[curr_team].append(player_name)\n",
    "\n",
    "    return calc_injury_impact(players_dict,home_abr,away_abr)\n",
    "\n",
    "\n",
    "def generate_features(end_year,file_name):\n",
    "    '''\n",
    "    returns lists containing features, samples\n",
    "    end_year: string representing end year of NBA season\n",
    "    file_name: name of CSV containing games for given season in old_games folder\n",
    "    '''\n",
    "    features = []\n",
    "    samples = []\n",
    "    file_path = \"old_games/{file_name}\".format(file_name=file_name)\n",
    "    # construct data set, consisting of team misc stats as features and win/loss as samples\n",
    "    with open(file_path, mode='r') as f:\n",
    "        lines = csv.reader(f)\n",
    "        for date,away_team,away_pt,home_team,home_pt in lines:\n",
    "            date_list = date.split()\n",
    "            month = MONTH_TO_NUM[date_list[1]]\n",
    "            day = date_list[2]\n",
    "            year = date_list[3]\n",
    "            results = [1,0] if away_pt > home_pt else [0,1]\n",
    "            \n",
    "            # get box score page\n",
    "            box_score_page = \"https://www.basketball-reference.com/boxscores/{YEAR}{MO}{DA}0{HOME}.html\".format(YEAR=year,MO=month,DA=day,HOME=TEAM_NAME_TO_ABR[home_team.upper()])\n",
    "            home_stats,away_stats = check_injured(box_score_page,home_team,away_team)\n",
    "            \n",
    "            features.append(np.subtract(away_stats,home_stats))\n",
    "            samples.append(results)\n",
    "    return features,samples\n",
    "\n",
    "\n",
    "# TODO : add end year of season into here somewhere\n",
    "def get_injuries_for_games(file_name,end_year):\n",
    "    file_path = '{file_name}'.format(file_name=file_name)\n",
    "    with open(file_path, mode='r') as f:\n",
    "        lines = csv.reader(f)\n",
    "        for date,away_team,away_pt,home_team,home_pt in lines:\n",
    "            date_list = date.split()\n",
    "            month = MONTH_TO_NUM[date_list[1]]\n",
    "            day = date_list[2]\n",
    "            year = date_list[3]\n",
    "            winner = away_team if away_pt > home_pt else home_team\n",
    "            # get box score page\n",
    "            box_score_page = \"https://www.basketball-reference.com/boxscores/{YEAR}{MO}{DA}0{HOME}.html\".format(YEAR=year,MO=month,DA=day,HOME=TEAM_NAME_TO_ABR[home_team.upper()])\n",
    "            home_stats,away_stats = check_injured(box_score_page,home_team,away_team)\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.basketball-reference.com/teams/BRK/2022/on-off/\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "results = soup.find('table',id='on_off')\n",
    "on_off_list = list(results.find_all('th',scope='row'))\n",
    "on_off_list[0].text = name\n",
    "list(on_off_list[2].previous.stripped_strings)\n",
    "#results = soup.find('table',id='on_off')\n",
    "#on -off, bos , everythin else\n",
    "#player_link = link.attrs['href'][0:-5]\n",
    "#player_on_off = \"https://www.basketball-reference.com{player_link}/on-off/{year}\".format(player_link=player_link,year=end_year)\n",
    "list(results.find_all('th',scope='row')[2].previous.stripped_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.basketball-reference.com/boxscores/202110200NOP.html\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "results = soup.find_all('strong')\n",
    "player_links = results[3].previous.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0] * 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016-2023 NBA Seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Generate features and samples using date specific stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.basketball-reference.com/friv/standings.fcgi?month=1&day=14&year=2024&lg_id=NBA\n",
    "# https://www.basketball-reference.com/boxscores/202212100GSW.html\n",
    "# https://www.basketball-reference.com/boxscores/YEARMODA0WIN.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate features and samples for each season one at a time, to avoid BBALL reference blocking scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_norm = []\n",
    "samples = []\n",
    "\n",
    "pop_team_stats('2017')\n",
    "features_2017,samples_2017 = generate_features('2017','2016-2017_season.csv')\n",
    "features_2017_norm = [[float(i)/sum(j) for i in j ]for j in features_2017]\n",
    "\n",
    "features_norm.extend(features_2017_norm)\n",
    "samples.extend(samples_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_team_stats('2018')\n",
    "features_2018,samples_2018 = generate_features('2018','2017-2018_season.csv')\n",
    "features_2018_norm = [[float(i)/sum(j) for i in j ]for j in features_2018]\n",
    "\n",
    "features_norm.extend(features_2018_norm)\n",
    "samples.extend(samples_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_team_stats('2019')\n",
    "features_2019,samples_2019 = generate_features('2019','2018-2019_season.csv')\n",
    "features_2019_norm = [[float(i)/sum(j) for i in j ]for j in features_2019]\n",
    "\n",
    "features_norm.extend(features_2019_norm)\n",
    "samples.extend(samples_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_team_stats('2020')\n",
    "features_2020,samples_2020 = generate_features('2020','2019-2020_season.csv')\n",
    "features_2020_norm = [[float(i)/sum(j) for i in j ]for j in features_2020]\n",
    "\n",
    "features_norm.extend(features_2020_norm)\n",
    "samples.extend(samples_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_team_stats('2021')\n",
    "features_2021,samples_2021 = generate_features('2021','2020-2021_season.csv')\n",
    "features_2021_norm = [[float(i)/sum(j) for i in j ]for j in features_2021]\n",
    "\n",
    "features_norm.extend(features_2021_norm)\n",
    "samples.extend(samples_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_team_stats('2022')\n",
    "features_2022,samples_2022 = generate_features('2022','2021-2022_season.csv')\n",
    "features_2022_norm = [[float(i)/sum(j) for i in j ]for j in features_2022]\n",
    "\n",
    "features_norm.extend(features_2022_norm)\n",
    "samples.extend(samples_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_team_stats('2023')\n",
    "features_2023,samples_2023 = generate_features('2023','2022-2023_season.csv')\n",
    "features_2023_norm = [[float(i)/sum(j) for i in j ]for j in features_2023]\n",
    "\n",
    "features_norm.extend(features_2023_norm)\n",
    "samples.extend(samples_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_1d = np.genfromtxt('old_samps_feats/2017-2023_nba_samples_1d.csv',delimiter=',')\n",
    "features_norm = np.genfromtxt('old_samps_feats/2017-2023_nba_features_norm.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features_norm,samples_1d, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN, FP, FN, TP\n",
      "[2574  692  758 2199]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      3266\n",
      "           1       0.76      0.74      0.75      2957\n",
      "\n",
      "    accuracy                           0.77      6223\n",
      "   macro avg       0.77      0.77      0.77      6223\n",
      "weighted avg       0.77      0.77      0.77      6223\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[692 655 710 610]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50      1347\n",
      "           1       0.48      0.46      0.47      1320\n",
      "\n",
      "    accuracy                           0.49      2667\n",
      "   macro avg       0.49      0.49      0.49      2667\n",
      "weighted avg       0.49      0.49      0.49      2667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#solver = lbfgs might be good\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(16,32,16), alpha=1, learning_rate_init=0.025, activation='relu', solver='lbfgs', max_iter=10000)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.075, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=5000)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.075, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN, FP, FN, TP\n",
      "[2286  980 1160 1797]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68      3266\n",
      "           1       0.65      0.61      0.63      2957\n",
      "\n",
      "    accuracy                           0.66      6223\n",
      "   macro avg       0.66      0.65      0.65      6223\n",
      "weighted avg       0.66      0.66      0.66      6223\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[745 602 737 583]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.55      0.53      1347\n",
      "           1       0.49      0.44      0.47      1320\n",
      "\n",
      "    accuracy                           0.50      2667\n",
      "   macro avg       0.50      0.50      0.50      2667\n",
      "weighted avg       0.50      0.50      0.50      2667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(18,36,72,36,18), alpha=0.0001, learning_rate='invscaling', activation='tanh', solver='adam',max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 256, 128)\n",
      "TN, FP, FN, TP\n",
      "[2545  721  907 2050]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.78      0.76      3266\n",
      "         1.0       0.74      0.69      0.72      2957\n",
      "\n",
      "    accuracy                           0.74      6223\n",
      "   macro avg       0.74      0.74      0.74      6223\n",
      "weighted avg       0.74      0.74      0.74      6223\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[743 604 728 592]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.55      0.53      1347\n",
      "         1.0       0.49      0.45      0.47      1320\n",
      "\n",
      "    accuracy                           0.50      2667\n",
      "   macro avg       0.50      0.50      0.50      2667\n",
      "weighted avg       0.50      0.50      0.50      2667\n",
      "\n",
      "(64, 128, 128, 64)\n",
      "TN, FP, FN, TP\n",
      "[2518  748  814 2143]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.77      0.76      3266\n",
      "         1.0       0.74      0.72      0.73      2957\n",
      "\n",
      "    accuracy                           0.75      6223\n",
      "   macro avg       0.75      0.75      0.75      6223\n",
      "weighted avg       0.75      0.75      0.75      6223\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[712 635 689 631]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.53      0.52      1347\n",
      "         1.0       0.50      0.48      0.49      1320\n",
      "\n",
      "    accuracy                           0.50      2667\n",
      "   macro avg       0.50      0.50      0.50      2667\n",
      "weighted avg       0.50      0.50      0.50      2667\n",
      "\n",
      "(128, 256, 256, 128)\n",
      "TN, FP, FN, TP\n",
      "[2568  698  813 2144]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.79      0.77      3266\n",
      "         1.0       0.75      0.73      0.74      2957\n",
      "\n",
      "    accuracy                           0.76      6223\n",
      "   macro avg       0.76      0.76      0.76      6223\n",
      "weighted avg       0.76      0.76      0.76      6223\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[709 638 713 607]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.53      0.51      1347\n",
      "         1.0       0.49      0.46      0.47      1320\n",
      "\n",
      "    accuracy                           0.49      2667\n",
      "   macro avg       0.49      0.49      0.49      2667\n",
      "weighted avg       0.49      0.49      0.49      2667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arcs = [(128,256,128),(64,128,128,64),(128,256,256,128)]\n",
    "for arc in arcs:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=arc, alpha=0.0075, learning_rate_init=0.001, activation='tanh', solver='adam', epsilon=0.0000001, max_iter=10000)\n",
    "    mlp.fit(feat_train,samp_train)\n",
    "    print(arc)\n",
    "    predict_train = mlp.predict(feat_train)\n",
    "    predict_test = mlp.predict(feat_test)\n",
    "\n",
    "    print('TN, FP, FN, TP')\n",
    "    print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "    print(classification_report(samp_train,predict_train))\n",
    "    print('TN, FP, FN, TP')\n",
    "    print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "    print(classification_report(samp_test,predict_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN, FP, FN, TP\n",
      "[2489  777  836 2121]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.76      0.76      3266\n",
      "         1.0       0.73      0.72      0.72      2957\n",
      "\n",
      "    accuracy                           0.74      6223\n",
      "   macro avg       0.74      0.74      0.74      6223\n",
      "weighted avg       0.74      0.74      0.74      6223\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[705 642 662 658]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.52      0.52      1347\n",
      "         1.0       0.51      0.50      0.50      1320\n",
      "\n",
      "    accuracy                           0.51      2667\n",
      "   macro avg       0.51      0.51      0.51      2667\n",
      "weighted avg       0.51      0.51      0.51      2667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(64,128,64), alpha=0.0001, learning_rate_init=0.001, activation='tanh', solver='adam', epsilon=0.0000000001, max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN, FP, FN, TP\n",
      "[2558  708  737 2220]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.78      0.78      3266\n",
      "         1.0       0.76      0.75      0.75      2957\n",
      "\n",
      "    accuracy                           0.77      6223\n",
      "   macro avg       0.77      0.77      0.77      6223\n",
      "weighted avg       0.77      0.77      0.77      6223\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[700 647 698 622]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.52      0.51      1347\n",
      "         1.0       0.49      0.47      0.48      1320\n",
      "\n",
      "    accuracy                           0.50      2667\n",
      "   macro avg       0.50      0.50      0.50      2667\n",
      "weighted avg       0.50      0.50      0.50      2667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(64,128,64), alpha=0.01, learning_rate_init=0.001, activation='tanh', solver='lbfgs', max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('2017-2023_nba_features_norm.csv', features_norm, delimiter=',')\n",
    "np.savetxt('2017-2023_nba_samples_1d.csv', samples_1d, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022-2023 NBA Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_team_stats('2023')\n",
    "features,samples = generate_features('2023','2022-2023_season.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_norm = [[float(i)/sum(j) for i in j ]for j in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_train, feat_test, samp_train, samp_test = train_test_split(features_norm,samples, test_size=0.30, random_state=1)\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features,samples, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 4, 4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.55      0.60       427\n",
      "           1       0.66      0.77      0.71       497\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       924\n",
      "   macro avg       0.67      0.66      0.66       924\n",
      "weighted avg       0.67      0.67      0.66       924\n",
      " samples avg       0.67      0.67      0.67       924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.46      0.48       174\n",
      "           1       0.61      0.65      0.63       222\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       396\n",
      "   macro avg       0.56      0.55      0.55       396\n",
      "weighted avg       0.56      0.57      0.56       396\n",
      " samples avg       0.57      0.57      0.57       396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8, 8, 8, 4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       427\n",
      "           1       0.68      0.67      0.67       497\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       924\n",
      "   macro avg       0.65      0.65      0.65       924\n",
      "weighted avg       0.66      0.65      0.66       924\n",
      " samples avg       0.65      0.65      0.65       924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.48      0.49       174\n",
      "           1       0.60      0.61      0.61       222\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       396\n",
      "   macro avg       0.55      0.55      0.55       396\n",
      "weighted avg       0.55      0.56      0.55       396\n",
      " samples avg       0.56      0.56      0.56       396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 8, 8, 8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       427\n",
      "           1       0.80      0.83      0.81       497\n",
      "\n",
      "   micro avg       0.80      0.79      0.79       924\n",
      "   macro avg       0.80      0.79      0.79       924\n",
      "weighted avg       0.80      0.79      0.79       924\n",
      " samples avg       0.79      0.79      0.79       924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.47      0.46       174\n",
      "           1       0.58      0.57      0.57       222\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       396\n",
      "   macro avg       0.52      0.52      0.52       396\n",
      "weighted avg       0.53      0.52      0.52       396\n",
      " samples avg       0.52      0.52      0.52       396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 16, 16, 16, 8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       427\n",
      "           1       0.87      0.86      0.86       497\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       924\n",
      "   macro avg       0.85      0.85      0.85       924\n",
      "weighted avg       0.85      0.85      0.85       924\n",
      " samples avg       0.85      0.85      0.85       924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.40      0.41       174\n",
      "           1       0.54      0.56      0.55       222\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       396\n",
      "   macro avg       0.48      0.48      0.48       396\n",
      "weighted avg       0.49      0.49      0.49       396\n",
      " samples avg       0.49      0.49      0.49       396\n",
      "\n",
      "(16, 16, 16, 16, 16)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85       427\n",
      "           1       0.89      0.85      0.87       497\n",
      "\n",
      "   micro avg       0.87      0.85      0.86       924\n",
      "   macro avg       0.87      0.86      0.86       924\n",
      "weighted avg       0.87      0.85      0.86       924\n",
      " samples avg       0.84      0.85      0.84       924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.49      0.47       174\n",
      "           1       0.57      0.51      0.54       222\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       396\n",
      "   macro avg       0.51      0.50      0.50       396\n",
      "weighted avg       0.51      0.51      0.51       396\n",
      " samples avg       0.51      0.51      0.51       396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "arcs = [(4,4,4,4),(4,8,8,8,4),(8,8,8,8,8),(8,16,16,16,8),(16,16,16,16,16)]\n",
    "for arc in arcs:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=arc, alpha=0.0025, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=10000)\n",
    "    mlp.fit(feat_train,samp_train)\n",
    "    print(arc)\n",
    "    predict_train = mlp.predict(feat_train)\n",
    "    predict_test = mlp.predict(feat_test)\n",
    "    print(classification_report(samp_train,predict_train))\n",
    "    print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85       427\n",
      "           1       0.93      0.82      0.87       497\n",
      "\n",
      "   micro avg       0.92      0.81      0.86       924\n",
      "   macro avg       0.92      0.81      0.86       924\n",
      "weighted avg       0.92      0.81      0.86       924\n",
      " samples avg       0.81      0.81      0.81       924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.50      0.49       174\n",
      "           1       0.59      0.55      0.57       222\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       396\n",
      "   macro avg       0.53      0.53      0.53       396\n",
      "weighted avg       0.54      0.53      0.53       396\n",
      " samples avg       0.53      0.53      0.53       396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#solver = lbfgs might be good\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(16,32,16), alpha=1, learning_rate_init=0.025, activation='relu', solver='lbfgs', max_iter=10000)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.05, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=5000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       427\n",
      "           1       0.86      0.90      0.88       497\n",
      "\n",
      "   micro avg       0.85      0.90      0.87       924\n",
      "   macro avg       0.85      0.90      0.87       924\n",
      "weighted avg       0.85      0.90      0.87       924\n",
      " samples avg       0.84      0.90      0.86       924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.56      0.53       174\n",
      "           1       0.61      0.58      0.59       222\n",
      "\n",
      "   micro avg       0.56      0.57      0.56       396\n",
      "   macro avg       0.55      0.57      0.56       396\n",
      "weighted avg       0.56      0.57      0.56       396\n",
      " samples avg       0.56      0.57      0.56       396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#solver = lbfgs might be good\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(16,32,16), alpha=1, learning_rate_init=0.025, activation='relu', solver='lbfgs', max_iter=10000)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.025, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=5000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.85       427\n",
      "           1       0.93      0.82      0.87       497\n",
      "\n",
      "   micro avg       0.91      0.82      0.86       924\n",
      "   macro avg       0.91      0.82      0.86       924\n",
      "weighted avg       0.91      0.82      0.86       924\n",
      " samples avg       0.82      0.82      0.82       924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.49      0.49       174\n",
      "           1       0.60      0.59      0.59       222\n",
      "\n",
      "   micro avg       0.55      0.54      0.55       396\n",
      "   macro avg       0.54      0.54      0.54       396\n",
      "weighted avg       0.55      0.54      0.55       396\n",
      " samples avg       0.54      0.54      0.54       396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#solver = lbfgs might be good\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(16,32,16), alpha=1, learning_rate_init=0.025, activation='relu', solver='lbfgs', max_iter=10000)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.075, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2021 - 2023 Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get features and samples for each season, combine into features and samples array\n",
    "pop_team_stats('2021')\n",
    "features_2021,samples_2021 = generate_features('2021','2020-2021_season.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_team_stats('2022')\n",
    "features_2022,samples_2022 = generate_features('2022','2021-2022_season.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_team_stats('2023')\n",
    "features_2023,samples_2023 = generate_features('2023','2022-2023_season.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "samples = []\n",
    "features.extend(features_2021)\n",
    "features.extend(features_2022)\n",
    "features.extend(features_2023)\n",
    "samples.extend(samples_2021)\n",
    "samples.extend(samples_2022)\n",
    "samples.extend(samples_2023)\n",
    "\n",
    "#normalize?\n",
    "#features_norm = [[float(i)/sum(j) for i in j ]for j in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_norm = [[float(i)/sum(j) for i in j ]for j in features]\n",
    "samples_1d = [0 if j[0] == 0 else 1 for j in samples]\n",
    "feat_train, feat_test, samp_train, samp_test = train_test_split(features_norm,samples_1d, test_size=0.30, random_state=1)\n",
    "#feat_train, feat_test, samp_train, samp_test = train_test_split(features_norm,samples, test_size=0.30, random_state=1)\n",
    "#feat_train, feat_test, samp_train, samp_test = train_test_split(features,samples, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75      1276\n",
      "           1       0.77      0.77      0.77      1393\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      2669\n",
      "   macro avg       0.76      0.76      0.76      2669\n",
      "weighted avg       0.76      0.76      0.76      2669\n",
      " samples avg       0.75      0.76      0.75      2669\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.51      0.52       551\n",
      "           1       0.56      0.56      0.56       594\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      1145\n",
      "   macro avg       0.54      0.54      0.54      1145\n",
      "weighted avg       0.54      0.54      0.54      1145\n",
      " samples avg       0.54      0.54      0.54      1145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#solver = lbfgs might be good\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(16,32,16), alpha=1, learning_rate_init=0.025, activation='relu', solver='lbfgs', max_iter=10000)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.075, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=5000)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.075, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=5000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.34      0.43      1276\n",
      "           1       0.56      0.77      0.65      1393\n",
      "\n",
      "   micro avg       0.56      0.57      0.56      2669\n",
      "   macro avg       0.56      0.56      0.54      2669\n",
      "weighted avg       0.56      0.57      0.54      2669\n",
      " samples avg       0.55      0.57      0.56      2669\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.29      0.36       551\n",
      "           1       0.51      0.70      0.59       594\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      1145\n",
      "   macro avg       0.49      0.49      0.47      1145\n",
      "weighted avg       0.49      0.50      0.48      1145\n",
      " samples avg       0.49      0.50      0.49      1145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#solver = lbfgs might be good\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(16,32,16), alpha=1, learning_rate_init=0.025, activation='relu', solver='lbfgs', max_iter=10000)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,32,16), alpha=0.075, activation='tanh', solver='adam',max_iter=5000, epsilon=0.00000001)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "# np_samp_train = np.array(samp_train)\n",
    "# np_samp_test = np.array(samp_test)\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN, FP, FN, TP\n",
      "[1086  307  336  940]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1393\n",
      "           1       0.75      0.74      0.75      1276\n",
      "\n",
      "    accuracy                           0.76      2669\n",
      "   macro avg       0.76      0.76      0.76      2669\n",
      "weighted avg       0.76      0.76      0.76      2669\n",
      "\n",
      "TN, FP, FN, TP\n",
      "[323 271 268 283]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.55       594\n",
      "           1       0.51      0.51      0.51       551\n",
      "\n",
      "    accuracy                           0.53      1145\n",
      "   macro avg       0.53      0.53      0.53      1145\n",
      "weighted avg       0.53      0.53      0.53      1145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#solver = lbfgs might be good\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(16,32,16), alpha=1, learning_rate_init=0.025, activation='relu', solver='lbfgs', max_iter=10000)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.075, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=5000)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,64,32,16), alpha=0.075, learning_rate='invscaling', activation='tanh', solver='lbfgs',max_iter=10000)\n",
    "mlp.fit(feat_train,samp_train)\n",
    "\n",
    "predict_train = mlp.predict(feat_train)\n",
    "predict_test = mlp.predict(feat_test)\n",
    "\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_train,predict_train).ravel())\n",
    "print(classification_report(samp_train,predict_train))\n",
    "print('TN, FP, FN, TP')\n",
    "print(confusion_matrix(samp_test,predict_test).ravel())\n",
    "print(classification_report(samp_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('2021-2023_nba_features_raw.csv', features, delimiter=',')\n",
    "np.savetxt('2021-2023_nba_samples_1d.csv', samples_1d, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1086  307  336  940]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(samp_train,predict_train).ravel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
